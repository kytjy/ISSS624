---
title: "test"
---

---
title: "In-class Ex 2"
date: "Published on November 25 2023"
date-modified: "Last updated on `r format(Sys.time(), '%B %d %Y')`"
format:
  html:
    code-fold: false
    code-summary: "code block"
    toc-title: Contents
    number-sections: true
execute: 
  warning: false
---

<font size = "5"> **Geospatial Analysis using sfdep**</font>

# Loading of R Packages

The following packages are used for this exercise:

-   **sf** for handling spatial data and geoprocessing
-   **tmap** for creating thematic maps
-   **sfdep** for creating space-time cubes and emerging hot spot analysis
-   **tidyverse** as a universe of packages used for aspatial data transformation
-   **plotly** for interactive charts

```{r}
pacman::p_load(sf, tmap, sfdep, tidyverse, knitr, plotly, Kendall)
```

# Importing data

import **hunan** geospatial shapefile and **hunan_2012** aspatial dataframes:

```{r}
hunan <- st_read(dsn = "data/geospatial",
                 layer = "Hunan")
```

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")

GDPPC <- read_csv("data/aspatial/Hunan_GDPPC.csv")
```

## Joining the dataframes

Spatial features are added to the attribute dataframe as **geometry** column:

```{r}
hunan_GDPPC<- left_join(hunan, 
                         GDPPC, 
                         by = "County")

glimpse(hunan_GDPPC)
```

# Cloropleth

```{r}
#| fig-width: 8
tmap_mode("plot")
tm_shape(hunan_GDPPC) +
  tm_fill("GDPPC", 
          style = "quantile", 
          palette = "Blues",
          title = "GDPPC") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of GDP per capita by district, Hunan Province",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

# Computing Neighbors and Deriving Contiguity Weights

**Neighbour Matrix** and **Queen's Contiguity Spatial weights** are calculated together using `st_contiguity` and `st_weights`:

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1)
```

# Local Measures of Autocorrelation

```{r}
lisa <- wm_q %>%
  mutate(
    local_moran = local_moran(GDPPC,
                              nb,
                              wt,
                              nsim = 99),
  # place new columns in front
         .before = 1) %>%
  # values are stored as list -- unnest as a separate column
  unnest(local_moran)
```

# Create a time series cube

using `spacetime()` from sfdep package to create a **spacetime cube object**:

```{r}
GDPPC_st <- spacetime(GDPPC,
                      hunan,
                      # define location column
                      .loc_col = "County",
                      # define time column
                      .time_col = "Year")
```

## Confirm if the new dataframe is a spacetime cube object

```{r}
is_spacetime_cube(GDPPC_st)
```

# Computing GI\*

::: panel-tabset
## Define neighbors and compute spatial weights

```{r}
GDPPC_nb <- GDPPC_st %>%
  # need to specify which field to calculate from using activate when using spacetime cube objects
  activate(
    "geometry"
  ) %>%
  mutate(
    nb = include_self(st_contiguity(geometry)),
    wt = st_inverse_distance(nb,
                             geometry,
                             scale = 1,
                             alpha = 1
                             ),
    .before = 1
  ) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```

-   activate() of dplyr package is used to activate the geometry context
-   mutate() of dplyr package is used to create two new columns nb and wt.
-   Then, we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()
-   row order is very important so do not rearrange the observations after using set_nbs() or set_wts().

Note that this dataset now has neighbors and weights for each time-slice:

```{r}
head(GDPPC_nb)
```

## Calculate GI\* Stat

```{r}
gi_stars <- GDPPC_nb %>% 
  group_by(Year) %>% 
  mutate(gi_star = local_gstar_perm(
    GDPPC, nb, wt)) %>% 
  tidyr::unnest(gi_star)
```

## Conduct Mann-Kendall Test

With these Gi\* measures we can then evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses Changsha county.

```{r}
cbg <- gi_stars %>% 
  ungroup() %>% 
  filter(County == "Changsha") |> 
  select(County, Year, gi_star)
```

```{r}
cbg %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

In the above result, sl is the p-value. This result tells us that there is a slight upward but insignificant trend.
:::

```{r}
p <- ggplot(data = cbg, 
       aes(x = Year, 
           y = gi_star)) +
  labs(title = "Changsha GI* By Year") +
  geom_line() +
  theme_light()

ggplotly(p)
```

# Emerging Hotspot analysis

::: panel-tabset
## Replicate the test for each location

```{r}
ehsa <- gi_stars %>%
  group_by(County) %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>%
  tidyr::unnest_wider(mk)
```

## Arrange to show significant hot/cold spots

```{r}
emerging <- ehsa %>% 
  arrange(sl, abs(tau)) %>% 
  slice(1:5)
```

## Performing Emerging Hotspot Analysis

Lastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument.

The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.

```{r}
ehsa <- emerging_hotspot_analysis(
  x = GDPPC_st,
  .var = "GDPPC",
  k = 1,
  nsim = 99
)
```

What is the distribution of EHSA classes?

```{r}
ggplot(data = ehsa,
       aes(x = classification)) +
  geom_bar()
```
:::

# Geographic visualisation of EHSA

```{r}
hunan_ehsa <- hunan %>%
  left_join(ehsa,
            by = join_by(County == location))
```

```{r}
ehsa_sig <- hunan_ehsa  %>%
  filter(p_value < 0.05)
tmap_mode("plot")
tm_shape(hunan_ehsa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(ehsa_sig) +
  tm_fill("classification") + 
  tm_borders(alpha = 0.4)
```
