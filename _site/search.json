[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Spatial interaction describe quatitatively the flow of people, material, or information between locations in geographical space.\nConditions for Spatial Flows\nThree interdependent conditions are necessary for a spatial interaction to occur:\n\nFeatures\n\n\nLocations: A movement is occurring between a location of origin and a location of destination (i=origin; j =destination)\nCentroid: Abstraction of the attributes of a zone at a point\nFlows: Expressed by a valued vector Tij representing an interaction between locations i and j\nVectors: A vector Tij links two centroids and has a value assigned to it (50) which can represents movements\n\n\n\nIn this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data.\n\n\n\n\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\ntmap for creating thematic maps; useful for static and interactive maps.\nsf for importing, integrating, processing and transforming geospatial data.\nDT for interactive data tables\nstplanr for sustainable transport planning; provides functions and tools for analysis and visualisation of transport projects\nperformance for model performance measurement\nggpubr for visualisation\ntidyverse for importing, integrating, wrangling and visualising data.\n\n\n\n\n\nImporting OD dataExtracting study data\n\n\nNote: Using October 2023 data because Postman API couldn’t find Oct 2022 data, maybe too long ago :(\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\nRecheck to confirm that the 2 variables have indeed been updated:\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\nFor our study, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable allows for interactive tables:\n\n\nShow the code\ndatatable(\n  odbus6_9,\n  filter='top')\n\n\n\n\n\n\n\nWe will save the output in rds format for future use, and reimport the saved rds file into R environment:\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")\n\n\n\n\n\n\n\nTwo geospatial data will be used. They are:\n\nBusStop: This data provides the location of bus stop as at last quarter of 2022.\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\nImporting geospatial dataGeospatial data wrangling\n\n\n\n\nNote that there are repeated bus stop ids , however they have different bus stop roof ids and geometry values.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nduplicate &lt;- busstop %&gt;%\n  group_by(BUS_STOP_N) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\nduplicate\n\nSimple feature collection with 32 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13488.02 ymin: 32594.17 xmax: 44144.57 ymax: 47934\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 32 × 4\n   BUS_STOP_N BUS_ROOF_N LOC_DESC                       geometry\n   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                       &lt;POINT [m]&gt;\n 1 58031      UNK        OPP CANBERRA DR      (27089.69 47570.9)\n 2 62251      B03        Bef Blk 471B        (35500.54 39943.41)\n 3 47201      UNK        &lt;NA&gt;                (22616.75 47793.68)\n 4 58031      UNK        OPP CANBERRA DR     (27111.07 47517.77)\n 5 22501      B02        Blk 662A             (13489.09 35536.4)\n 6 82221      B01        BLK 3A               (35323.6 33257.05)\n 7 68091      B01        AFT BAKER ST        (32164.11 42695.98)\n 8 43709      B06        BLK 644              (18963.42 36762.8)\n 9 97079      B14        OPP ST. JOHN'S CRES (44144.57 38980.25)\n10 82221      B01        Blk 3A              (35308.74 33335.17)\n# ℹ 22 more rows\n\n\nThere are duplicated bus stop numbers, but with different roof IDs and geometry. Some of them could be temporary bus stops within the month?\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\nsummary(mpsz)\n\n  SUBZONE_N          SUBZONE_C          PLN_AREA_N         PLN_AREA_C       \n Length:332         Length:332         Length:332         Length:332        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   REGION_N           REGION_C                  geometry  \n Length:332         Length:332         MULTIPOLYGON :332  \n Class :character   Class :character   epsg:3414    :  0  \n Mode  :character   Mode  :character   +proj=tmer...:  0  \n\nunique(mpsz$PLN_AREA_N)\n\n [1] \"MARINA EAST\"             \"RIVER VALLEY\"           \n [3] \"SINGAPORE RIVER\"         \"WESTERN ISLANDS\"        \n [5] \"MUSEUM\"                  \"MARINE PARADE\"          \n [7] \"SOUTHERN ISLANDS\"        \"BUKIT MERAH\"            \n [9] \"DOWNTOWN CORE\"           \"STRAITS VIEW\"           \n[11] \"QUEENSTOWN\"              \"OUTRAM\"                 \n[13] \"MARINA SOUTH\"            \"ROCHOR\"                 \n[15] \"KALLANG\"                 \"TANGLIN\"                \n[17] \"NEWTON\"                  \"CLEMENTI\"               \n[19] \"BEDOK\"                   \"PIONEER\"                \n[21] \"JURONG EAST\"             \"ORCHARD\"                \n[23] \"GEYLANG\"                 \"BOON LAY\"               \n[25] \"BUKIT TIMAH\"             \"NOVENA\"                 \n[27] \"TOA PAYOH\"               \"TUAS\"                   \n[29] \"JURONG WEST\"             \"SERANGOON\"              \n[31] \"BISHAN\"                  \"TAMPINES\"               \n[33] \"BUKIT BATOK\"             \"HOUGANG\"                \n[35] \"CHANGI BAY\"              \"PAYA LEBAR\"             \n[37] \"ANG MO KIO\"              \"PASIR RIS\"              \n[39] \"BUKIT PANJANG\"           \"TENGAH\"                 \n[41] \"SELETAR\"                 \"SUNGEI KADUT\"           \n[43] \"YISHUN\"                  \"MANDAI\"                 \n[45] \"PUNGGOL\"                 \"CHOA CHU KANG\"          \n[47] \"SENGKANG\"                \"CHANGI\"                 \n[49] \"CENTRAL WATER CATCHMENT\" \"SEMBAWANG\"              \n[51] \"WESTERN WATER CATCHMENT\" \"WOODLANDS\"              \n[53] \"NORTH-EASTERN ISLANDS\"   \"SIMPANG\"                \n[55] \"LIM CHU KANG\"           \n\nunique(mpsz$REGION_N)\n\n[1] \"CENTRAL REGION\"    \"WEST REGION\"       \"EAST REGION\"      \n[4] \"NORTH-EAST REGION\" \"NORTH REGION\"     \n\n\nObservations: 332 subzones, 5 regions\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")\n\n\n\n\n\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nObservations: Number of bus stop dropped from 5161 (busstop) to 5156 (busstop_mpsz) due to the 5 busstops outside MPSZ boundary (ie in Malaysia).\n\n\nShow the code\ndatatable(busstop_mpsz, \n          options = list(pageLength = 5))\n\n\n\n\n\n\n\nSave the output in rds format for future use:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\n\n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore: 242,208 After: 242,944\n\n\n\nCheck for duplicates to prevent double counting:\n\nduplicate2 &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 1,186 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 11009     01341         1 QTSZ01   \n 2 11009     01341         1 QTSZ01   \n 3 11009     01411         4 QTSZ01   \n 4 11009     01411         4 QTSZ01   \n 5 11009     01421        17 QTSZ01   \n 6 11009     01421        17 QTSZ01   \n 7 11009     01511        19 QTSZ01   \n 8 11009     01511        19 QTSZ01   \n 9 11009     01521         2 QTSZ01   \n10 11009     01521         2 QTSZ01   \n# ℹ 1,176 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nBefore: 242,944 After: 242,351\n\n\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nBefore: 242,351 After: 243,263\n\nduplicate3 &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate3\n\n# A tibble: 1,350 × 5\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ SUBZONE_C\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 01013     51071         2 RCSZ10    CCSZ01   \n 2 01013     51071         2 RCSZ10    CCSZ01   \n 3 01112     51071        66 RCSZ10    CCSZ01   \n 4 01112     51071        66 RCSZ10    CCSZ01   \n 5 01112     53041         4 RCSZ10    BSSZ01   \n 6 01112     53041         4 RCSZ10    BSSZ01   \n 7 01121     51071         8 RCSZ04    CCSZ01   \n 8 01121     51071         8 RCSZ04    CCSZ01   \n 9 01121     82221         1 RCSZ04    GLSZ05   \n10 01121     82221         1 RCSZ04    GLSZ05   \n# ℹ 1,340 more rows\n\n\nRetain unique records:\n\nod_data &lt;- unique(od_data)\n\nBefore: 243,263 After: 242,588\n\n\n\n\nod_data &lt;- od_data %&gt;%\n  # Rename column for better clarity\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  # Remove NAs (where there are missing subzones due to time diff between busstop & ridership info)\n  drop_na() %&gt;% \n  # Group and summarise number of trips at each O/D level \n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nod_data\n\n# A tibble: 21,079 × 3\n# Groups:   ORIGIN_SZ [310]\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 AMSZ01    AMSZ01            2694\n 2 AMSZ01    AMSZ02           10591\n 3 AMSZ01    AMSZ03           14980\n 4 AMSZ01    AMSZ04            3106\n 5 AMSZ01    AMSZ05            7734\n 6 AMSZ01    AMSZ06            2306\n 7 AMSZ01    AMSZ07            1824\n 8 AMSZ01    AMSZ08            2734\n 9 AMSZ01    AMSZ09            2300\n10 AMSZ01    AMSZ10             164\n# ℹ 21,069 more rows\n\n\nBefore: 242,588 After: 21,079\nSave the output in rds format for future use, and reimport into R environment:\n\nwrite_rds(od_data, \"data/rds/od_data.rds\")\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")\n\n\n\n\n\n\n\n\nIn this section, we learn how to prepare a desired line by using stplanr package.\n\nRemove intra-zonal flowsCreate desired linesVisualise desired lines\n\n\nWe will not plot the intra-zonal flows, i.e. where the origin and destination are the same (eg origin = AMSZ01 and destination = AMSZ01)\nThe code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\nBefore: 21,079 After: 20,787\n\n\n\n\n\n\nNote\n\n\n\nThe comma , after the condition is significant. In R’s data frame syntax, the format for subsetting is [rows, columns]. When you place a condition before the comma, it applies to rows. The comma itself then implies that you’re not applying any specific filter to the columns – meaning you want all columns.\n\n\n\n\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nflowLine\n\nSimple feature collection with 20787 features and 3 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 5105.594 ymin: 25813.33 xmax: 49483.22 ymax: 49552.79\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK                       geometry\n1     AMSZ01    AMSZ02        10591 LINESTRING (29501.77 39419....\n2     AMSZ01    AMSZ03        14980 LINESTRING (29501.77 39419....\n3     AMSZ01    AMSZ04         3106 LINESTRING (29501.77 39419....\n4     AMSZ01    AMSZ05         7734 LINESTRING (29501.77 39419....\n5     AMSZ01    AMSZ06         2306 LINESTRING (29501.77 39419....\n6     AMSZ01    AMSZ07         1824 LINESTRING (29501.77 39419....\n7     AMSZ01    AMSZ08         2734 LINESTRING (29501.77 39419....\n8     AMSZ01    AMSZ09         2300 LINESTRING (29501.77 39419....\n9     AMSZ01    AMSZ10          164 LINESTRING (29501.77 39419....\n10    AMSZ01    AMSZ11          932 LINESTRING (29501.77 39419....\n\n\n\n\n\n\n\n\nArguments of od2line\n\n\n\n\n\n\nflow: data frame representing origin-destination data. The first two columns of this data frame should correspond to the first column of the data in the zones. Thus in cents_sf(), the first column is geo_code. This corresponds to the first two columns of flow().\nzones: spatial object representing origins (and destinations if no separate destinations object is provided) of travel.\ndestinations: spatial object representing destinations of travel flows.\nzone_code: name of the variable in zones containing the ids of the zone. By default this is the first column names in the zones.\norigin_code: Name of the variable in flow containing the ids of the zone of origin. By default this is the first column name in the flow input dataset.\ndest_code: name of the variable in flow containing the ids of the zone of destination. By default this is the second column name in the flow input dataset or the first column name in the destinations if that is set.\nzone_code_d: Name of the variable in destinations containing the ids of the zone. By default this is the first column names in the destinations.\nsilent: TRUE by default, setting it to TRUE will show you the matching columns\n\n\n\n\n\n\n\n\n\n\n\n\nArguments of tm_lines\n\n\n\n\n\ntm_lines\ncol: color of the lines. Either a color value or a data variable name.\nlwd: line width. Either a numeric value or a data variable.\nalpha: transparency number between 0 (totally transparent) and 1 (not transparent).\nscale: line width multiplier number.\nn: preferred number of color scale classes. Only applicable when lwd is the name of a numeric variable.\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows.\nEg: flow &gt;= 5000:\n\ntmap_mode('view')\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#task",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#task",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#loading-r-packages",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "pacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\ntmap for creating thematic maps; useful for static and interactive maps.\nsf for importing, integrating, processing and transforming geospatial data.\nDT for interactive data tables\nstplanr for sustainable transport planning; provides functions and tools for analysis and visualisation of transport projects\nperformance for model performance measurement\nggpubr for visualisation\ntidyverse for importing, integrating, wrangling and visualising data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-flow-data",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Importing OD dataExtracting study data\n\n\nNote: Using October 2023 data because Postman API couldn’t find Oct 2022 data, maybe too long ago :(\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\nRecheck to confirm that the 2 variables have indeed been updated:\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\nFor our study, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable allows for interactive tables:\n\n\nShow the code\ndatatable(\n  odbus6_9,\n  filter='top')\n\n\n\n\n\n\n\nWe will save the output in rds format for future use, and reimport the saved rds file into R environment:\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Two geospatial data will be used. They are:\n\nBusStop: This data provides the location of bus stop as at last quarter of 2022.\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\nImporting geospatial dataGeospatial data wrangling\n\n\n\n\nNote that there are repeated bus stop ids , however they have different bus stop roof ids and geometry values.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nduplicate &lt;- busstop %&gt;%\n  group_by(BUS_STOP_N) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\nduplicate\n\nSimple feature collection with 32 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13488.02 ymin: 32594.17 xmax: 44144.57 ymax: 47934\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 32 × 4\n   BUS_STOP_N BUS_ROOF_N LOC_DESC                       geometry\n   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                       &lt;POINT [m]&gt;\n 1 58031      UNK        OPP CANBERRA DR      (27089.69 47570.9)\n 2 62251      B03        Bef Blk 471B        (35500.54 39943.41)\n 3 47201      UNK        &lt;NA&gt;                (22616.75 47793.68)\n 4 58031      UNK        OPP CANBERRA DR     (27111.07 47517.77)\n 5 22501      B02        Blk 662A             (13489.09 35536.4)\n 6 82221      B01        BLK 3A               (35323.6 33257.05)\n 7 68091      B01        AFT BAKER ST        (32164.11 42695.98)\n 8 43709      B06        BLK 644              (18963.42 36762.8)\n 9 97079      B14        OPP ST. JOHN'S CRES (44144.57 38980.25)\n10 82221      B01        Blk 3A              (35308.74 33335.17)\n# ℹ 22 more rows\n\n\nThere are duplicated bus stop numbers, but with different roof IDs and geometry. Some of them could be temporary bus stops within the month?\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\nsummary(mpsz)\n\n  SUBZONE_N          SUBZONE_C          PLN_AREA_N         PLN_AREA_C       \n Length:332         Length:332         Length:332         Length:332        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   REGION_N           REGION_C                  geometry  \n Length:332         Length:332         MULTIPOLYGON :332  \n Class :character   Class :character   epsg:3414    :  0  \n Mode  :character   Mode  :character   +proj=tmer...:  0  \n\nunique(mpsz$PLN_AREA_N)\n\n [1] \"MARINA EAST\"             \"RIVER VALLEY\"           \n [3] \"SINGAPORE RIVER\"         \"WESTERN ISLANDS\"        \n [5] \"MUSEUM\"                  \"MARINE PARADE\"          \n [7] \"SOUTHERN ISLANDS\"        \"BUKIT MERAH\"            \n [9] \"DOWNTOWN CORE\"           \"STRAITS VIEW\"           \n[11] \"QUEENSTOWN\"              \"OUTRAM\"                 \n[13] \"MARINA SOUTH\"            \"ROCHOR\"                 \n[15] \"KALLANG\"                 \"TANGLIN\"                \n[17] \"NEWTON\"                  \"CLEMENTI\"               \n[19] \"BEDOK\"                   \"PIONEER\"                \n[21] \"JURONG EAST\"             \"ORCHARD\"                \n[23] \"GEYLANG\"                 \"BOON LAY\"               \n[25] \"BUKIT TIMAH\"             \"NOVENA\"                 \n[27] \"TOA PAYOH\"               \"TUAS\"                   \n[29] \"JURONG WEST\"             \"SERANGOON\"              \n[31] \"BISHAN\"                  \"TAMPINES\"               \n[33] \"BUKIT BATOK\"             \"HOUGANG\"                \n[35] \"CHANGI BAY\"              \"PAYA LEBAR\"             \n[37] \"ANG MO KIO\"              \"PASIR RIS\"              \n[39] \"BUKIT PANJANG\"           \"TENGAH\"                 \n[41] \"SELETAR\"                 \"SUNGEI KADUT\"           \n[43] \"YISHUN\"                  \"MANDAI\"                 \n[45] \"PUNGGOL\"                 \"CHOA CHU KANG\"          \n[47] \"SENGKANG\"                \"CHANGI\"                 \n[49] \"CENTRAL WATER CATCHMENT\" \"SEMBAWANG\"              \n[51] \"WESTERN WATER CATCHMENT\" \"WOODLANDS\"              \n[53] \"NORTH-EASTERN ISLANDS\"   \"SIMPANG\"                \n[55] \"LIM CHU KANG\"           \n\nunique(mpsz$REGION_N)\n\n[1] \"CENTRAL REGION\"    \"WEST REGION\"       \"EAST REGION\"      \n[4] \"NORTH-EAST REGION\" \"NORTH REGION\"     \n\n\nObservations: 332 subzones, 5 regions\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")\n\n\n\n\n\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nObservations: Number of bus stop dropped from 5161 (busstop) to 5156 (busstop_mpsz) due to the 5 busstops outside MPSZ boundary (ie in Malaysia).\n\n\nShow the code\ndatatable(busstop_mpsz, \n          options = list(pageLength = 5))\n\n\n\n\n\n\n\nSave the output in rds format for future use:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\n\n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore: 242,208 After: 242,944\n\n\n\nCheck for duplicates to prevent double counting:\n\nduplicate2 &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 1,186 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 11009     01341         1 QTSZ01   \n 2 11009     01341         1 QTSZ01   \n 3 11009     01411         4 QTSZ01   \n 4 11009     01411         4 QTSZ01   \n 5 11009     01421        17 QTSZ01   \n 6 11009     01421        17 QTSZ01   \n 7 11009     01511        19 QTSZ01   \n 8 11009     01511        19 QTSZ01   \n 9 11009     01521         2 QTSZ01   \n10 11009     01521         2 QTSZ01   \n# ℹ 1,176 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nBefore: 242,944 After: 242,351\n\n\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nBefore: 242,351 After: 243,263\n\nduplicate3 &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate3\n\n# A tibble: 1,350 × 5\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ SUBZONE_C\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 01013     51071         2 RCSZ10    CCSZ01   \n 2 01013     51071         2 RCSZ10    CCSZ01   \n 3 01112     51071        66 RCSZ10    CCSZ01   \n 4 01112     51071        66 RCSZ10    CCSZ01   \n 5 01112     53041         4 RCSZ10    BSSZ01   \n 6 01112     53041         4 RCSZ10    BSSZ01   \n 7 01121     51071         8 RCSZ04    CCSZ01   \n 8 01121     51071         8 RCSZ04    CCSZ01   \n 9 01121     82221         1 RCSZ04    GLSZ05   \n10 01121     82221         1 RCSZ04    GLSZ05   \n# ℹ 1,340 more rows\n\n\nRetain unique records:\n\nod_data &lt;- unique(od_data)\n\nBefore: 243,263 After: 242,588\n\n\n\n\nod_data &lt;- od_data %&gt;%\n  # Rename column for better clarity\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  # Remove NAs (where there are missing subzones due to time diff between busstop & ridership info)\n  drop_na() %&gt;% \n  # Group and summarise number of trips at each O/D level \n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nod_data\n\n# A tibble: 21,079 × 3\n# Groups:   ORIGIN_SZ [310]\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 AMSZ01    AMSZ01            2694\n 2 AMSZ01    AMSZ02           10591\n 3 AMSZ01    AMSZ03           14980\n 4 AMSZ01    AMSZ04            3106\n 5 AMSZ01    AMSZ05            7734\n 6 AMSZ01    AMSZ06            2306\n 7 AMSZ01    AMSZ07            1824\n 8 AMSZ01    AMSZ08            2734\n 9 AMSZ01    AMSZ09            2300\n10 AMSZ01    AMSZ10             164\n# ℹ 21,069 more rows\n\n\nBefore: 242,588 After: 21,079\nSave the output in rds format for future use, and reimport into R environment:\n\nwrite_rds(od_data, \"data/rds/od_data.rds\")\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "In this section, we learn how to prepare a desired line by using stplanr package.\n\nRemove intra-zonal flowsCreate desired linesVisualise desired lines\n\n\nWe will not plot the intra-zonal flows, i.e. where the origin and destination are the same (eg origin = AMSZ01 and destination = AMSZ01)\nThe code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\nBefore: 21,079 After: 20,787\n\n\n\n\n\n\nNote\n\n\n\nThe comma , after the condition is significant. In R’s data frame syntax, the format for subsetting is [rows, columns]. When you place a condition before the comma, it applies to rows. The comma itself then implies that you’re not applying any specific filter to the columns – meaning you want all columns.\n\n\n\n\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nflowLine\n\nSimple feature collection with 20787 features and 3 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 5105.594 ymin: 25813.33 xmax: 49483.22 ymax: 49552.79\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK                       geometry\n1     AMSZ01    AMSZ02        10591 LINESTRING (29501.77 39419....\n2     AMSZ01    AMSZ03        14980 LINESTRING (29501.77 39419....\n3     AMSZ01    AMSZ04         3106 LINESTRING (29501.77 39419....\n4     AMSZ01    AMSZ05         7734 LINESTRING (29501.77 39419....\n5     AMSZ01    AMSZ06         2306 LINESTRING (29501.77 39419....\n6     AMSZ01    AMSZ07         1824 LINESTRING (29501.77 39419....\n7     AMSZ01    AMSZ08         2734 LINESTRING (29501.77 39419....\n8     AMSZ01    AMSZ09         2300 LINESTRING (29501.77 39419....\n9     AMSZ01    AMSZ10          164 LINESTRING (29501.77 39419....\n10    AMSZ01    AMSZ11          932 LINESTRING (29501.77 39419....\n\n\n\n\n\n\n\n\nArguments of od2line\n\n\n\n\n\n\nflow: data frame representing origin-destination data. The first two columns of this data frame should correspond to the first column of the data in the zones. Thus in cents_sf(), the first column is geo_code. This corresponds to the first two columns of flow().\nzones: spatial object representing origins (and destinations if no separate destinations object is provided) of travel.\ndestinations: spatial object representing destinations of travel flows.\nzone_code: name of the variable in zones containing the ids of the zone. By default this is the first column names in the zones.\norigin_code: Name of the variable in flow containing the ids of the zone of origin. By default this is the first column name in the flow input dataset.\ndest_code: name of the variable in flow containing the ids of the zone of destination. By default this is the second column name in the flow input dataset or the first column name in the destinations if that is set.\nzone_code_d: Name of the variable in destinations containing the ids of the zone. By default this is the first column names in the destinations.\nsilent: TRUE by default, setting it to TRUE will show you the matching columns\n\n\n\n\n\n\n\n\n\n\n\n\nArguments of tm_lines\n\n\n\n\n\ntm_lines\ncol: color of the lines. Either a color value or a data variable name.\nlwd: line width. Either a numeric value or a data variable.\nalpha: transparency number between 0 (totally transparent) and 1 (not transparent).\nscale: line width multiplier number.\nn: preferred number of color scale classes. Only applicable when lwd is the name of a numeric variable.\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows.\nEg: flow &gt;= 5000:\n\ntmap_mode('view')\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey of geospatial analytics. Join me in my adventure :)\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains.\n\n\n\n\nAimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) techniques to reveal spatial mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis\n\nCompute LISA of the passenger trips generate by origin\nDisplay and draw statistical conclusions of LISA maps"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#background",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#background",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "AimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) techniques to reveal spatial mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis\n\nCompute LISA of the passenger trips generate by origin\nDisplay and draw statistical conclusions of LISA maps"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.1 The Data",
    "text": "3.1 The Data\nThe following data are used for this study:\n\nAspatial:\n\nPassenger Volume by Origin Destination Bus Stops for August 2023, downloaded from LTA DataMall using API.\n\nGeospatial\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\nhexagon, a hexagon layer of 250m to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2 Import & Preparation",
    "text": "3.2 Import & Preparation\n\n3.2.1 Aspatial\n\n3.2.1.1 Import into R\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset for August 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\n\n\n3.2.1.2 Data Exploration\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. These should be in factor data type for further processing and georeferencing.\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique originating bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops based on August 2023 passenger data.\n\n\n3.2.1.3 Data Wrangling\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\nThe code chunk below identifies all rows in the odbus08 dataframe that have an exact duplicate (i.e., another row with the same values in all columns) using group_by_all().\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period for August 2023\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma()) + scale_x_discrete(labels=c(\"WDA\"=\"Weekday Afternoon\", \"WDM\"= \"Weekday Morning\", \"WEE\"= \"Weekend Evening\", \"WEM\"= \"Weekend Morning\"))\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays for the month of August.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nEach peak period has its own column, as seen using the glimpse() function of dplyr.\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\n\n\n\n3.2.2 Geospatial\n\n3.2.2.1 Import into R\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wide table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\nqtm() of tmap allows us to quickly map the points to visualise the results.\n\nqtm(busstop)\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\nst_intersects is used to identify the bus stops falling inside each hexagon, while lengths returns the number of bus stops inside each hexagon.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer by totalling the number of bus stop in all the hexagons. We use sum() to perform this.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"plot\")\ntm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\n\n\n\n\n\n\n\n\n\n\n3.2.2.2 Geospatial Data Wrangling\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame using the following functions:\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain preferred variables from the data frames.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id) %&gt;% \n  st_drop_geometry\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 4\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;\n1 43709      B06        BLK 644                 1904\n2 43709      B06        BLK 644                 1904\n3 58031      UNK        OPP CANBERRA DR         2939\n4 58031      UNK        OPP CANBERRA DR         2939\n5 51071      B21        MACRITCHIE RESERVOIR    3081\n6 51071      B21        MACRITCHIE RESERVOIR    3081\n7 97079      B14        OPP ST. JOHN'S CRES     5037\n8 97079      B14        OPP ST. JOHN'S CRES     5037\n\n\nResults displayed 4 seemingly genuine duplicated records, with same bus stop number, roof, and location description. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n(b) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame using left_join. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore. LOC_DESC = first(LOC_DESC) geta the first location description for each grid_id group, this allows us to have a rough reference of the name of the bus stop when visualising later. sum() totals up the passenger trips at the hexagonal level. Lastly, we retain only the grids with passenger trip records and bus stop information.\n\norigin_grid &lt;- left_join(peakperiods_wide, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219)) %&gt;%  # retains SG bus stops \n  group_by(grid_id) %&gt;% \n  summarise(\n    LOC_DESC = first(LOC_DESC),\n    WDA = sum(WDA),\n    WDM = sum(WDM),\n    WEM = sum(WEM),\n    WEE = sum(WEE)\n  ) %&gt;% \n  filter(!is.na(grid_id))\n\n# View results\nglimpse(origin_grid)\n\nRows: 1,503\nColumns: 6\n$ grid_id  &lt;int&gt; 34, 65, 99, 127, 129, 130, 131, 159, 160, 161, 163, 190, 191,…\n$ LOC_DESC &lt;chr&gt; \"AFT TUAS STH BLVD\", \"BEF TUAS STH AVE 14\", \"YONG NAM\", \"OPP …\n$ WDA      &lt;dbl&gt; 417, 110, 249, 1810, 2985, 220, 325, 318, 196, 2633, 173, 555…\n$ WDM      &lt;dbl&gt; 62, 50, 44, 155, 1201, 73, 82, 59, 123, 773, 407, 183, 168, 2…\n$ WEM      &lt;dbl&gt; 5, 24, 27, 148, 512, 75, 43, 23, 39, 556, 47, 76, 58, 1377, 3…\n$ WEE      &lt;dbl&gt; 65, 26, 54, 303, 637, 35, 49, 43, 141, 981, 162, 124, 79, 138…\n\n\n\n\n3.2.2.3 Variable Transformation\nLet’s visualise the distribution of passenger trips using a histogram with the ggplot2 package.\n\n\nShow the code\n# Weekday Morning\n# Extract column\ndistWDM &lt;- origin_grid$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 55000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekday Afternoon\n# Extract column\ndistWDA &lt;- origin_grid$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 140000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekend Morning\n# Extract column\ndistWEM &lt;- origin_grid$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 33000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekend Evening\n# Extract column\ndistWEE &lt;- origin_grid$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 39000, \n    y = 1200, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods at a hexagon level appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness and make patterns more evident for analysis.\nifelse() in the code chunk below checks for 0 values and performs log-transformation if the value is non-zero. This is crucial because log of 0 is undefined.\n\norigin_grid_wider &lt;- origin_grid %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Weekday Morning\n# Extract column\ndistlogWDM &lt;- origin_grid_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 12, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Weekday Afternoon\n# Extract column\ndistlogWDA &lt;- origin_grid_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 12, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Weekend Morning\n# Extract column\ndistlogWEM &lt;- origin_grid_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Weekend Evening\n# Extract column\ndistlogWEE &lt;- origin_grid_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 300, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2.4 Retrieve Geometry\nNow, we can finally add in the geometry for each hexagon grid using an inner_join() between hexagon_w_busstops (geospatial data) and origin_grid_wider (aspatial data). This ensures that only common grids in the two data sets are retained.\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid_wider, \n                           by = \"grid_id\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#aspatial",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#aspatial",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2.1 Aspatial",
    "text": "3.2.1 Aspatial\n\nImport into RData ExplorationData Wrangling\n\n\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset for August 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\n\n\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. These should be in factor data type for further processing and georeferencing.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique originating bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops.\n\n\n\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma()) + scale_x_discrete(labels=c(\"WDA\"=\"Weekday Afternoon\", \"WDM\"= \"Weekday Morning\", \"WEE\"= \"Weekend Evening\", \"WEM\"= \"Weekend Morning\"))\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling3.2.3 Variable Transformation3.2.4 Retrieve Geometry\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"plot\")\ntm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 4\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;\n1 43709      B06        BLK 644                 1904\n2 43709      B06        BLK 644                 1904\n3 58031      UNK        OPP CANBERRA DR         2939\n4 58031      UNK        OPP CANBERRA DR         2939\n5 51071      B21        MACRITCHIE RESERVOIR    3081\n6 51071      B21        MACRITCHIE RESERVOIR    3081\n7 97079      B14        OPP ST. JOHN'S CRES     5037\n8 97079      B14        OPP ST. JOHN'S CRES     5037\n\n\nResults displayed 4 seemingly genuine duplicated records, with same bus stop number, roof, and location description. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(b) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame using left_join. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore. LOC_DESC = first(LOC_DESC) geta the first location description for each grid_id group, this allows us to have a rough reference of the name of the bus stop when visualising later.\n\norigin_grid &lt;- left_join(peakperiods_wide, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219)) %&gt;%  # retains SG bus stops \n  group_by(grid_id) %&gt;% \n  summarise(\n    LOC_DESC = first(LOC_DESC),\n    WDA = sum(WDA),\n    WDM = sum(WDM),\n    WEM = sum(WEM),\n    WEE = sum(WEE)\n  ) %&gt;% \n  filter(!is.na(grid_id))\n\nglimpse(origin_grid)\n\nRows: 1,503\nColumns: 6\n$ grid_id  &lt;int&gt; 34, 65, 99, 127, 129, 130, 131, 159, 160, 161, 163, 190, 191,…\n$ LOC_DESC &lt;chr&gt; \"AFT TUAS STH BLVD\", \"BEF TUAS STH AVE 14\", \"YONG NAM\", \"OPP …\n$ WDA      &lt;dbl&gt; 417, 110, 249, 1810, 2985, 220, 325, 318, 196, 2633, 173, 555…\n$ WDM      &lt;dbl&gt; 62, 50, 44, 155, 1201, 73, 82, 59, 123, 773, 407, 183, 168, 2…\n$ WEM      &lt;dbl&gt; 5, 24, 27, 148, 512, 75, 43, 23, 39, 556, 47, 76, 58, 1377, 3…\n$ WEE      &lt;dbl&gt; 65, 26, 54, 303, 637, 35, 49, 43, 141, 981, 162, 124, 79, 138…\n\n\n\n\n\n\n\nShow the code\n# Weekday Morning\n# Extract column\ndistWDM &lt;- origin_grid$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 55000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekday Afternoon\n# Extract column\ndistWDA &lt;- origin_grid$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 140000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekend Morning\n# Extract column\ndistWEM &lt;- origin_grid$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 33000, \n    y = 1200,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Weekend Evening\n# Extract column\ndistWEE &lt;- origin_grid$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 39000, \n    y = 1200, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods at a hexagon level appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\norigin_grid_wider &lt;- origin_grid %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Weekday Morning\n# Extract column\ndistlogWDM &lt;- origin_grid_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 12, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Weekday Afternoon\n# Extract column\ndistlogWDA &lt;- origin_grid_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 12, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Weekend Morning\n# Extract column\ndistlogWEM &lt;- origin_grid_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 300,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Weekend Evening\n# Extract column\ndistlogWEE &lt;- origin_grid_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 300, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid_wider, \n                           by = \"grid_id\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-into-r",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Import into R",
    "text": "Import into R\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset from August to October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n#odbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\n#odbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-exploration",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-exploration",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n#glimpse(odbus09)\n#glimpse(odbus10)\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma())\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\nNotice that there are 5067 unique origin bus stops.\n\n\n(d) Variable Transformation\n\n\nShow the code\n# Extract column\ndistWDM &lt;- peakperiods_wide$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 80000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWDA &lt;- peakperiods_wide$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 110000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEM &lt;- peakperiods_wide$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 23000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEE &lt;- peakperiods_wide$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 29000, \n    y = 2000, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\npeakperiods_wider &lt;- peakperiods_wide %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Extract column\ndistlogWDM &lt;- peakperiods_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWDA &lt;- peakperiods_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Extract column\ndistlogWEM &lt;- peakperiods_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWEE &lt;- peakperiods_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"view\")\nhex &lt;- tm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\nhex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id, busstops) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 5\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id busstops\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;    &lt;int&gt;\n1 43709      B06        BLK 644                 1904        7\n2 43709      B06        BLK 644                 1904        7\n3 58031      UNK        OPP CANBERRA DR         2939        7\n4 58031      UNK        OPP CANBERRA DR         2939        7\n5 51071      B21        MACRITCHIE RESERVOIR    3081        6\n6 51071      B21        MACRITCHIE RESERVOIR    3081        6\n7 97079      B14        OPP ST. JOHN'S CRES     5037        5\n8 97079      B14        OPP ST. JOHN'S CRES     5037        5\n\n\nResults displayed 4 genuine duplicated records. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(c) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore.\n\norigin_grid &lt;- left_join(peakperiods_wider, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  group_by(grid_id) %&gt;% \n  # retains SG bus stops\n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219))\n\nglimpse(origin_grid)\n\nRows: 5,076\nColumns: 13\nGroups: grid_id [1,504]\n$ ORIGIN_BS  &lt;chr&gt; \"01012\", \"01013\", \"01019\", \"01029\", \"01039\", \"01059\", \"0110…\n$ WDA        &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233, 932…\n$ WDM        &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 4240, 5…\n$ WEE        &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6221,…\n$ WEM        &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 6198, …\n$ logWDM     &lt;dbl&gt; 7.587311, 6.858565, 7.489412, 7.848153, 7.985484, 7.409136,…\n$ logWDA     &lt;dbl&gt; 9.041685, 8.899458, 8.190909, 9.139596, 9.467847, 7.665285,…\n$ logWEM     &lt;dbl&gt; 7.728856, 7.436617, 7.320527, 8.093157, 8.598589, 6.967909,…\n$ logWEE     &lt;dbl&gt; 8.073403, 7.935945, 7.392032, 8.353261, 8.909641, 7.081709,…\n$ BUS_ROOF_N &lt;chr&gt; \"B03\", \"B05\", \"B04\", \"B07\", \"B09\", \"B08\", \"TMNL\", \"B07\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"HOTEL GRAND PACIFIC\", \"ST JOSEPH'S CH\", \"BRAS BASAH CPLX\",…\n$ grid_id    &lt;int&gt; 3292, 3292, 3292, 3323, 3354, 3324, 3324, 3292, 3324, 3292,…\n$ busstops   &lt;int&gt; 8, 8, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7,…\n\n\n\n\n(d) Retrieve Geometry\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid, \n                           by = \"grid_id\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-classification",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-classification",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.1 Data Classification",
    "text": "4.1 Data Classification\nDifferent classification schemes highlight areas with the highest and/or lowest values, while others create classes that result in a more uniform distribution of colors. When data is sharply skewed or has extreme outliers, it’s important to consider whether the goal is to emphasize those areas or to achieve a more even distribution of colors and sizes.\nThe main methods of data classification are:\n\nQuantile: each class contains an equal number of features. It assigns the same number of data values to each class. There are no empty classes or classes with too few or too many values\nJenks/Natural breaks: seeks clumps of values that are clustered together in order to form categories that may reflect meaningful groupings of areas\nEqual: divides the range of attribute values into equal-sized sub-ranges\n\nSince our variable is less skewed after log transformation, we can explore various classification methods for visualization. This approach may reveal interesting insights that were not immediately apparent before."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#plots",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#plots",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Plots",
    "text": "4.2 Plots\n\n4.2.1 Weekday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\n\nplotlogWDM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n\nplotlogWDM_q\n\n\n\n\n\n\n\nThe grids above are partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period:\n\nWest: BLK 821, BLK 252, Sunshine Place\nNorth: BLK 314\nNorth-East: BLK 477A, BLK 1, BLK 555, BLK 324\nEast: BLK 109, BLK 124, BLK 756\n\nThis is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nHigher passenger traffic were noted at the bus stops nearer to MRT stations such as Harbourfront Station, Farrer Road Station, Yio Chu Kang Station, and Admirality Station. A possible contributing factor could be the people who are transiting from taking the MRTs to buses to get to their destinations.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. This could potentially be due to the people commuting across the causeway from Malaysia into the Singapore borders.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_e\n\n\n\n\n\n\n\nThe map using equal intervals provided slightly different insights. We noted that the bus stop located near to MRT stations had higher levels of ridership. In particular, more trips originated from Tiong Bahru Station, Buona Vista Station, Tanah Merah Station, Admiralty Station, Harbourfront, and Woodleigh Station. Bus interchanges also appeared to be popular origins, i.e. Bukit Panjang Interchange and Joo Koon Interchange.\nIn general, more homogeneity is noted using the equal interval – the contrast between hexagon to hexagon is less obvious.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_j\n\n\n\n\n\n\n\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes. Higher bus ridership were spotted at bus stops within close proximity to MRT stations (Kranji Station, Buona Vista Station, Buangkok Station, Ranggung Station, Farrer Road Station, Stevens Station, Bedok Reservoir Station) and residential estates (Sunshine Place near Tengah, BLK 109 in Bedok, BLK 477A in Sengkang, Bef. BLK 629A in Woodlands, to name a few).\n\n\n\n\n\n4.2.2 Weekday Afternoon Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_q\n\n\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nBus stops in close proximity to MRT tations and popular bus stops in residential estatements remained high.\nMore trips originating from institutional areas: Opposite Ngee Ann Poly, Temasek Poly, NIE BLK 2, School of the Arts\nMore trips originating from industrial buildings/business parks: North Link Bldg, Aft Senoko Way, Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nMore trips originating from hospitals: Yishun Community Hospital, Changi General Hospital\nSeletar Camp also looked to have high passenger levels\nThe far West seemed to experience low ridership other than the bus stop opposite Tuas Link Station.\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_e\n\n\n\n\n\n\n\nNotably, there were higher concentration of passengers who boarded the bus at Serangoon Station, Harbourfront/VivoCity, Tiong Bahru Station, Admiralty Station, and Punggol Station during weekday afternoons according to the equal interval classification method.\nSimilar to the map for weekday morning peak period, the equal interval seemed to produce more homogeneous classifications.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_j\n\n\n\n\n\n\n\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas.\nIt also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method.\nAlternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\n\n4.2.3 Weekend/Holiday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_q\n\n\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nDuring the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. Buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends.\nBus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe bus stops with the highest boarding passengers are Sunshine Place, Opp BLK 271, BLK 252, Aft. Hasanah Mosque, Buona Vista Station, Harbourfront/Vivocity, Admiralty Station, BLK 555, Bedok Reservoir Station, BLK 22, BLK 109.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_e\n\n\n\n\n\n\n\nEqual interval classification highlighted the following bus stops to have the highest ridership during weekend/holiday morning peak period: Harbourfront/Vivocity, Tiong Bahru Station, Orchard Station/Lucky Plaza, Admirality Station, Aft. Punggol Road.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n4.2.4 Weekend/Holiday Evening\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_q\n\n\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods.\nSunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership.\nWoodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_e\n\n\n\n\n\n\n\nThe bus stops with higher traffic seem to be quite consistent across the different peak periods. This includes Woodlands Checkpoint, Kranji Station, Admiralty Station, Serangoon Station, Aft. Punggol Road, Bukit Panjang MRT, Yio Chu Kang Interchange.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Global Spatial Autocorrelation",
    "text": "5.1 Global Spatial Autocorrelation\n\n5.1.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  500.0   500.0   500.0   503.4   500.0  2291.3 \n\n\nThe maximum nearest neighbour distance is 2291.3m, thus we will use threshold value of 2292m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 2992),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\n#kable(head(wm_fd,5))\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 1503 \nNumber of nonzero links: 106746 \nPercentage nonzero weights: 4.725346 \nAverage number of links: 71.02196 \nLink number distribution:\n\n  1   2   4   9  10  11  12  13  14  15  16  17  19  20  21  22  23  24  25  26 \n  1   1   1   4   2   2   3   1   2   3   3   1   2   2   1   1   6   5   3   3 \n 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46 \n  8   9   4   3   7   2   7   6   4   9   9   5  13  10   7   9   9  12  13  16 \n 47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 \n 15  11  13  19  18  15  19  19  24  16  12  22  20  29  24  25   9  33  27  15 \n 67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86 \n 20  24  21  24  26  23  24  20  30  19  20  24  23  22  32  29  20  23  26  33 \n 87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 \n 29  30  31  31  25  24  22  23  18  27  18  26  20  13  17  12  16   6  14   7 \n107 108 109 110 \n  5   6   3   3 \n1 least connected region:\n1503 with 1 link\n3 most connected regions:\n1013 1024 1050 with 110 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 3 well-connected hexagons with 110 neighbours. We can also identify an average of 71 neighbours per hexagon using the distance-based weight matrix.\n\n#wm_fd_sp &lt;- as(wm_fd, \"Spatial\")\n\n#centroid &lt;- st_centroid(origin_gridwgeom)\n#plot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n#plot(wm_fd_sp$polygons, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")\n\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 13 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1   2, 4, 5, 8, 9, 12, 22, 23\n2   1, 4, 5, 8, 9, 12, 22, 23\n3 5, 6, 9, 10, 13, 14, 16, 17\n                                                      wt grid_id busstops\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34        1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65        1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99        1\n             LOC_DESC WDA WDM WEM WEE   logWDM   logWDA   logWEM   logWEE\n1   AFT TUAS STH BLVD 417  62   5  65 4.127134 6.033086 1.609438 4.174387\n2 BEF TUAS STH AVE 14 110  50  24  26 3.912023 4.700480 3.178054 3.258097\n3            YONG NAM 249  44  27  54 3.784190 5.517453 3.295837 3.988984\n               area_hexagon_grid\n1 POLYGON ((3970.122 27925.48...\n2 POLYGON ((4220.122 28358.49...\n3 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\nFor our analysis, we will set the number of neighbours to 8.\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_knn(geo,\n                     k=8),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nhead(wm_idw, n=3)\n\nSimple feature collection with 3 features and 13 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1   2, 4, 5, 8, 9, 12, 22, 23\n2   1, 4, 5, 8, 9, 12, 22, 23\n3 5, 6, 9, 10, 13, 14, 16, 17\n                                                                                                             wts\n1 0.0020000000, 0.0011547005, 0.0004364358, 0.0007559289, 0.0005000000, 0.0005547002, 0.0005547002, 0.0004588315\n2 0.0020000000, 0.0020000000, 0.0005547002, 0.0011547005, 0.0006666667, 0.0007559289, 0.0006666667, 0.0005773503\n3 0.0020000000, 0.0020000000, 0.0010000000, 0.0020000000, 0.0011547005, 0.0011547005, 0.0007559289, 0.0010000000\n  grid_id busstops            LOC_DESC WDA WDM WEM WEE   logWDM   logWDA\n1      34        1   AFT TUAS STH BLVD 417  62   5  65 4.127134 6.033086\n2      65        1 BEF TUAS STH AVE 14 110  50  24  26 3.912023 4.700480\n3      99        1            YONG NAM 249  44  27  54 3.784190 5.517453\n    logWEM   logWEE              area_hexagon_grid\n1 1.609438 4.174387 POLYGON ((3970.122 27925.48...\n2 3.178054 3.258097 POLYGON ((4220.122 28358.49...\n3 3.295837 3.988984 POLYGON ((4470.122 30523.55...\n\n\nThe inverse distance approach is best suited for continuous data or for modeling scenarios where spatial proximity increases the likelihood of interaction or influence between two features. Nevertheless, this method treats every feature as a potential neighbor to every other feature, which can lead to a significant computational burden, especially in the case of large datasets where the volume of calculations required becomes substantial.\n\n#mpsz_sp &lt;- as(wm_idw, \"Spatial\")\n\ncentroid &lt;- st_centroid(origin_gridwgeom)\nplot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n\n\n\n#plot(wm_idw, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")\n\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method is computationally intensive as each feature is potentially a neighbour of every other feature.\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#computing-global-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#computing-global-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Computing Global Spatial Autocorrelation Statistics",
    "text": "5.2 Computing Global Spatial Autocorrelation Statistics\n\n5.2.1 Moran’s I\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing, using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed).\nH1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed using the original and logged values with a seed number 1234. set.seed() function allows us to create reproducible results.\nNote: nsim arugment of global_moran_perm() refers to the number of simulations is nsim + 1, i.e., for nsim = 99, 100 simulations will be performed.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.19938, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Variable\n\n\nShow the code\ngmp_logWDM &lt;- global_moran_perm(wm_ad$logWDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.5159, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.059528, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWDA &lt;- global_moran_perm(wm_ad$logWDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.35711, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15158, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWEM &lt;- global_moran_perm(wm_ad$logWEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.49385, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.097321, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWEE &lt;- global_moran_perm(wm_ad$logWEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.40407, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained). The higher Moran’s I values for logged-transformed variables suggests a higher level of clustering compared to the original ridership values."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#local-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#local-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.3 Local Spatial Autocorrelation Statistics",
    "text": "5.3 Local Spatial Autocorrelation Statistics\nGlobal spatial autocorrelation provides a broad overview of spatial clustering within a dataset, offering a single value that indicates whether similar values are generally clustered or dispersed across the entire study area. In contrast, local spatial autocorrelation delves into specific locations, identifying where clusters of similar values (hot spots or cold spots) or spatial outliers exist. While global metrics give an overall trend, local metrics provide detailed, location-specific insights, highlighting exact areas of significant spatial clustering or anomaly.\nThus, after we have established through statistical testing that spatial clustering of bus ridership occurs in Singapore, we now seek to detect clusters or outliers and discover if there are any hot or cold spots of high ridership using Local Spatial Autocorrelation Statistics.\n\n5.3.1 Local Moran’s I\nIn this section, we will perform Moran’s I statistics testing by using local_moran() of sfdep. The output of local_moran() is a sf data.frame, containing the columns below:\n\nii: local moran statistic\neii: expectation of local Moran’s I statistic\nvar_ii: variance of local Moran’s I statistic\nz_ii: standard deviation of local Moran’s I statistic\np_ii: p-value of local Moran’s I statistic using pnorm()\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value, based on crand.py of pysal\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nunnest() of tidyr package helps expand a list-column containing data frames into rows and columns.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\nOriginal Data\n\n\nShow the code\nlisa_WDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDM, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii   p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.386 -0.0300  0.0517  1.83 0.0673     0.02         0.01   -0.986    1.02 \n2 0.386  0.00824 0.0439  1.80 0.0715     0.02         0.01   -1.59     3.83 \n3 0.384  0.0181  0.0392  1.85 0.0646     0.02         0.01   -1.25     2.84 \n4 0.382 -0.00282 0.0440  1.83 0.0669     0.02         0.01   -1.33     2.74 \n5 0.367  0.0196  0.0363  1.82 0.0688     0.02         0.01   -0.911    0.458\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nLog-Transformed Data\n\n\nShow the code\nlisa_logWDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWDM, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii       p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2.50   0.0725  0.395   3.85 0.000116       0.02         0.01    0.164 -0.366  \n2 2.60  -0.00763 0.371   4.28 0.0000186      0.02         0.01    0.152  0.00836\n3 2.43   0.00367 0.499   3.43 0.000596       0.02         0.01    0.451  0.187  \n4 1.98   0.00665 0.283   3.70 0.000212       0.02         0.01    0.142 -0.585  \n5 0.846 -0.0305  0.0363  4.60 0.00000421     0.02         0.01    0.266 -0.274  \n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDA, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.205 -0.00517 0.0243  1.35 0.177     0.02         0.01    -2.11     5.11\n2 0.209 -0.0201  0.0338  1.25 0.213     0.02         0.01    -1.96     3.82\n3 0.204  0.0222  0.0211  1.25 0.211     0.02         0.01    -2.54     9.59\n4 0.192  0.0250  0.0136  1.43 0.152     0.02         0.01    -2.33     6.51\n5 0.177 -0.00590 0.0164  1.43 0.153     0.02         0.01    -1.78     4.07\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nLog-Transformed Data\n\n\nShow the code\nlisa_logWDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWDA, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii       p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 1.90   0.0644  0.303   3.34 0.000848       0.04         0.02    0.849    0.770\n2 2.67  -0.0583  0.537   3.73 0.000194       0.02         0.01   -0.153   -0.661\n3 2.10   0.00427 0.375   3.42 0.000619       0.06         0.03    0.946    1.62 \n4 0.924 -0.0318  0.0420  4.66 0.00000311     0.02         0.01    0.581    0.695\n5 0.523  0.00710 0.0151  4.21 0.0000258      0.02         0.01    0.343   -0.534\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEM, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii   p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.315  0.00993 0.0417  1.49 0.135      0.02         0.01    -1.98     5.32\n2 0.314  0.0264  0.0334  1.57 0.116      0.02         0.01    -1.77     4.00\n3 0.307  0.0271  0.0316  1.57 0.116      0.02         0.01    -1.72     4.44\n4 0.303  0.0129  0.0262  1.80 0.0725     0.02         0.01    -1.30     1.87\n5 0.290 -0.0248  0.0488  1.43 0.154      0.02         0.01    -1.93     3.92\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nLog-Transformed Data\n\n\nShow the code\nlisa_logWEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWEM, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii     eii var_ii  z_ii        p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 4.21   0.111  1.35    3.53 0.000413        0.02         0.01    0.224   -0.322\n2 3.27   0.0112 0.693   3.91 0.0000919       0.02         0.01    0.400    0.614\n3 2.64   0.0295 0.453   3.88 0.000103        0.02         0.01    0.342   -0.542\n4 1.92  -0.0367 0.153   5.00 0.000000568     0.02         0.01    0.168   -0.344\n5 0.903 -0.0294 0.0373  4.83 0.00000135      0.02         0.01    0.181   -0.155\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEE, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.223 -0.00162 0.0255  1.41 0.159     0.02         0.01    -2.01     6.38\n2 0.225 -0.0145  0.0384  1.22 0.222     0.02         0.01    -2.25     5.82\n3 0.216  0.00855 0.0216  1.41 0.157     0.02         0.01    -1.70     3.01\n4 0.213 -0.00814 0.0345  1.19 0.233     0.02         0.01    -2.88    11.0 \n5 0.200 -0.00909 0.0319  1.17 0.241     0.02         0.01    -2.02     3.82\n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nLog-Transformed Data\n\n\nShow the code\nlisa_logWEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWEE, n=5)\n\n\nSimple feature collection with 5 features and 25 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 26\n     ii      eii var_ii  z_ii     p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2.17  -0.00124 0.385   3.50 0.000466     0.02         0.01   0.174   0.342  \n2 2.67   0.0907  0.638   3.22 0.00127      0.02         0.01  -0.0207  0.00460\n3 2.02  -0.156   0.419   3.36 0.000767     0.04         0.02   0.577   0.605  \n4 1.20   0.0287  0.103   3.64 0.000277     0.02         0.01   0.336  -0.0657 \n5 0.675 -0.00449 0.0309  3.87 0.000110     0.02         0.01   0.788   0.969  \n# ℹ 17 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops &lt;int&gt;, LOC_DESC &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEM &lt;dbl&gt;, WEE &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\n\n5.3.2 Visualising Local Moran’s I & p-value\nTo better understand which areas are outliers/clusters, we will use choropleth mapping functions of tmap package to visualise the local Moran’s I values and the associated p-values by using the code chunks below.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisaWDM &lt;-\n  tm_shape(lisa_WDM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),\n            frame = FALSE)\n\nplotp_lisaWDM &lt;- \n  tm_shape(lisa_WDM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),          \n            frame = FALSE)\n\nplot_lisalogWDM &lt;-\n  tm_shape(lisa_logWDM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),\n            frame = FALSE\n            )\n\nplotp_lisalogWDM &lt;- \n  tm_shape(lisa_logWDM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),\n            frame = FALSE)\n\n\ntmap_arrange(plot_lisaWDM, plotp_lisaWDM, plot_lisalogWDM, plotp_lisalogWDM, asp=2, ncol=2, nrow = 2) \n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisaWDA &lt;-\n  tm_shape(lisa_WDA) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\nplotp_lisaWDA &lt;- \n  tm_shape(lisa_WDA) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(-Inf, \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),          \n            frame = FALSE\n            )\n            \nplot_lisalogWDA &lt;-\n  tm_shape(lisa_logWDA) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\nplotp_lisalogWDA &lt;- \n  tm_shape(lisa_logWDA) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\ntmap_arrange(plot_lisaWDA, plotp_lisaWDA, plot_lisalogWDA, plotp_lisalogWDA, asp=2, ncol=2)\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisaWEM &lt;-\n  tm_shape(lisa_WEM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),             \n            frame = FALSE\n            )\n\nplotp_lisaWEM &lt;- \n  tm_shape(lisa_WEM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(-Inf, \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),           \n            frame = FALSE\n            )\n\nplot_lisalogWEM &lt;-\n  tm_shape(lisa_logWEM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\nplotp_lisalogWEM &lt;- \n  tm_shape(lisa_logWEM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\ntmap_arrange(plot_lisaWEM, plotp_lisaWEM, plot_lisalogWEM, plotp_lisalogWEM, asp=2, ncol=2, nrow = 2)\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisaWEE &lt;-\n  tm_shape(lisa_WEE) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  #tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n             legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE)\n\nplotp_lisaWEE &lt;- \n  tm_shape(lisa_WEE) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(-Inf, \"0.01\", \"0.05\", \"Not sig\")) +\n  #tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n              legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),           \n            frame = FALSE)\n\nplot_lisalogWEE &lt;-\n  tm_shape(lisa_logWEE) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n # tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n             legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),            \n            frame = FALSE\n            )\n\nplotp_lisalogWEE &lt;- \n  tm_shape(lisa_logWEE) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  #tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I\\n (Using Log-Transformed Variables)\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n              legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"top\"),           \n            frame = FALSE\n            )\n\ntmap_arrange(plot_lisaWEE, plotp_lisaWEE, plot_lisalogWEE, plotp_lisalogWEE, asp=2, ncol=2, nrow=2)\n\n\n\n\n\n\n\n\nThe plot on the top-left shows regions of positive (in blue) and negative (in red) Moran’s I statistics, indicating positive and negative clustering relationships. In particular, bus stops near transit hubs like Clementi Station, Tampines Interchange, and Punggol Station have high Local Moran’s I statistics across all four peak periods. On the contrary, Woodlands Checkpoint seems to only experience high Moran’s I on weekday mornings.\nNotably, the Boon Lay MRT region displayed negative Local Moran’s (in red) throughout the four peak periods, indicating that the volume of passenger trips at this area is dissimilar to its neighbours.\nOn the top-right, we see that the p-values are significant at 5% significance level for the regions in the 3 darker shades of blue. We see that areas in the far West, North-West, and far East have statistically significant p-values for the cluster/outlier spatial relationship that they see.\nWe obtain different insights using the log-transformed variables to calculate Local Moran’s I. On weekdays, North-West region, particularly around Lim Chu Kang / Sungei Buloh. The plot on the right suggests that with p-value &lt;0.05, the high spatial clustering observed in the area is also statistically significant.\nLISA cluster maps combines both Local Moran’s I values and p-values to derive more insightful observations.\n\n\n5.3.3 Visualising LISA Map\nThe LISA Cluster Map allows us to identify hotspots can its statistical significance. It is colour-coded by four types of spatial autocorrelation:\n\nHigh-High: Positive autocorrelation, i.e. clusters (indicates hexagon and its neighbours all have high ridership)\nLow-Low: Positive autocorrelation, i.e. clusters (indicates hexagon and its neighbours all have low number ridership)\nLow-High: Negative autocorrelation, i.e. outlier (indicates hexagon with low ridership among neighbours with high ridership)\nHigh-Low: Negative autocorrelation, i.e. outlier (indicates hexagon with high ridership among neighbours with low ridership)\n\nThe following functions are used:\n\nfilter() from dplyr used to retain records with statistically significant results (p-value &lt; 0.05)\ntmap_mode(“view”) allows for interactive viewing of plots\n\nNote: The median is used for untransformed variables due to their right-skewed distribution, while the mean is used for log-transformed variables.\nWeekday Morning\n\nOriginal ValuesLog-Transformed Variable\n\n\n\n\nShow the code\nlisa_sig_WDM &lt;- lisa_WDM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_WDM) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_WDM) +\n  tm_fill(\"median\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WDM\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlisa_sig_logWDM &lt;-lisa_logWDM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_logWDM) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_logWDM) +\n  tm_fill(\"mean\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WDM\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nThe plot demonstrates that the statistically significant Moran’s I values are depicted in salmon for high-high autocorrelation and in teal for low-low autocorrelation, indicating clusters. Areas displaying low-low autocorrelation are primarily observed around the edges of the island, notably in the West, North-West, and East regions. In the context of our study, these areas experience low bus ridership and are surrounded by bus stops that also have low ridership. This pattern could suggest that on weekday mornings, these areas either have less human traffic or that residents prefer other forms of transportation. More and larger clusters are also seen using the log-transformed variables, where similar neighbouring hexagons demonstrate similar autocorrelation.\nHigh-high autocorrelation areas, where both an area and its neighboring areas have high bus ridership, are scattered across the island. These are predominantly found near transit hubs such as Boon Lay Station, Aft. Bukit Panjang Station, Woodlands Checkpoint, and Buona Vista. Some residential estates and the neighourhood schools, including Punggol and Clementi, also exhibit high-high autocorrelation. This trend could be attributed to people traveling from their homes or switching transportation modes, opting for buses to reach their destinations. Retail centres appear to have high-high autocorrelation during the weekday morning peak-periods as well, evidenced in areas like Teck Whye Shopping Centre.\nSeveral outliers are identified in purple and yellow. The Low-High regions (in purple) are generally found in proximity to high-high regions (in salmon). Conversely, High-Low regions (in yellow) appear to be located near low-low regions (in teal).\nWeekday Afternoons\n\nOriginal ValuesLog-Transformed Variable\n\n\n\n\nShow the code\nlisa_sig_WDA &lt;- lisa_WDA  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_WDA) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_WDA) +\n  tm_fill(\"median\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WDA\")) +  \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlisa_sig_logWDA &lt;- lisa_logWDA  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_logWDA) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_logWDA) +\n  tm_fill(\"mean\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WDA\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nFor the weekday afternoon peak period, areas exhibiting high-high autocorrelation include transit hubs such as Opp. LakeSide Station, Bef. Khatib Station, Compassvale Station, Serangoon Station, Downtown Station, and others. This trend mirrors that of weekday mornings, where transit hubs experience high bus ridership, likely due to passengers switching between different modes of transportation.\nBus stop near area of attraction (like the Singapore Zoo) also showed high-low autocorrelation on weekday afternoons, compared to the high-high autocorrelation experienced on weekday morning peak period. This suggests that it’s ridership remains high but lower ridership recorded in the surrounding regions.\nUsing the log-transformed variable, the stretch along Orchard Road from Orchard Station to War Memorial Park, and CBD area in the South have also been highlighted as a high-high cluster.\nDuring these afternoon peak periods, there appears to be less statistically significant autocorrelation, particularly in areas like the Loyang region, including Changi Prison and Laguna National Country Club. Notably, using the untransformed values, the Woodlands Checkpoint area does not demonstrate the statistically significant high-high relationship expected from the previous Section 4.2.2 Geovisualisation or in comparison to weekday mornings. This observation might indicate that there is more human traffic moving from Malaysia to Singapore in the mornings, resulting in higher bus ridership originating from the checkpoints.\nWeekend/Holidays Morning\n\nOriginal ValuesLog-Transformed Variable\n\n\n\n\nShow the code\nlisa_sig_WEM &lt;- lisa_WEM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_WEM) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_WEM) +\n  tm_fill(\"median\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WEM\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlisa_sig_logWEM &lt;- lisa_logWEM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_logWEM) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_logWEM) +\n  tm_fill(\"mean\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WEM\")) +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nThere are a lot more low-low regions on weekend/holiday mornings, suggesting generally lower levels of ridership compared to the weekday peak periods. These clusters were noted along the peripheral edges. This is in line with the observations made in our barplot in Section 3.2.1. Another difference with the weekday peak periods is the low-low autocorrelation noted at the Science Park area evidenced by the cluster of teal hexagons in the South-West region.\nThere are also notably less high-high clusters in the West, specifically in the Jurong West / Boon Lay areas, and more of such clusters in the South-East region (i.e. Bras Basah and Marine Parade). There is also seemingly an influx of passengers from the Tanah Merah Ferry Terminal on weekend/holiday mornings, in contrast to the low-low autocorrelation for weekday-mornings.\nWeekend/Holidays Evening\n\nOriginal ValuesLog-Transformed Variable\n\n\n\n\nShow the code\nlisa_sig_WEE &lt;- lisa_WEE  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_WEE) + \n  tm_fill(alpha=0.6)+\n  tm_polygons() +\n#  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_WEE) +\n  tm_fill(\"median\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WEE\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlisa_sig_logWEE &lt;- lisa_logWEE  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(lisa_logWEE) +\n  tm_fill(alpha=0.6)+\n  tm_polygons() +\ntm_shape(lisa_sig_logWEE) +\n  tm_fill(\"mean\",\n          alpha=0.6,\n          id=\"LOC_DESC\",\n          popup.vars = c(\"Location Description: \" = \"LOC_DESC\",\n                         \"Grid ID: \" = \"grid_id\",\n                         \"No. of Bus Stops:\" = \"busstops\",\n                         \"No. of Passenger Trips :\" = \"WEE\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nUsing the untransformed passenger volume, the bus stops in the West, North-West, and Changi Village regions continue to experience low ridership on weekday and holiday evenings, as illustrated by the clusters of teal hexagons. Bus stops located near transit hubs and around the shopping district in town exhibit high-high autocorrelation (in salmon). Notably, the area around Woodlands MRT station shows significant high-high autocorrelation, which could be attributed to its connectivity with Woodlands Bus Interchange and its status as an interchange serving both the North-South Line and the Thomson-East Coast Line. Interestingly, no high-low outliers (in yellow) are observed in the Central and South regions of Singapore.\nMore clusters are shown with the log-transformed passenger volume. In particular, Hougang Central, Paya Lebar / Joo Chiat region, Toa Payoh Central, Tiong Bahru and Clementi were not previously highlighted as high-high clusters before."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex1.html",
    "href": "Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nThis is the getting started paragraph"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html",
    "href": "In-class_Ex/In-class_Ex2/test.html",
    "title": "In-class Ex 2",
    "section": "",
    "text": "Geospatial Analysis using sfdep"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html#joining-the-dataframes",
    "href": "In-class_Ex/In-class_Ex2/test.html#joining-the-dataframes",
    "title": "In-class Ex 2",
    "section": "2.1 Joining the dataframes",
    "text": "2.1 Joining the dataframes\nSpatial features are added to the attribute dataframe as geometry column:\n\nhunan_GDPPC&lt;- left_join(hunan, \n                         GDPPC, \n                         by = \"County\")\n\nglimpse(hunan_GDPPC)\n\nRows: 1,496\nColumns: 10\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21098, 21098, 21098, 21098, 21098, 21098, 21098, 210…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anx…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County\", \"County\", \"County\", \"County\",…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 1.869074, 1.869074, 1.869074, 1.869074, 1.869074,…\n$ Shape_Area &lt;dbl&gt; 0.1005619, 0.1005619, 0.1005619, 0.1005619, 0.1005619, 0.10…\n$ County     &lt;chr&gt; \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anx…\n$ Year       &lt;dbl&gt; 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,…\n$ GDPPC      &lt;dbl&gt; 8184.00, 10995.00, 12670.00, 14128.00, 16763.00, 19817.00, …\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.0625 …"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html#confirm-if-the-new-dataframe-is-a-spacetime-cube-object",
    "href": "In-class_Ex/In-class_Ex2/test.html#confirm-if-the-new-dataframe-is-a-spacetime-cube-object",
    "title": "In-class Ex 2",
    "section": "6.1 Confirm if the new dataframe is a spacetime cube object",
    "text": "6.1 Confirm if the new dataframe is a spacetime cube object\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains.\n\n\n\n\nAimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "AimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.1 The Data",
    "text": "3.1 The Data\nThe following data are used for this study:\n\nAspatial:\n\nPassenger Volume by Origin Destination Bus Stops for August, September and October 2023, downloaded from LTA DataMall using API.\n\nGeospatial\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\nhexagon, a hexagon layer of 250m is provided to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2 Import & Preparation",
    "text": "3.2 Import & Preparation"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#aspatial",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#aspatial",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2.1 Aspatial",
    "text": "3.2.1 Aspatial\n::: panel-tabset"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-into-r",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Import into R",
    "text": "Import into R\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset from August to October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n#odbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\n#odbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-exploration",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-exploration",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n#glimpse(odbus09)\n#glimpse(odbus10)\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma())\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\nNotice that there are 5067 unique origin bus stops.\n\n\n(d) Variable Transformation\n\n\nShow the code\n# Extract column\ndistWDM &lt;- peakperiods_wide$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 80000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWDA &lt;- peakperiods_wide$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 110000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEM &lt;- peakperiods_wide$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 23000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEE &lt;- peakperiods_wide$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 29000, \n    y = 2000, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\npeakperiods_wider &lt;- peakperiods_wide %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Extract column\ndistlogWDM &lt;- peakperiods_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWDA &lt;- peakperiods_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Extract column\ndistlogWEM &lt;- peakperiods_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWEE &lt;- peakperiods_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"view\")\nhex &lt;- tm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\nhex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id, busstops) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 5\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id busstops\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;    &lt;int&gt;\n1 43709      B06        BLK 644                 1904        7\n2 43709      B06        BLK 644                 1904        7\n3 58031      UNK        OPP CANBERRA DR         2939        7\n4 58031      UNK        OPP CANBERRA DR         2939        7\n5 51071      B21        MACRITCHIE RESERVOIR    3081        6\n6 51071      B21        MACRITCHIE RESERVOIR    3081        6\n7 97079      B14        OPP ST. JOHN'S CRES     5037        5\n8 97079      B14        OPP ST. JOHN'S CRES     5037        5\n\n\nResults displayed 4 genuine duplicated records. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(c) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore.\n\norigin_grid &lt;- left_join(peakperiods_wider, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  group_by(grid_id) %&gt;% \n  # retains SG bus stops\n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219))\n\nglimpse(origin_grid)\n\nRows: 5,076\nColumns: 13\nGroups: grid_id [1,504]\n$ ORIGIN_BS  &lt;chr&gt; \"01012\", \"01013\", \"01019\", \"01029\", \"01039\", \"01059\", \"0110…\n$ WDA        &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233, 932…\n$ WDM        &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 4240, 5…\n$ WEE        &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6221,…\n$ WEM        &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 6198, …\n$ logWDM     &lt;dbl&gt; 7.587311, 6.858565, 7.489412, 7.848153, 7.985484, 7.409136,…\n$ logWDA     &lt;dbl&gt; 9.041685, 8.899458, 8.190909, 9.139596, 9.467847, 7.665285,…\n$ logWEM     &lt;dbl&gt; 7.728856, 7.436617, 7.320527, 8.093157, 8.598589, 6.967909,…\n$ logWEE     &lt;dbl&gt; 8.073403, 7.935945, 7.392032, 8.353261, 8.909641, 7.081709,…\n$ BUS_ROOF_N &lt;chr&gt; \"B03\", \"B05\", \"B04\", \"B07\", \"B09\", \"B08\", \"TMNL\", \"B07\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"HOTEL GRAND PACIFIC\", \"ST JOSEPH'S CH\", \"BRAS BASAH CPLX\",…\n$ grid_id    &lt;int&gt; 3292, 3292, 3292, 3323, 3354, 3324, 3324, 3292, 3324, 3292,…\n$ busstops   &lt;int&gt; 8, 8, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7,…\n\n\n\n\n(d) Retrieve Geometry\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid, \n                           by = \"grid_id\")\n#origin_gridwgeom &lt;- st_as_sf(origin_gridwgeom)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-classification",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-classification",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.1 Data Classification",
    "text": "4.1 Data Classification\nDifferent classification schemes highlight areas with the highest and/or lowest values, while others create classes that result in a more uniform distribution of colors. When data is sharply skewed or has extreme outliers, it’s important to consider whether the goal is to emphasize those areas or to achieve a more even distribution of colors and sizes.\nThe main methods of data classification are: - Quantile: each class contains an equal number of features. It assigns the same number of data values to each class. There are no empty classes or classes with too few or too many values - Jenks/Natural breaks: seeks clumps of values that are clustered together in order to form categories that may reflect meaningful groupings of areas - Equal: divides the range of attribute values into equal-sized sub-ranges\nSince our variable is less skewed after log transformation, we can explore various classification methods for visualization. This approach may reveal interesting insights that were not immediately apparent before."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#plots",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#plots",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Plots",
    "text": "4.2 Plots\n\n4.2.1 Weekday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\n\nplotlogWDM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n\nplotlogWDM_q\n\n\n\n\n\n\n\nThe grids above are partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period:\n\nWest: BLK 821, BLK 252, Sunshine Place\nNorth: BLK 314\nNorth-East: BLK 477A, BLK 1, BLK 555, BLK 324\nEast: BLK 109, BLK 124, BLK 756\n\nThis is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nHigher passenger traffic were noted at the bus stops nearer to MRT stations such as Harbourfront Station, Farrer Road Station, Yio Chu Kang Station, and Admirality Station. A possible contributing factor could be the people who are transiting from taking the MRTs to buses to get to their destinations.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. This could potentially be due to the people commuting across the causeway from Malaysia into the Singapore borders.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_e\n\n\n\n\n\n\n\nThe map using equal intervals provided slightly different insights. We noted that the bus stop located near to MRT stations had higher levels of ridership. In particular, more trips originated from Tiong Bahru Station, Buona Vista Station, Tanah Merah Station, Admiralty Station, Harbourfront, and Woodleigh Station. Bus interchanges also appeared to be popular origins, i.e. Bukit Panjang Interchange and Joo Koon Interchange.\nIn general, more homogeneity is noted using the equal interval – the contrast between hexagon to hexagon is less obvious.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_j\n\n\n\n\n\n\n\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes. Higher bus ridership were spotted at bus stops within close proximity to MRT stations (Kranji Station, Buona Vista Station, Buangkok Station, Ranggung Station, Farrer Road Station, Stevens Station, Bedok Reservoir Station) and residential estates (Sunshine Place near Tengah, BLK 109 in Bedok, BLK 477A in Sengkang, Bef. BLK 629A in Woodlands, to name a few).\n\n\n\n\n\n4.2.2 Weekday Afternoon Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_q\n\n\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nBus stops in close proximity to MRT tations and popular bus stops in residential estatements remained high.\nMore trips originating from institutional areas: Opposite Ngee Ann Poly, Temasek Poly, NIE BLK 2, School of the Arts\nMore trips originating from industrial buildings/business parks: North Link Bldg, Aft Senoko Way, Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nMore trips originating from hospitals: Yishun Community Hospital, Changi General Hospital\nSeletar Camp also looked to have high passenger levels\nThe far West seemed to experience low ridership other than the bus stop opposite Tuas Link Station.\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_e\n\n\n\n\n\n\n\nNotably, there were higher concentration of passengers who boarded the bus at Serangoon Station, Harbourfront/VivoCity, Tiong Bahru Station, Admiralty Station, and Punggol Station during weekday afternoons according to the equal interval classification method.\nSimilar to the map for weekday morning peak period, the equal interval seemed to produce more homogeneous classifications.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_j\n\n\n\n\n\n\n\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas.\nIt also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method.\nAlternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\n\n4.2.3 Weekend/Holiday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_q\n\n\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nDuring the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. Buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends.\nBus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe bus stops with the highest boarding passengers are Sunshine Place, Opp BLK 271, BLK 252, Aft. Hasanah Mosque, Buona Vista Station, Harbourfront/Vivocity, Admiralty Station, BLK 555, Bedok Reservoir Station, BLK 22, BLK 109.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_e\n\n\n\n\n\n\n\nEqual interval classification highlighted the following bus stops to have the highest ridership during weekend/holiday morning peak period: Harbourfront/Vivocity, Tiong Bahru Station, Orchard Station/Lucky Plaza, Admirality Station, Aft. Punggol Road.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n4.2.4 Weekend/Holiday Evening\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_q\n\n\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods.\nSunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership.\nWoodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_e\n\n\n\n\n\n\n\nThe bus stops with higher traffic seem to be quite consistent across the different peak periods. This includes Woodlands Checkpoint, Kranji Station, Admiralty Station, Serangoon Station, Aft. Punggol Road, Bukit Panjang MRT, Yio Chu Kang Interchange.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#global-spatial-autocorrelation",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Global Spatial Autocorrelation",
    "text": "5.1 Global Spatial Autocorrelation\n\n5.1.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   22.89    0.00 1000.00 \n\n\nThe maximum nearest neighbour distance is 1000m, thus we will use threshold value of 1001m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 1001),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\n#kable(head(wm_fd,5))\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 266698 \nPercentage nonzero weights: 1.057466 \nAverage number of links: 53.10593 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  3   6   3   4   7   6  20  19  20  13  24  13  21  29  20  35  28  40  34  40 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n 24  52  45  33  39  48  26  44  31  30  31  52  48  39  35  55  48  49  83  55 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n 74  67  59  73  76  83  96  81  59  53 101 136  87 117 101  84 111  79 134 127 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n114 150  96 113 103 103 106  81  94 107  61  73  92  55  41  64  61  73  42  31 \n 81  82  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100 102 \n 40  32   9  30  30  26   9  19  14  21   6   9  12  15   8   4   4   6  13   5 \n3 least connected regions:\n2274 5021 5022 with 1 link\n5 most connected regions:\n3699 3700 3701 3702 3703 with 102 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 5 hexagons with 102 neighbours. We can also identify an average of 53 neighbours per hexagon using the distance-based weight matrix.\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1  2, 4, 5, 9, 10, 15, 32, 33\n2  1, 4, 5, 9, 10, 15, 32, 33\n3 5, 6, 7, 11, 12, 16, 17, 18\n                                                      wt grid_id busstops.x\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34          1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65          1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99          1\n  ORIGIN_BS WDA WDM WEE WEM   logWDM   logWDA   logWEM   logWEE BUS_ROOF_N\n1     25059 417  62  65   5 4.127134 6.033086 1.609438 4.174387        UNK\n2     25751 110  50  26  24 3.912023 4.700480 3.178054 3.258097       B02D\n3     26379 249  44  54  27 3.784190 5.517453 3.295837 3.988984        NIL\n             LOC_DESC busstops.y              area_hexagon_grid\n1   AFT TUAS STH BLVD          1 POLYGON ((3970.122 27925.48...\n2 BEF TUAS STH AVE 14          1 POLYGON ((4220.122 28358.49...\n3            YONG NAM          1 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_contiguity() of sfdep is used to identify the neighbours by using contiguity criteria. The output is a list of neighbours (i.e. nb).\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_contiguity(geo),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nsummary(wm_idw$nb)\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 107808 \nPercentage nonzero weights: 0.4274621 \nAverage number of links: 21.46714 \n6 regions with no links:\n1750 2274 3159 4675 4989 4994\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 \n  6  12  17  33  23  97  70  99  88  76 115 136 126 133 130 160 168 227 197 169 \n 20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39 \n159 174 251 240 213 195 222 210 183 187 124 115 104 110 111  39  54  56  11  17 \n 40  41  42  43  44  48 \n 55  62  13  17  10   8 \n12 least connected regions:\n1 32 62 736 3354 3355 4982 4990 5002 5003 5021 5022 with 1 link\n8 most connected regions:\n3048 3049 3050 3051 3052 3053 3054 3055 with 48 links\n\n\nUsing the inverse distance method resulted in 6 regions with no neighbours, this could be due to the spatial isolation of certain hexagons.\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method led to regions with no neighbours and is computationally intensive as each neighbour\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well.\n\n\ncentroid &lt;- st_centroid(origin_gridwgeom)\nplot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n\n\n\n#plot(wm_idw, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#computing-global-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#computing-global-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Computing Global Spatial Autocorrelation Statistics",
    "text": "5.2 Computing Global Spatial Autocorrelation Statistics\n\n5.2.1 Moran’s I\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing, using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed). H1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed with a seed number 1234. set.seed() function allows us to create reproducible results.\nNote: nsim arugment of global_moran_perm() refers to the number of simulations is nsim + 1, i.e., for nsim = 99, 100 simulations will be performed.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.094609, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.063584, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.095565, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.083812, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained).\n\n\n5.2.2 Geary’s C\n\n\n5.2.3 Spatial Correlogram"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.3 Local Spatial Autocorrelation Statistics",
    "text": "5.3 Local Spatial Autocorrelation Statistics\nGlobal spatial autocorrelation provides a broad overview of spatial clustering within a dataset, offering a single value that indicates whether similar values are generally clustered or dispersed across the entire study area. In contrast, local spatial autocorrelation delves into specific locations, identifying where clusters of similar values (hot spots or cold spots) or spatial outliers exist. While global metrics give an overall trend, local metrics provide detailed, location-specific insights, highlighting exact areas of significant spatial clustering or anomaly.\nThus, after we have established through statistical testing that spatial clustering of bus ridership occurs in Singapore, we now seek to detect clusters or outliers and discover if there are any hot or cold spots of high ridership using Local Spatial Autocorrelation Statistics.\n\n5.2.1 Local Moran’s I\nIn this section, we will perform Moran’s I statistics testing by using local_moran() of sfdep. The output of local_moran() is a sf data.frame, containing the columns below:\n\nii: local moran statistic\neii: expectation of local Moran’s I statistic\nvar_ii: variance of local Moran’s I statistic\nz_ii: standard deviation of local Moran’s I statistic\np_ii: p-value of local Moran’s I statistic using pnorm()\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value, based on crand.py of pysal\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nunnest() of tidyr package helps expand a list-column containing data frames into rows and columns.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\nlisa_WDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.190  0.00735 0.0204 1.28  0.201     0.02         0.01    -2.55     8.37\n2 0.190 -0.0100  0.0433 0.962 0.336     0.02         0.01    -5.72    42.9 \n3 0.186  0.00312 0.0459 0.853 0.394     0.02         0.01    -6.21    49.1 \n4 0.181  0.0166  0.0142 1.38  0.167     0.02         0.01    -2.06     5.79\n5 0.167  0.00919 0.0118 1.45  0.147     0.02         0.01    -2.18     7.71\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDA, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii     eii   var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0752 0.00345 0.00381  1.16  0.245     0.02         0.01    -1.92     4.44\n2 0.0795 0.00807 0.00673  0.870 0.384     0.04         0.02    -3.02    10.4 \n3 0.0734 0.00141 0.00811  0.799 0.424     0.08         0.04    -2.87     9.31\n4 0.0567 0.0145  0.00114  1.25  0.212     0.02         0.01    -3.00    12.6 \n5 0.0415 0.00794 0.000767 1.21  0.225     0.02         0.01    -2.80    11.0 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEM, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.143  0.000449 0.0154  1.15  0.252     0.04         0.02   -2.77     8.66 \n2 0.141  0.0126   0.00812 1.43  0.154     0.06         0.03   -0.884    0.201\n3 0.130 -0.0145   0.0446  0.684 0.494     0.02         0.01   -3.95    18.0  \n4 0.124  0.00189  0.0111  1.16  0.247     0.04         0.02   -2.96    11.3  \n5 0.115 -0.00534  0.0161  0.948 0.343     0.02         0.01   -5.03    33.2  \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEE, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0904 -0.0160   0.0277  0.639 0.523     0.04         0.02    -4.96    27.3 \n2 0.0924 -0.00619  0.0143  0.824 0.410     0.02         0.01    -2.83     8.51\n3 0.0809  0.00535  0.00947 0.777 0.437     0.14         0.07    -2.66     7.65\n4 0.0756  0.000552 0.00974 0.760 0.447     0.02         0.01    -4.97    30.6 \n5 0.0637  0.000789 0.00272 1.20  0.228     0.04         0.02    -2.01     4.58\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekday-afternoon-2",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekday-afternoon-2",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekday Afternoon",
    "text": "Weekday Afternoon"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-morning-2",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-morning-2",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekend/Holiday Morning",
    "text": "Weekend/Holiday Morning"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-evening-3",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-evening-3",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekend/Holiday Evening",
    "text": "Weekend/Holiday Evening"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#visualising-bus-ridership",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#visualising-bus-ridership",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Visualising Bus Ridership",
    "text": "4.2 Visualising Bus Ridership\nWe will visualise the spatial distribution of ridership for each peak period using a choropleth. This is performed using the code chunk below.\n\nWeekday Morning Peak PeriodWeekday Afternoon Peak PeriodWeekend/Holiday Morning Peak PeriodWeekend/Holiday Evening\n\n\n\n\nShow the code\ntmap_mode (\"plot\")\n\nplotlogWDM_q &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6) +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Quantile Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWDM_e &lt;-\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Equal Interval Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWDM_j &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Jenks Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n  \ntmap_arrange(plotlogWDM_q, plotlogWDM_e, plotlogWDM_j, asp=1, ncol=3)\n\n\n\n\n\nThe leftmost map above is partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period. This is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. Woodlands Checkpoint is one of Singapore’s two land border checkpoints, facilitating the movement of ground traffic between Singapore and Malaysia. This could potentially be due to the people commuting across the causeway between Malaysia and Singapore.\nThe map using equal intervals had more homogeneity – the contrast between hexagon to hexagon is less obvious. There appears to be more spots of dark blue, indicating more areas with high ridership.\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes.\n\n\n\n\nShow the code\ntmap_mode (\"plot\")\n\nplotlogWDA_q &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6) +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Quantile Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWDA_e &lt;-\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Equal Interval Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWDA_j &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Jenks Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n  \ntmap_arrange(plotlogWDA_q, plotlogWDA_e, plotlogWDA_j, asp=1, ncol=3)\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nMore trips originating from industrial/business parks: Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nSeletar Camp also looked to have high passenger levels\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\nUsing the Equal Interval classification, there were notably higher concentration of passengers trips across the island, producing more homogeneous classifications.\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas. It also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method. Alternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\nShow the code\ntmap_mode (\"plot\")\n\nplotlogWEM_q &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6) +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Quantile Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWEM_e &lt;-\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Equal Interval Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWEM_j &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Jenks Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n  \ntmap_arrange(plotlogWEM_q, plotlogWEM_e, plotlogWEM_j, asp=1, ncol=3)\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nThe map partitioned using the quantile intervals showed that during the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. This suggests that buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends. Bus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe map using interval classification looked more monochromatic, there is less contrast with a more uniform appearance. On the other hand, Jenk’s method identified more hot spots across the island than the other two methods.\n\n\n\n\nShow the code\ntmap_mode (\"plot\")\n\nplotlogWEE_q &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6) +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Quantile Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWEE_e &lt;-\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Equal Interval Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n\nplotlogWEE_j &lt;- \n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title=\"Jenks Classification\",\n            main.title.size = 0.7,\n            main.title.position = \"center\",\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = FALSE)\n  \ntmap_arrange(plotlogWEE_q, plotlogWEE_e, plotlogWEE_j, asp=1, ncol=3)\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods as witnessed in the first plot using the quantile classification method. Sunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership. Woodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\nUsing the equal interval classification method, the general areas of bus stops with higher traffic seem to be quite consistent across the different peak periods.\nThe Jenk’s method seems to suggest that hot spots are mostly congregated in the core of Singapore, with cold spots along the periphery of Singapore.\n\n\n\nWhile the choropleths were useful for quickly visualizing results, the different plots reveal that varying data classification methods can lead to different findings. To draw objective conclusions, we should supplement our initial findings with geospatial analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Notes from Class\n\n\n\n\n\n\nFor THE1:\n\nReproducibility: just need to change first line for another month\nChange chrome limit\nHexagons: bus stops in JB, 1 bus stop @ tip of SG causeway that will be cut off if we use MPSZ.\nHave to select spatial weights for analysis. Diff geo context and config will need to apply diff spatial weights.\n\n\nGravity Model we calculated this in HOE3! - Vi = push factor @ origin (can be 1 variable or multiple variables), Wj = pull factor @ destination, Sij = distance decay\nRetail Model - Bij = propensity / porbability that people will go or not go to a location"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#loading-package",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#loading-package",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "2.1 Loading Package",
    "text": "2.1 Loading Package\n\npacman::p_load(tmap, sf, sp, DT, \n               performance, reshape2,\n               ggpubr, tidyverse)\n\n\ntmap: thematic maps\nsf: handle geospatial data\nsp: older R package that has been replaced by sf\nDT: data tables\nperformance: statistical models\nreshape2: great grandfather of tidyr, can handle matrix. tidyverse works on data frames and cannot handle matrix well.\nggpubr: used to create multiple plots into 1\ntidyverse: compose of basic R packages for data science work."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#the-data",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#the-data",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "2.2 The Data",
    "text": "2.2 The Data\n\nGeospatial: mpsz.rds based on BusStop shapefile from LTA, MPSZ\nAspatial:\n\nod_data.rds based on weekday morning peak passenger flows at planning subzone level\npop.csv\n\n\n\nGeospatialAspatial\n\n\n\n#pop &lt;- read_csv(\"data/aspatial/pop.csv\")\n#respopagesex2022 &lt;- read_csv(\"data/aspatial/respopagesex2022.csv\")\n\n\n\nOutput should be saved as rds format\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#converting-from-sf-data.table-to-spatialpolygonsdataframe",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#converting-from-sf-data.table-to-spatialpolygonsdataframe",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "3.1 Converting from sf data.table to SpatialPolygonsDataFrame",
    "text": "3.1 Converting from sf data.table to SpatialPolygonsDataFrame\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n# same as:\n# mpsz_sz &lt;- mpsz %&gt;% \n#   as.Spatial()\n\n# to call: mpsz@data$column to pick up values\n\n\n#mpsz_sp_selected &lt;- mpsz_sp %&gt;% \n#  select(mpsz@data$SUBZONE_N)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#computing-the-distance-matrix",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#computing-the-distance-matrix",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "3.2 Computing the distance matrix",
    "text": "3.2 Computing the distance matrix\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n# longlat = TRUE = great circle\n# Large matrix size: 332*332=110224\n\nObservations:\n\nOutput dist is a matrix object class of R\nColumn heanders and row headers are not labeled with the planning subzone codes."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#labelling-column-and-row-heanders-of-a-distance-matrix",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#labelling-column-and-row-heanders-of-a-distance-matrix",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "3.3 Labelling column and row heanders of a distance matrix",
    "text": "3.3 Labelling column and row heanders of a distance matrix\nReplace columns and rows names with subzones names so we can create tibble data frame later. Data frame will help us understand data better.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#pivoting-distance-value-by-subzone_c",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#pivoting-distance-value-by-subzone_c",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "3.4 Pivoting distance value by SUBZONE_C",
    "text": "3.4 Pivoting distance value by SUBZONE_C\nBe mindful not to sort the data to maintain the sequence!\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\n\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\nObservations: Within-zone (intrazone) distance = 0."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#updating-intra-zonal-distances",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#updating-intra-zonal-distances",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "3.5 Updating intra-zonal distances",
    "text": "3.5 Updating intra-zonal distances\n\n# cached on memory, not saved in environment\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary() #to see what is the minimum distance\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\n50 is arbitruary, cannot overshoot the minimum. 175/2 (for each radius of the nucleus) = 80 (rounded down to 50\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, \n                        distPair$dist)\n\n\n# Check the result data.frame.\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n# Rename origin & destination fields\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nSave the dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#separating-intra-flow-from-passenger-volume-df",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#separating-intra-flow-from-passenger-volume-df",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "4.1 Separating intra-flow from passenger volume df",
    "text": "4.1 Separating intra-flow from passenger volume df\nAdd three new fields in flow_data dataframe\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-population-data",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-population-data",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "5.1 Importing population data",
    "text": "5.1 Importing population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "5.2 Geospatial Data Wrangling",
    "text": "5.2 Geospatial Data Wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-origin-attrbute",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-origin-attrbute",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "5.3 Preparing Origin Attrbute",
    "text": "5.3 Preparing Origin Attrbute\nPeople on their journey to school (pri & sec sch) / journey to work\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-destination-attribute",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-destination-attribute",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "5.4 Preparing destination attribute",
    "text": "5.4 Preparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\nwrite_rds(flow_data1, \"data/rds/SIM_data\")\n\nmorning = push factor is origin evening = pull factor is destination bc ppl want to go home"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex3/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#combining-passenger-volume-data-with-distance-value",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#combining-passenger-volume-data-with-distance-value",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "4.2 Combining passenger volume data with distance value",
    "text": "4.2 Combining passenger volume data with distance value\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nleft_join() of dplyr will be used to flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-the-modelling-data",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-the-modelling-data",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.1 Importing the modelling data",
    "text": "6.1 Importing the modelling data\n\nSIM_data &lt;- read_rds(\"data/rds/SIM_data.rds\")\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12 ORIGIN_AGE13_24 ORIGIN_AGE25_64\n Min.   :1   Min.   :  173.8   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2210  \n Median :1   Median : 6121.0   Median : 710   Median : 1400   Median : 7030  \n Mean   :1   Mean   : 6951.8   Mean   :1037   Mean   : 2278   Mean   :10536  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500   3rd Qu.: 3282   3rd Qu.:15830  \n Max.   :1   Max.   :26135.8   Max.   :6340   Max.   :16380   Max.   :74610  \n DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 250   1st Qu.:  460   1st Qu.: 2210  \n Median : 720   Median : 1430   Median : 7120  \n Mean   :1040   Mean   : 2305   Mean   :10648  \n 3rd Qu.:1500   3rd Qu.: 3290   3rd Qu.:15830  \n Max.   :6340   Max.   :16380   Max.   :74610"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#visualising-the-dependent-variable",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#visualising-the-dependent-variable",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.2 Visualising the dependent variable",
    "text": "6.2 Visualising the dependent variable\nDistribution of the dependent variable (i.e. TRIPS) by using histogram\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\nObservations: Distribution is highly skewed and not resemble bell shape or also known as normal distribution.\nRelation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nObservation: Notice that their relationship hardly resemble linear relationship.\nOn the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#distribution-of-the-dependent-variable-i.e.-trips-by-using-histogram",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#distribution-of-the-dependent-variable-i.e.-trips-by-using-histogram",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "Distribution of the dependent variable (i.e. TRIPS) by using histogram",
    "text": "Distribution of the dependent variable (i.e. TRIPS) by using histogram\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\nObservations: - Distribution is highly skewed and not resemble bell shape or also known as normal distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#relation-between-the-dependent-variable-and-one-of-the-key-independent-variable-in-spatial-interaction-model-namely-distance",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#relation-between-the-dependent-variable-and-one-of-the-key-independent-variable-in-spatial-interaction-model-namely-distance",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "Relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance",
    "text": "Relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nObservation: - Notice that their relationship hardly resemble linear relationship.\nOn the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#checking-for-variables-with-zero-values",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#checking-for-variables-with-zero-values",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.3 Checking for variables with zero values",
    "text": "6.3 Checking for variables with zero values\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nIn the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12 ORIGIN_AGE13_24 ORIGIN_AGE25_64\n Min.   :1   Min.   :  173.8   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2210  \n Median :1   Median : 6121.0   Median : 710   Median : 1400   Median : 7030  \n Mean   :1   Mean   : 6951.8   Mean   :1037   Mean   : 2278   Mean   :10536  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500   3rd Qu.: 3282   3rd Qu.:15830  \n Max.   :1   Max.   :26135.8   Max.   :6340   Max.   :16380   Max.   :74610  \n DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 250   1st Qu.:  460   1st Qu.: 2210  \n Median : 720   Median : 1430   Median : 7120  \n Mean   :1040   Mean   : 2305   Mean   :10648  \n 3rd Qu.:1500   3rd Qu.: 3290   3rd Qu.:15830  \n Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nObservations:\n\nVariables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64, DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nFeature engineering\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nCheck again:\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :1   Min.   :  173.8   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240.00   1st Qu.:  460.00  \n Median :1   Median : 6121.0   Median : 710.00   Median : 1400.00  \n Mean   :1   Mean   : 6951.8   Mean   :1036.73   Mean   : 2278.59  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500.00   3rd Qu.: 3282.50  \n Max.   :1   Max.   :26135.8   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2210.00   1st Qu.: 250.00   1st Qu.:  460.00   1st Qu.: 2210.00  \n Median : 7030.00   Median : 720.00   Median : 1430.00   Median : 7120.00  \n Mean   :10535.93   Mean   :1039.98   Mean   : 2305.33   Mean   :10647.95  \n 3rd Qu.:15830.00   3rd Qu.:1500.00   3rd Qu.: 3290.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nObservation: All the 0 values have been replaced by 0.99."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#unconstrained-spatial-interaction-model",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#unconstrained-spatial-interaction-model",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.4 Unconstrained Spatial Interaction Model",
    "text": "6.4 Unconstrained Spatial Interaction Model\nglm() have various kinds of regression. This example we use poisson & log.\nformula should be using a +\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            17.00287               0.21001               0.01289  \n           log(dist)  \n            -1.51785  \n\nDegrees of Freedom: 14273 Total (i.e. Null);  14270 Residual\nNull Deviance:      36120000 \nResidual Deviance: 19960000     AIC: 20040000\n\n\n\n\n\n\n\n\nImportant\n\n\n\ndistance = -1.5 definitely have to have -ve because it is inverse distance."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#r-squared-function",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#r-squared-function",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.5 R-squared function",
    "text": "6.5 R-squared function\nIn order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value.\n\n# Helper function\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\n# Compute R-squared\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1694734\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.446\n  adj. R2: 0.446\n\n\n0.446 is good. (why ah)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#origin-production-constrained-sim",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#origin-production-constrained-sim",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.6 Origin (Production) constrained SIM",
    "text": "6.6 Origin (Production) constrained SIM\nFit an origin constrained SIM by using the code3 chunk below\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.9309957  0.0054015  3689.887  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       0.6805710  0.0052686   129.175  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       0.3597850  0.0054884    65.554  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -0.1106566  0.0060027   -18.434  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -0.3140561  0.0067998   -46.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       0.0634425  0.0060258    10.528  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.1301580  0.0110298  -102.464  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -0.6330394  0.0102949   -61.491  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       0.1064915  0.0063450    16.784  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       0.5061899  0.0053889    93.931  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.3167911  0.0144870   -90.895  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.5103004  0.0127453  -118.499  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.3626004  0.0051433   264.929  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       0.9554084  0.0059655   160.156  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.1476190  0.0054278   211.433  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       2.0110410  0.0046344   433.940  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       1.0658940  0.0053976   197.477  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       1.2719222  0.0054774   232.213  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -0.5053039  0.0111553   -45.297  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -0.3556193  0.0102947   -34.544  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -0.3606399  0.0075473   -47.784  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       0.1357265  0.0061394    22.107  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       0.4101999  0.0058983    69.545  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -0.3418645  0.0070764   -48.310  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -0.2986750  0.0074073   -40.322  &lt; 2e-16 ***\nORIGIN_SZBKSZ06      -0.2637855  0.0068739   -38.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       0.5498323  0.0051476   106.813  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -0.0527393  0.0061457    -8.582  &lt; 2e-16 ***\nORIGIN_SZBKSZ09      -0.1564691  0.0067300   -23.249  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.7551329  0.0176599   -99.385  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -1.9493637  0.0213859   -91.152  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -2.9057732  0.0535995   -54.213  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.4672066  0.0254726   -57.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       0.1806064  0.0060563    29.821  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.4026549  0.0078244  -179.267  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -0.5976236  0.0063808   -93.660  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -0.5456513  0.0059061   -92.388  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -3.1095195  0.0188118  -165.297  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -3.0273827  0.0194319  -155.794  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -0.7378197  0.0066865  -110.345  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -0.9306150  0.0067188  -138.510  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.4137345  0.0101071  -139.876  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.7054195  0.0101582  -167.886  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -1.2418380  0.0076792  -161.714  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.3746537  0.0109769  -125.231  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -0.4339494  0.0069335   -62.587  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -0.9950458  0.0076302  -130.410  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -0.6544196  0.0068964   -94.892  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.5193747  0.0105329  -144.250  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.6536771  0.0180672   -91.529  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       0.1484355  0.0064734    22.930  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -0.3602094  0.0073902   -48.741  &lt; 2e-16 ***\nORIGIN_SZBPSZ03      -0.1567975  0.0072226   -21.709  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       0.4504873  0.0058418    77.115  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       0.5028646  0.0053682    93.675  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.0125668  0.0105638   -95.853  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -0.3859065  0.0098561   -39.154  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       0.1488497  0.0065504    22.724  &lt; 2e-16 ***\nORIGIN_SZBSSZ02       0.4269498  0.0055893    76.387  &lt; 2e-16 ***\nORIGIN_SZBSSZ03      -0.2437385  0.0062020   -39.300  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       0.1987940  0.0066672    29.817  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -0.4571546  0.0090784   -50.356  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -0.2697243  0.0077941   -34.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.0997236  0.0115225   -95.441  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.0053122  0.0132594   -75.819  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -1.0841201  0.0102242  -106.035  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.3134497  0.0158499  -145.960  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.1581618  0.0121161   -95.589  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.0805930  0.0577831   -18.701  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -0.8145372  0.0152638   -53.364  &lt; 2e-16 ***\nORIGIN_SZCHSZ01       0.0377079  0.0133240     2.830 0.004654 ** \nORIGIN_SZCHSZ02      -0.6209553  0.0096388   -64.422  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       1.6790244  0.0069559   241.381  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       0.0839586  0.0059934    14.008  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       0.4379511  0.0062289    70.309  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       0.7956950  0.0051892   153.335  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.2740323  0.0053165   239.637  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       0.9326213  0.0061807   150.893  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       0.3976273  0.0085639    46.431  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -0.7522917  0.0094655   -79.477  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.3937450  0.0153260   -90.940  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -0.7898683  0.0091016   -86.784  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       0.8451512  0.0051258   164.882  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.6573818  0.0166091   -99.788  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       0.9478181  0.0048182   196.716  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -0.2499753  0.0064632   -38.677  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       0.1350119  0.0069296    19.483  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.3868782  0.0192743   -71.955  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -3.7535792  0.0871325   -43.079  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -3.8462041  0.0840156   -45.780  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.9738127  0.0349241   -85.151  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.5175198  0.0110135  -137.787  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       0.2405712  0.0058742    40.954  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       0.1940241  0.0061989    31.300  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       1.0292572  0.0049028   209.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       0.9864552  0.0050898   193.811  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       0.3073609  0.0054307    56.597  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       0.3827293  0.0054555    70.154  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       0.2342580  0.0059240    39.544  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       0.8750090  0.0049639   176.275  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.1695280  0.0049468   236.420  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -0.0462411  0.0063805    -7.247 4.25e-13 ***\nORIGIN_SZHGSZ07       0.4488583  0.0055139    81.404  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       0.2236095  0.0061279    36.490  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -1.6376674  0.0084442  -193.941  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.9849025  0.0501042   -59.574  &lt; 2e-16 ***\nORIGIN_SZJESZ01       0.3926525  0.0056268    69.783  &lt; 2e-16 ***\nORIGIN_SZJESZ02       0.1230160  0.0056864    21.633  &lt; 2e-16 ***\nORIGIN_SZJESZ03       0.0188276  0.0061020     3.085 0.002032 ** \nORIGIN_SZJESZ04      -1.3611618  0.0117184  -116.156  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.0643662  0.0157083  -131.419  &lt; 2e-16 ***\nORIGIN_SZJESZ06       0.1556368  0.0055245    28.172  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.7664532  0.0133171  -132.646  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -0.9115981  0.0138203   -65.961  &lt; 2e-16 ***\nORIGIN_SZJESZ09       0.6121916  0.0060381   101.388  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.1953045  0.0233216   -51.253  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -1.4088748  0.0220921   -63.773  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       0.5759093  0.0077741    74.081  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       0.9769314  0.0053029   184.227  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.3242695  0.0049068   269.882  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       0.5621088  0.0057831    97.199  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.5744341  0.0146904  -107.174  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -0.9113320  0.0126913   -71.807  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.3083419  0.0357843   -64.507  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       2.0114225  0.0047956   419.429  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.9086705  0.0045255   421.759  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       0.2743166  0.0056908    48.204  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -0.6443386  0.0074521   -86.463  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -0.3990113  0.0067213   -59.366  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.1413876  0.0138405  -154.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -1.0913697  0.0121512   -89.816  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.6240764  0.1857405   -30.279  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.1885897  0.0096830  -122.750  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.7018593  0.0114317  -148.872  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -1.6659670  0.0446420   -37.318  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -1.1210505  0.0318834   -35.161  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -0.5096299  0.0116645   -43.691  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.9187039  0.0198291   -96.762  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -0.5260512  0.0094201   -55.844  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -0.2905084  0.0077974   -37.257  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       0.3342293  0.0063715    52.457  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.8337096  0.1105053   -34.693  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.9845040  0.0397028   -75.171  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.1812985  0.0249470  -127.522  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -0.9742991  0.0085424  -114.054  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -4.2086932  0.0579737   -72.597  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -4.5831822  0.0583494   -78.547  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       0.3186962  0.0052944    60.195  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -0.5321136  0.0073747   -72.154  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -0.9911852  0.0090560  -109.451  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -0.8329721  0.0099590   -83.640  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.1460777  0.0182401  -117.657  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -0.5604078  0.0151515   -36.987  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -0.4025139  0.0085135   -47.279  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       0.6975483  0.0055534   125.608  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.2175486  0.0051080   238.363  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       0.3895354  0.0069851    55.767  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -0.5572701  0.0134473   -41.441  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -0.9854214  0.0172337   -57.180  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -1.6991954  0.0472629   -35.952  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -2.2000217  0.0373580   -58.890  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -1.7086663  0.0260920   -65.486  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.5292867  0.0055102   277.535  &lt; 2e-16 ***\nORIGIN_SZPNSZ02       0.7457519  0.0127815    58.346  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.3659046  0.0216180   -63.184  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.0025379  0.0360655   -55.525  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -0.9157959  0.0320955   -28.533  &lt; 2e-16 ***\nORIGIN_SZPRSZ01       0.0522611  0.0139142     3.756 0.000173 ***\nORIGIN_SZPRSZ02       1.3063371  0.0053809   242.774  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       0.9963670  0.0054293   183.516  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -0.0300950  0.0088010    -3.419 0.000627 ***\nORIGIN_SZPRSZ05       1.6840313  0.0050839   331.245  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -0.8277202  0.0131296   -63.042  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.1698449  0.0177362  -122.340  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       0.4559353  0.0072609    62.793  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -0.3517047  0.0078770   -44.650  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -0.8199353  0.0071544  -114.605  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -0.2457614  0.0065555   -37.490  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.2216614  0.0084050  -145.349  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -0.7219952  0.0072360   -99.778  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -0.6729363  0.0076658   -87.784  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.4497690  0.0109365  -132.563  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -0.2770151  0.0070193   -39.465  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -0.6157554  0.0078739   -78.202  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -0.3091547  0.0075471   -40.963  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.9698881  0.0151247  -130.243  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -2.6449643  0.0205857  -128.485  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -0.3754107  0.0088433   -42.452  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.6537473  0.0134378  -123.067  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -0.3435351  0.0131956   -26.034  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.7104390  0.0141179  -121.154  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -1.1250727  0.0094909  -118.542  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.0220116  0.0339694   -88.963  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -3.6040075  0.0297641  -121.086  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.2345594  0.0259149  -124.814  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.6900313  0.0575908   -64.073  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.9527570  0.0178582  -165.344  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       0.0238445  0.0078563     3.035 0.002405 ** \nORIGIN_SZSBSZ02      -0.5780602  0.0093054   -62.121  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       0.8961719  0.0054586   164.175  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       0.8421798  0.0061888   136.080  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -0.1682984  0.0078342   -21.482  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.1482701  0.0196421   -58.460  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -0.8830317  0.0160709   -54.946  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.1039492  0.0174602   -63.226  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -0.5946691  0.0101961   -58.323  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.1144933  0.0050948   218.749  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.1058963  0.0049026   225.574  &lt; 2e-16 ***\nORIGIN_SZSESZ04       0.7427975  0.0056948   130.433  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -0.2812684  0.0069596   -40.414  &lt; 2e-16 ***\nORIGIN_SZSESZ06       0.8168315  0.0055800   146.387  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.2842043  0.0231232   -98.784  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -0.7313790  0.0098957   -73.909  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.1185406  0.0110919  -100.843  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       0.1752618  0.0060508    28.965  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       0.3764395  0.0056165    67.023  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.7203916  0.0118945  -144.637  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       0.4630857  0.0052886    87.563  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -0.7051233  0.0073133   -96.417  &lt; 2e-16 ***\nORIGIN_SZSKSZ01       0.2053928  0.0100710    20.395  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       1.2630428  0.0063490   198.935  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -0.3035297  0.0096788   -31.360  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -1.7952886  0.0359225   -49.977  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -0.3836861  0.0176686   -21.716  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -2.5916326  0.0348001   -74.472  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -0.2251549  0.0088517   -25.436  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.9590365  0.0173638  -170.414  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -1.9639893  0.0570321   -34.437  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.7281304  0.0272797   -63.349  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.7837906  0.0343179   -81.118  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.1800693  0.0205491  -106.091  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       0.8228136  0.0066824   123.131  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.3174781  0.0044978   515.243  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.7061757  0.0048615   350.957  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       1.2407899  0.0058389   212.504  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -0.1000526  0.0124079    -8.064 7.41e-16 ***\nORIGIN_SZTNSZ01      -2.0347519  0.0139596  -145.760  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.8682671  0.0107901  -173.146  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.1737183  0.0146759  -148.115  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -0.5006452  0.0081501   -61.428  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -0.6722487  0.0075606   -88.914  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       0.4552916  0.0050191    90.711  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -0.7865781  0.0072250  -108.869  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -0.7049044  0.0066456  -106.071  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -0.5574925  0.0070366   -79.227  &lt; 2e-16 ***\nORIGIN_SZTPSZ06      -0.4247282  0.0068709   -61.815  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -0.2846984  0.0071030   -40.081  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.0898051  0.0110046   -99.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -0.8092746  0.0079160  -102.232  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -0.9332072  0.0086809  -107.502  &lt; 2e-16 ***\nORIGIN_SZTPSZ11      -0.0421981  0.0064343    -6.558 5.44e-11 ***\nORIGIN_SZTPSZ12      -0.6330081  0.0078324   -80.819  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -1.7650409  0.0517357   -34.116  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       1.1707267  0.0094178   124.310  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       0.6581679  0.0095894    68.635  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       0.8736493  0.0104965    83.233  &lt; 2e-16 ***\nORIGIN_SZTSSZ05       0.0957248  0.0178709     5.356 8.49e-08 ***\nORIGIN_SZTSSZ06       1.7581609  0.0206810    85.013  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       0.8097950  0.0105622    76.669  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -1.9966163  0.0345747   -57.748  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -5.0687420  0.1474971   -34.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.4926003  0.0047216   316.124  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       0.9916597  0.0055755   177.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       1.5918065  0.0052180   305.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.3717152  0.0060516   226.669  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       0.6700111  0.0062287   107.569  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       0.8115996  0.0060947   133.165  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -0.6488914  0.0093567   -69.351  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -0.3610234  0.0096440   -37.435  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.4445461  0.0052279   276.317  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -0.2039272  0.0069548   -29.322  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       0.8707707  0.0058957   147.697  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.8348842  0.0050377   364.231  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       1.0780641  0.0052960   203.564  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       0.3222765  0.0069700    46.237  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -0.4424689  0.0124866   -35.435  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.0267883  0.0155821   -65.895  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       0.1833117  0.0070935    25.842  &lt; 2e-16 ***\nORIGIN_SZYSSZ09       1.0766070  0.0050451   213.396  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  0.0295428  0.0001051   280.998  &lt; 2e-16 ***\nlog(dist)            -1.7024691  0.0004625 -3681.042  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12983718  on 13993  degrees of freedom\nAIC: 13068835\n\nNumber of Fisher Scoring iterations: 6\n\n\nExamine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4029115"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#destination-constrained",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#destination-constrained",
    "title": "In-Class Exercise 3: Processing and Visualising Flow Data",
    "section": "6.7 Destination Constrained",
    "text": "6.7 Destination Constrained\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.4822997  0.0050784  3836.298  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1263056  0.0049743    25.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.0421788  0.0049859     8.460  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -1.1668479  0.0074254  -157.143  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.2586639  0.0075854  -165.931  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -1.1414791  0.0073474  -155.359  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.5565804  0.0109476  -142.185  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.3990754  0.0074159   -53.813  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -1.0109118  0.0076802  -131.626  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.0159285  0.0051765     3.077  0.00209 ** \nDESTIN_SZAMSZ11      -0.3653273  0.0094866   -38.510  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.5297606  0.0053243    99.500  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       1.0394822  0.0044226   235.037  &lt; 2e-16 ***\nDESTIN_SZBDSZ02       0.1956964  0.0059564    32.855  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.3209267  0.0053718    59.742  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.2429874  0.0043104   288.370  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.8535842  0.0046360   184.122  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.5181443  0.0053736    96.423  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.5849371  0.0110468   -52.951  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.2871050  0.0128623  -100.068  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0633560  0.0077771  -136.730  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.4065316  0.0066712   -60.938  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.6815674  0.0066509  -102.477  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.4185485  0.0058306   -71.785  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8887654  0.0073867  -120.319  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.9436078  0.0068625  -137.501  &lt; 2e-16 ***\nDESTIN_SZBKSZ07      -0.0067325  0.0048408    -1.391  0.16430    \nDESTIN_SZBKSZ08      -1.2680903  0.0079177  -160.160  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.0350151  0.0054287    -6.450 1.12e-10 ***\nDESTIN_SZBLSZ01      -0.3045203  0.0081978   -37.146  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6432424  0.0074449    86.400  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.9595113  0.0084705   231.333  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0149756  0.0172081     0.870  0.38415    \nDESTIN_SZBMSZ01      -0.0378127  0.0055294    -6.838 8.00e-12 ***\nDESTIN_SZBMSZ02      -0.8458055  0.0054043  -156.505  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -1.1334399  0.0063720  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -1.1164759  0.0057743  -193.353  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -1.1078742  0.0078703  -140.766  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.2787234  0.0155126  -146.895  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.2739089  0.0051924   -52.752  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.6825978  0.0071842  -234.209  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -3.0047801  0.0159980  -187.823  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -2.2232689  0.0096907  -229.423  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.9657136  0.0086445  -227.394  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.5359286  0.0089658  -171.310  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5657561  0.0059960   -94.355  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.6904858  0.0084858  -199.214  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.5268383  0.0079959  -190.953  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.2045600  0.0130872  -168.452  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.2992381  0.0184895  -124.353  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.8549497  0.0065168  -131.191  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.7470549  0.0095751  -182.457  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.4015145  0.0090888  -154.203  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.5250632  0.0066496   -78.962  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3413171  0.0046404    73.553  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.8569188  0.0090795   -94.380  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.0751284  0.0089704    -8.375  &lt; 2e-16 ***\nDESTIN_SZBSSZ01       0.1015228  0.0055735    18.215  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7066412  0.0063845  -110.682  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1622730  0.0046689    34.756  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.5470615  0.0047984   114.009  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.1393371  0.0078266   -17.803  &lt; 2e-16 ***\nDESTIN_SZBTSZ03       0.1474771  0.0059428    24.816  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.2857827  0.0122000  -105.392  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.2629188  0.0081769   -32.154  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8319920  0.0081401  -102.209  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.8829448  0.0121227  -155.324  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.5732123  0.0116752  -134.748  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -3.5334327  0.3333510   -10.600  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.2129306  0.0093782   -22.705  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -0.1494972  0.0113078   -13.221  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0041774  0.0063195     0.661  0.50860    \nDESTIN_SZCHSZ03       2.5565450  0.0046495   549.857  &lt; 2e-16 ***\nDESTIN_SZCKSZ01       0.0489719  0.0053801     9.102  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.3548993  0.0060671   -58.496  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.5386351  0.0044913   119.928  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.4425512  0.0073837   -59.936  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4092591  0.0077267   -52.967  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.2207041  0.0074252    29.724  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.2851460  0.0052362    54.457  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -1.9270528  0.0147688  -130.482  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.6266521  0.0086780   -72.212  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1335581  0.0054216   -24.634  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -0.8912963  0.0096015   -92.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1781234  0.0048150    36.993  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5609619  0.0062277   -90.075  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.3875308  0.0068390   -56.665  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.2539453  0.0072623    34.968  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -2.5036295  0.0373421   -67.046  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -0.8956407  0.0149971   -59.721  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.6562176  0.0175441   -94.403  &lt; 2e-16 ***\nDESTIN_SZGLSZ01      -0.2716152  0.0056553   -48.029  &lt; 2e-16 ***\nDESTIN_SZGLSZ02      -0.1735665  0.0055548   -31.246  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.7029507  0.0044934   156.441  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.5788027  0.0045449   127.351  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.6865291  0.0045131   152.118  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.3275950  0.0043866    74.681  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.6326974  0.0063517   -99.610  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0597982  0.0073914  -143.382  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2267013  0.0052178   -43.448  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.3063050  0.0055452   -55.238  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7483961  0.0065544  -114.182  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.1096958  0.0051309    21.379  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.1374201  0.0056692   -24.240  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.0775400  0.0060230    12.874  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.3017475  0.0289292  -114.132  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0489065  0.0057246    -8.543  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5101614  0.0060074   -84.921  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5328921  0.0064129   -83.097  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.7348953  0.0082249   -89.351  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -1.0864570  0.0111740   -97.231  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.2407920  0.0046801    51.451  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1523093  0.0090103  -127.888  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.4627356  0.0094529   -48.952  &lt; 2e-16 ***\nDESTIN_SZJESZ09       0.0528616  0.0068126     7.759 8.53e-15 ***\nDESTIN_SZJESZ10       1.0240660  0.0084045   121.848  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.7875517  0.0076251   103.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.1533418  0.0076198   -20.124  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.0011019  0.0059389    -0.186  0.85280    \nDESTIN_SZJWSZ03       0.9063789  0.0046747   193.892  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.7019286  0.0049743   141.112  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.5197057  0.0072971   -71.220  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3350986  0.0061171    54.780  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.5961960  0.0328336   -18.158  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.8054662  0.0056006   143.819  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.5860146  0.0040282   393.723  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6500838  0.0063560  -102.279  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7039434  0.0064465  -109.197  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.1972384  0.0075577  -158.413  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7172228  0.0097573  -175.993  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.6042386  0.0093730   -64.466  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -3.0201496  0.0389503   -77.539  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.1522413  0.0076607  -150.409  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6977825  0.0057610  -121.122  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -0.6895952  0.0268661   -25.668  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -0.7155951  0.0228203   -31.358  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -0.8153643  0.0123003   -66.288  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.7745226  0.0301326   -92.077  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -0.5492095  0.0087198   -62.984  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.6104744  0.0069346   -88.033  &lt; 2e-16 ***\nDESTIN_SZMPSZ03       0.2775047  0.0054964    50.489  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.6322870  0.0214943  -122.464  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -4.0762008  0.0531046   -76.758  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -1.9765545  0.0125659  -157.296  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.4563069  0.0085433  -170.462  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -2.0125598  0.0270737   -74.336  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0145357  0.0504986   -59.695  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4693625  0.0053866   -87.135  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4525631  0.0060428   -74.894  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.4821492  0.0064725   -74.492  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -1.8929756  0.0128397  -147.432  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.4501752  0.0099737  -145.400  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.2305867  0.0174321   -70.593  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.8232919  0.0080153  -102.715  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.2138480  0.0050850    42.054  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1045757  0.0053579    19.518  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.7542450  0.0088883   -84.858  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0098642  0.0080428    -1.226  0.22003    \nDESTIN_SZPLSZ02      -1.2630412  0.0152594   -82.771  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1554479  0.0108611   -14.312  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -1.5505819  0.0114768  -135.105  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.2417805  0.0130391   -18.543  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       0.7926715  0.0073628   107.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       2.1914920  0.0073537   298.013  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       1.0246845  0.0086874   117.951  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       2.5522612  0.0091789   278.057  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       1.7995301  0.0138562   129.872  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6576686  0.0096037   -68.481  &lt; 2e-16 ***\nDESTIN_SZPRSZ02       0.3113532  0.0059851    52.021  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.9255296  0.0044779   206.687  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.0028578  0.0093218    -0.307  0.75917    \nDESTIN_SZPRSZ05       0.2457863  0.0058261    42.187  &lt; 2e-16 ***\nDESTIN_SZPRSZ06       0.3692137  0.0064542    57.205  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.6733306  0.0138440  -120.871  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.2221048  0.0074846   -29.675  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.0185488  0.0093179  -109.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.2802688  0.0081670  -156.761  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -1.3322708  0.0079106  -168.415  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1803631  0.0077366  -152.568  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -1.2215818  0.0072829  -167.734  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.3213145  0.0074858  -176.509  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6426306  0.0123347  -133.171  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.2224169  0.0058405   -38.082  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.8142678  0.0069796  -116.665  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.1090496  0.0062573   -17.428  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0108951  0.0061145    -1.782  0.07477 .  \nDESTIN_SZQTSZ12      -0.8582515  0.0090243   -95.105  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1834409  0.0065231    28.122  &lt; 2e-16 ***\nDESTIN_SZQTSZ14       0.1994454  0.0073615    27.093  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.6740197  0.0088699    75.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.7746427  0.0079375   -97.593  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -1.4394098  0.0209931   -68.566  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6060495  0.0175759  -148.274  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.5823769  0.0354706   -72.803  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5890601  0.0152644  -169.614  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -2.2277482  0.0165661  -134.477  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.8610445  0.0298251  -129.456  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -1.2035529  0.0103954  -115.777  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.0267199  0.0085239  -120.452  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.5977382  0.0050336   118.750  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.5362769  0.0060573    88.534  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -1.0440525  0.0089622  -116.495  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -1.3939595  0.0246679   -56.509  &lt; 2e-16 ***\nDESTIN_SZSBSZ07       0.1029116  0.0235414     4.372 1.23e-05 ***\nDESTIN_SZSBSZ08       1.3564902  0.0060529   224.105  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.4573712  0.0056585    80.829  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1553609  0.0056716   -27.393  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5412776  0.0043801   123.576  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6382091  0.0065411   -97.568  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3332093  0.0055002   -60.581  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.3085951  0.0072340   -42.659  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.6237684  0.0245753  -106.764  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.1062372  0.0066634   -15.943  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0475568  0.0058908    -8.073 6.85e-16 ***\nDESTIN_SZSGSZ03      -0.2118402  0.0055056   -38.477  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.1099618  0.0054841   -20.051  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.1556963  0.0113821  -189.394  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4416352  0.0043842   100.734  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3949335  0.0059250   -66.655  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.2847094  0.0288610   -44.514  &lt; 2e-16 ***\nDESTIN_SZSKSZ01       0.3089834  0.0082924    37.261  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       1.4139309  0.0059981   235.729  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.2427688  0.0067373    36.034  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.2527488  0.0161286   -15.671  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.6046051  0.0122766    49.249  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3927387  0.0099790   -39.356  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.5942110  0.0086225   -68.914  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.6855766  0.0138707  -193.615  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -3.2750084  0.0402668   -81.333  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.7964408  0.0261810   -68.616  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.6323994  0.0241831  -108.853  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.9444390  0.0166052  -117.098  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.3856054  0.0063086    61.123  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.8586526  0.0039229   473.790  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       1.2601385  0.0044018   286.278  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       1.5884327  0.0043362   366.316  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       1.0377553  0.0063271   164.018  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.9954275  0.0080345  -123.895  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.1032696  0.0109228  -192.557  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.0044892  0.0129215  -155.128  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -0.9750326  0.0081677  -119.377  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7788383  0.0068769  -113.254  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.2866080  0.0042843    66.898  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.8749841  0.0065470  -133.646  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.6852792  0.0081488  -206.812  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -1.3721346  0.0068230  -201.104  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.7832133  0.0069164  -113.239  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.3109126  0.0130830  -176.635  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.6406531  0.0104897  -156.406  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5636273  0.0076848   -73.343  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.5640843  0.0099984  -156.433  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3700482  0.0059834   -61.846  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8828228  0.0072302  -122.102  &lt; 2e-16 ***\nDESTIN_SZTSSZ01       0.3529526  0.0221887    15.907  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0265792  0.0153515    66.871  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.9647347  0.0092388   212.662  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.8649836  0.0089976   207.275  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       2.8437058  0.0085738   331.673  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       3.4238870  0.0161304   212.263  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       2.9550693  0.0051690   571.689  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.8214103  0.0129213   -63.570  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.7393427  0.0347472   -50.057  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.3424417  0.0039957   335.972  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2103694  0.0068601   -30.666  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       0.8268551  0.0051363   160.983  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.0643997  0.0079076    -8.144 3.82e-16 ***\nDESTIN_SZWDSZ05       0.0451985  0.0075732     5.968 2.40e-09 ***\nDESTIN_SZWDSZ06       0.6981330  0.0051936   134.423  &lt; 2e-16 ***\nDESTIN_SZWDSZ07      -0.0403233  0.0067749    -5.952 2.65e-09 ***\nDESTIN_SZWDSZ08       0.2850631  0.0069225    41.179  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       1.3016106  0.0050365   258.433  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       0.7598564  0.0044144   172.133  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2648061  0.0058239    45.469  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0412163  0.0068337    -6.031 1.63e-09 ***\nDESTIN_SZYSSZ04      -0.0561054  0.0060829    -9.223  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -0.9970159  0.0121827   -81.839  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.3808376  0.0125738  -109.819  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.7128364  0.0165296   -43.125  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.9409510  0.0045886   205.064  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3738436  0.0047971    77.930  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.1928847  0.0001667  1157.214  &lt; 2e-16 ***\nlog(dist)            -1.7828141  0.0004794 -3718.501  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12319763  on 13992  degrees of freedom\nAIC: 12404881\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.496166"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Global Spatial Autocorrelation Statistics",
    "text": "5.2 Global Spatial Autocorrelation Statistics\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing with the adaptive weight matrix (i.e. wm_ad), using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed). H1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed using the original and logged values with a seed number 1234. set.seed() function allows us to create reproducible results.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.19938, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Variable\n\n\nShow the code\ngmp_logWDM &lt;- global_moran_perm(wm_ad$logWDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.5159, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.059528, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWDA &lt;- global_moran_perm(wm_ad$logWDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.35711, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15158, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWEM &lt;- global_moran_perm(wm_ad$logWEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.49385, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.097321, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nLog-Transformed Data\n\n\nShow the code\ngmp_logWEE &lt;- global_moran_perm(wm_ad$logWEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.40407, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained). The higher Moran’s I values for logged-transformed variables suggests a higher level of clustering compared to the original ridership values."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#spatial-weights-matrix",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#spatial-weights-matrix",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Spatial Weights Matrix",
    "text": "5.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  500.0   500.0   500.0   503.4   500.0  2291.3 \n\n\nThe maximum nearest neighbour distance is 2291.3m, thus we will use threshold value of 2292m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 2992),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 1503 \nNumber of nonzero links: 106746 \nPercentage nonzero weights: 4.725346 \nAverage number of links: 71.02196 \nLink number distribution:\n\n  1   2   4   9  10  11  12  13  14  15  16  17  19  20  21  22  23  24  25  26 \n  1   1   1   4   2   2   3   1   2   3   3   1   2   2   1   1   6   5   3   3 \n 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46 \n  8   9   4   3   7   2   7   6   4   9   9   5  13  10   7   9   9  12  13  16 \n 47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 \n 15  11  13  19  18  15  19  19  24  16  12  22  20  29  24  25   9  33  27  15 \n 67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86 \n 20  24  21  24  26  23  24  20  30  19  20  24  23  22  32  29  20  23  26  33 \n 87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 \n 29  30  31  31  25  24  22  23  18  27  18  26  20  13  17  12  16   6  14   7 \n107 108 109 110 \n  5   6   3   3 \n1 least connected region:\n1503 with 1 link\n3 most connected regions:\n1013 1024 1050 with 110 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 3 well-connected hexagons with 110 neighbours. We can also identify an average of 71 neighbours per hexagon using the distance-based weight matrix.\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 13 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1   2, 4, 5, 8, 9, 12, 22, 23\n2   1, 4, 5, 8, 9, 12, 22, 23\n3 5, 6, 9, 10, 13, 14, 16, 17\n                                                      wt grid_id busstops\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34        1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65        1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99        1\n             LOC_DESC WDA WDM WEM WEE   logWDM   logWDA   logWEM   logWEE\n1   AFT TUAS STH BLVD 417  62   5  65 4.127134 6.033086 1.609438 4.174387\n2 BEF TUAS STH AVE 14 110  50  24  26 3.912023 4.700480 3.178054 3.258097\n3            YONG NAM 249  44  27  54 3.784190 5.517453 3.295837 3.988984\n               area_hexagon_grid\n1 POLYGON ((3970.122 27925.48...\n2 POLYGON ((4220.122 28358.49...\n3 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\nFor our analysis, we will set the number of neighbours to 8.\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_knn(geo,\n                     k=8),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nhead(wm_idw, n=3)\n\nSimple feature collection with 3 features and 13 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1   2, 4, 5, 8, 9, 12, 22, 23\n2   1, 4, 5, 8, 9, 12, 22, 23\n3 5, 6, 9, 10, 13, 14, 16, 17\n                                                                                                             wts\n1 0.0020000000, 0.0011547005, 0.0004364358, 0.0007559289, 0.0005000000, 0.0005547002, 0.0005547002, 0.0004588315\n2 0.0020000000, 0.0020000000, 0.0005547002, 0.0011547005, 0.0006666667, 0.0007559289, 0.0006666667, 0.0005773503\n3 0.0020000000, 0.0020000000, 0.0010000000, 0.0020000000, 0.0011547005, 0.0011547005, 0.0007559289, 0.0010000000\n  grid_id busstops            LOC_DESC WDA WDM WEM WEE   logWDM   logWDA\n1      34        1   AFT TUAS STH BLVD 417  62   5  65 4.127134 6.033086\n2      65        1 BEF TUAS STH AVE 14 110  50  24  26 3.912023 4.700480\n3      99        1            YONG NAM 249  44  27  54 3.784190 5.517453\n    logWEM   logWEE              area_hexagon_grid\n1 1.609438 4.174387 POLYGON ((3970.122 27925.48...\n2 3.178054 3.258097 POLYGON ((4220.122 28358.49...\n3 3.295837 3.988984 POLYGON ((4470.122 30523.55...\n\n\nThe inverse distance approach is best suited for continuous data or for modeling scenarios where spatial proximity increases the likelihood of interaction or influence between two features. Nevertheless, this method treats every feature as a potential neighbor to every other feature, which can lead to a significant computational burden, especially in the case of large datasets where the volume of calculations required becomes substantial.\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method is computationally intensive as each feature is potentially a neighbour of every other feature.\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods.\nHedonic pricing models help us understand various factors influence the price of a condo. In essence, it breaks down the price into components that are related to the attributes of the property. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-geospatial-data",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Importing geospatial data",
    "text": "5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nObservation: - mpsz = A simple feature object.\n\nThe geometry type is multipolygon\nMPSZ simple feature object does not have EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#updating-crs-information",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.2 Updating CRS information",
    "text": "5.2 Updating CRS information\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, we will reveal the extent (rectangular boundary) of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Importing the aspatial data",
    "text": "6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale &lt;- read_csv('data/aspatial/Condo_resale_2015.csv')\n\nThe codes chunks below uses glimpse() to display the data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nSee the x-y coordinates column:\n\nhead(condo_resale[, c(\"LONGITUDE\", \"LATITUDE\")], n=5)\n\n# A tibble: 5 × 2\n  LONGITUDE LATITUDE\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      104.     1.29\n2      104.     1.33\n3      104.     1.31\n4      104.     1.31\n5      104.     1.32\n\n\nNext, summary() of base R is used to display the summary statistics of condo_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c('LONGITUDE', 'LATITUDE'),\n                            crs = 4326) %&gt;% # World Geodetic System; represents coords in lat and lon; global standard\n  st_transform(crs= 3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7 Exploratory Data Analysis (EDA)",
    "text": "7 Exploratory Data Analysis (EDA)\nObjective: to use statistical graphics functions of ggplot2 package to perform EDA."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.1 EDA using statistical graphics",
    "text": "7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n\nShow the code\nggplot(data=condo_resale.sf, \n       aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  scale_x_continuous(labels = scales::comma)\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed distribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;% \n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the LOG_SELLING_PRICE using the code chunk below.\n\n\nShow the code\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\") \n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.2 Multiple Histogram Plots distribution of variables",
    "text": "7.2 Multiple Histogram Plots distribution of variables\nIn this section, we will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\n\nShow the code\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#drawing-statistical-point-map",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.3 Drawing Statistical Point Map",
    "text": "7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\n\ntmap_mode(\"plot\")\n#tmap_mode(\"view\")\n\n#tm_basemap(\"OneMapSG.Grey\") +\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\n  tm_fill(alpha=0.6)+\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.1 Simple Linear Regression Method",
    "text": "8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, \n                data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\n\nattributes(condo.slr)\n\n$names\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n$class\n[1] \"lm\"\n\n\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nSummaryANOVA\n\n\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n*y = -258121.1 + 14719x1*\nR-squared of 0.4518: the independent variable is able to explain about 45% of the variation in the dependent variable, resale prices.\np-value: is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\n\n\nanova(condo.slr)\n\nAnalysis of Variance Table\n\nResponse: SELLING_PRICE\n            Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    \nAREA_SQM     1 1.0504e+15 1.0504e+15    1182 &lt; 2.2e-16 ***\nResiduals 1434 1.2743e+15 8.8861e+11                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n    scale_y_continuous(labels = scales::comma)+\n  geom_smooth(method = lm)\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.2 Multiple Linear Regression Method",
    "text": "8.2 Multiple Linear Regression Method\n\n8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. We will be using the corrplot package.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\nnames(condo_resale)\n\n [1] \"LATITUDE\"             \"LONGITUDE\"            \"POSTCODE\"            \n [4] \"SELLING_PRICE\"        \"AREA_SQM\"             \"AGE\"                 \n [7] \"PROX_CBD\"             \"PROX_CHILDCARE\"       \"PROX_ELDERLYCARE\"    \n[10] \"PROX_URA_GROWTH_AREA\" \"PROX_HAWKER_MARKET\"   \"PROX_KINDERGARTEN\"   \n[13] \"PROX_MRT\"             \"PROX_PARK\"            \"PROX_PRIMARY_SCH\"    \n[16] \"PROX_TOP_PRIMARY_SCH\" \"PROX_SHOPPING_MALL\"   \"PROX_SUPERMARKET\"    \n[19] \"PROX_BUS_STOP\"        \"NO_Of_UNITS\"          \"FAMILY_FRIENDLY\"     \n[22] \"FREEHOLD\"             \"LEASEHOLD_99YR\"      \n\n\ncor(condo_resale[,5:23]) gives a matrix array of the correlation values between each pair of variables.\n\ncorrplot(cor(condo_resale[, 5:23]), \n         diag = FALSE, # whether display the correlation coefficients on the principal diagonal.\n         order = \"AOE\", # ordering method of the correlation matrix (original, angular order/AOE, FPC, hclust, alphabet)\n         tl.pos = \"td\", # position of text labels\n         tl.cex = 0.5, # size of text label (variable names)\n         tl.col=\"black\",\n         tl.srt=45,\n         method = \"number\", # other visualisation methods: color, pie, circle\n         type = \"upper\") # layouts: full, upper, lower\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE” (angular order), “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model, LEASE_99YEAR has been excluded.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\nStatistically insignificant (&gt;0.05): PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_TOP_PRIMARY_SCH, PROX_SUPERMARKET."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.4 Preparing Publication Quality Table: olsrr method",
    "text": "8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing variables above which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.5 Preparing Publication Quality Table: gtsummary method",
    "text": "8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note( # Adds customised options, eg adjusted R2, AIC, p-values, alpha\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\n\n\n\nVIF Interpretation\n\n\n\n&lt;5: low correlation of that predictor with other predictors.\n5-10: moderate correlation\n&gt;10: high, not tolerable correlation of model predictors\n\n\n\n\n8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nObservations: Most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#testing-for-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#testing-for-spatial-autocorrelation",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.5.4 Testing for Spatial Autocorrelation",
    "text": "8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\")  +\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1438876 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#computing-fixed-bandwith",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#computing-fixed-bandwith",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.1 Computing fixed bandwith",
    "text": "9.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\n2 approaches to determine the stopping rule: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nTBC…"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/THE2.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/THE2.html",
    "title": "Take-home Exercise 2: Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows",
    "section": "",
    "text": "AimTasks\n\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\n\n\nDerive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the traffic analysis zone (TAZ).\nWith reference to the time intervals provided in the table below, construct an O-D matrix of commuter flows for a time interval of your choice by integrating Passenger Volume by Origin Destination Bus Stops and Bus Stop Location from LTA DataMall. The O-D matrix must be aggregated at the analytics hexagon level\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the O-D flows of the passenger trips by using appropriate geovisualisation methods (not more than 5 maps).\nDescribe the spatial patterns revealed by the geovisualisation (not more than 100 words per visual).\nAssemble at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.\nCompute a distance matrix by using the analytical hexagon data derived earlier.\n\n\n\n\n\nCalibrate spatial interactive models to determine factors affecting urban commuting flows at the selected time interval.\nPresent the modelling results by using appropriate geovisualisation and graphical visualisation methods. (Not more than 5 visuals)\nWith reference to the Spatial Interaction Model output tables, maps and data visualisation prepared, describe the modelling results. (not more than 100 words per visual)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/THE2.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex2/THE2.html#objectives",
    "title": "Take-home Exercise 2: Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows",
    "section": "",
    "text": "AimTasks\n\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\n\n\nDerive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the traffic analysis zone (TAZ).\nWith reference to the time intervals provided in the table below, construct an O-D matrix of commuter flows for a time interval of your choice by integrating Passenger Volume by Origin Destination Bus Stops and Bus Stop Location from LTA DataMall. The O-D matrix must be aggregated at the analytics hexagon level\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the O-D flows of the passenger trips by using appropriate geovisualisation methods (not more than 5 maps).\nDescribe the spatial patterns revealed by the geovisualisation (not more than 100 words per visual).\nAssemble at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.\nCompute a distance matrix by using the analytical hexagon data derived earlier.\n\n\n\n\n\nCalibrate spatial interactive models to determine factors affecting urban commuting flows at the selected time interval.\nPresent the modelling results by using appropriate geovisualisation and graphical visualisation methods. (Not more than 5 visuals)\nWith reference to the Spatial Interaction Model output tables, maps and data visualisation prepared, describe the modelling results. (not more than 100 words per visual)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/THE2.html#od-data",
    "href": "Take-Home_Ex/Take-Home_Ex2/THE2.html#od-data",
    "title": "Take-home Exercise 2: Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows",
    "section": "3.1 OD Data",
    "text": "3.1 OD Data\n\nImporting csvAttributesExtracting Study Data\n\n\nPassenger Volume by Origin Destination Bus Stops dataset for October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\n\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nObservations:\n\nThere are 7 variables in the odbus tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\n\nTOTAL_TRIPS: Number of trips We also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. These should be in factor data type for further processing and georeferencing.\n\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nNote that both of them are in factor data type now.\n\n\nIn our study, we would like to know study the 4 peak hour periods identified. Therefore, we can employ a combination of the following functions to obtain the relevant data:\nSummary of the functions used as follow: - mutate(): Used to create a new variable period based on the conditions of the ifelse() function. - select(): Retains the desired variables for further analysis. - filter(): Retains rows that satisfies our condition (i.e. the 4 peak periods) - group_by() and summarise(): Aggregates the total trips at each combination of origin bus stop, destination bus stop, and peak period.\n\npeak &lt;- odbus %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\"))))) %&gt;% \n  select(5:8)  %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\")  %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE, period) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nThe code chunk below extracts the four peak periods respectively.\n\nodbus_WDM &lt;- peak %&gt;%\n  filter(period == \"WDM\") %&gt;%\n  select(1:2, 4)\n  \nodbus_WDA &lt;- peak %&gt;%\n  filter(period == \"WDA\") %&gt;%\n  select(1:2, 4)\n  \nodbus_WEM &lt;- peak %&gt;%\n  filter(period == \"WEM\") %&gt;%\n  select(1:2, 4)\n  \nodbus_WEE &lt;- peak %&gt;%\n  filter(period == \"WEE\") %&gt;%\n  select(1:2, 4)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Business.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Business.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/entertn.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/entertn.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/F&B.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/F&B.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/FinServ.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/FinServ.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Liesure&Recreation.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Liesure&Recreation.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/MPSZ-2019.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Retails.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Retails.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "index.html#hands-on-exercises",
    "href": "index.html#hands-on-exercises",
    "title": "Geospatial Data Analytics",
    "section": "Hands-on Exercises",
    "text": "Hands-on Exercises\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercises",
    "href": "index.html#in-class-exercises",
    "title": "Geospatial Data Analytics",
    "section": "In-class Exercises",
    "text": "In-class Exercises\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercises",
    "href": "index.html#take-home-exercises",
    "title": "Geospatial Data Analytics",
    "section": "Take-home Exercises",
    "text": "Take-home Exercises\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.1 Building Fixed Bandwidth GWR Model",
    "text": "9.1 Building Fixed Bandwidth GWR Model\n\n9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\n2 approaches to determine the stopping rule: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres.\n\n\n9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-12-08 15:33:19.350607 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-12-08 15:33:20.467381"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.2 Building Adaptive Bandwidth GWR Model",
    "text": "9.2 Building Adaptive Bandwidth GWR Model\n\n9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE,# Changed to TRUE\n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-12-08 15:33:28.798466 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-12-08 15:33:30.159021 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-gwr-output",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.3 Visualising GWR Output",
    "text": "9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its \"data\" slot in an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#converting-sdf-into-sf-data.frame",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.4 Converting SDF into sf data.frame",
    "text": "9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-local-r2",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.5 Visualising local R2",
    "text": "9.5 Visualising local R2\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.6 Visualising coefficient estimates",
    "text": "9.6 Visualising coefficient estimates\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.6.1 By URS Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/THE2.html#geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex2/THE2.html#geospatial-data",
    "title": "Take-home Exercise 2: Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\n\n3.2.1 Importing Geospatial Data"
  }
]