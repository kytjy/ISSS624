[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Spatial interaction describe quatitatively the flow of people, material, or information between locations in geographical space.\nConditions for Spatial Flows\nThree interdependent conditions are necessary for a spatial interaction to occur:\n\nFeatures\n\n\nLocations: A movement is occurring between a location of origin and a location of destination (i=origin; j =destination)\nCentroid: Abstraction of the attributes of a zone at a point\nFlows: Expressed by a valued vector Tij representing an interaction between locations i and j\nVectors: A vector Tij links two centroids and has a value assigned to it (50) which can represents movements\n\n\n\nIn this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data.\n\n\n\n\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\ntmap for creating thematic maps; useful for static and interactive maps.\nsf for importing, integrating, processing and transforming geospatial data.\nDT for interactive data tables\nstplanr for sustainable transport planning; provides functions and tools for analysis and visualisation of transport projects\nperformance for model performance measurement\nggpubr for visualisation\ntidyverse for importing, integrating, wrangling and visualising data.\n\n\n\n\n\nImporting OD dataExtracting study data\n\n\nNote: Using October 2023 data because Postman API couldn’t find Oct 2022 data, maybe too long ago :(\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\nRecheck to confirm that the 2 variables have indeed been updated:\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\nFor our study, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable allows for interactive tables:\n\n\nShow the code\ndatatable(\n  odbus6_9,\n  filter='top')\n\n\n\n\n\n\n\nWe will save the output in rds format for future use, and reimport the saved rds file into R environment:\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")\n\n\n\n\n\n\n\n\nImporting geospatial dataGeospatial data wrangling\n\n\n\n\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\nShow the code\ndatatable(busstop_mpsz)\n\n\n\n\n\n\n\nSave the output in rds format for future use:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\n\n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\n\n\n\nCheck for duplicates to prevent double counting:\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate\n\n# A tibble: 1,186 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 11009     01341         1 QTSZ01   \n 2 11009     01341         1 QTSZ01   \n 3 11009     01411         4 QTSZ01   \n 4 11009     01411         4 QTSZ01   \n 5 11009     01421        17 QTSZ01   \n 6 11009     01421        17 QTSZ01   \n 7 11009     01511        19 QTSZ01   \n 8 11009     01511        19 QTSZ01   \n 9 11009     01521         2 QTSZ01   \n10 11009     01521         2 QTSZ01   \n# ℹ 1,176 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\n\n\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate\n\n# A tibble: 1,350 × 5\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ SUBZONE_C\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 01013     51071         2 RCSZ10    CCSZ01   \n 2 01013     51071         2 RCSZ10    CCSZ01   \n 3 01112     51071        66 RCSZ10    CCSZ01   \n 4 01112     51071        66 RCSZ10    CCSZ01   \n 5 01112     53041         4 RCSZ10    BSSZ01   \n 6 01112     53041         4 RCSZ10    BSSZ01   \n 7 01121     51071         8 RCSZ04    CCSZ01   \n 8 01121     51071         8 RCSZ04    CCSZ01   \n 9 01121     82221         1 RCSZ04    GLSZ05   \n10 01121     82221         1 RCSZ04    GLSZ05   \n# ℹ 1,340 more rows\n\n\nRetain unique records:\n\nod_data &lt;- unique(od_data)\n\n\n\n\n\nod_data &lt;- od_data %&gt;%\n  # Rename column for better clarity\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  # Remove NAs\n  drop_na() %&gt;% \n  # Group and summarise number of trips at each O/D level \n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nod_data\n\n# A tibble: 21,079 × 3\n# Groups:   ORIGIN_SZ [310]\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 AMSZ01    AMSZ01            2694\n 2 AMSZ01    AMSZ02           10591\n 3 AMSZ01    AMSZ03           14980\n 4 AMSZ01    AMSZ04            3106\n 5 AMSZ01    AMSZ05            7734\n 6 AMSZ01    AMSZ06            2306\n 7 AMSZ01    AMSZ07            1824\n 8 AMSZ01    AMSZ08            2734\n 9 AMSZ01    AMSZ09            2300\n10 AMSZ01    AMSZ10             164\n# ℹ 21,069 more rows\n\n\nSave the output in rds format for future use, and reimport into R environment:\n\nwrite_rds(od_data, \"data/rds/od_data.rds\")\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")\n\n\n\n\n\n\n\n\n\nRemove intra-zonal flowsCreate desired linesVisualise desired lines\n\n\nWe will not plot the intra-zonal flows, i.e. where the origin and destination are the same (eg origin = AMSZ01 and destination = AMSZ01)\nThe code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\n\n\n\n\nNote\n\n\n\nThe comma , after the condition is significant. In R’s data frame syntax, the format for subsetting is [rows, columns]. When you place a condition before the comma, it applies to rows. The comma itself then implies that you’re not applying any specific filter to the columns – meaning you want all columns.\n\n\n\n\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#task",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#task",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#loading-r-packages",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "pacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\ntmap for creating thematic maps; useful for static and interactive maps.\nsf for importing, integrating, processing and transforming geospatial data.\nDT for interactive data tables\nstplanr for sustainable transport planning; provides functions and tools for analysis and visualisation of transport projects\nperformance for model performance measurement\nggpubr for visualisation\ntidyverse for importing, integrating, wrangling and visualising data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-flow-data",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Importing OD dataExtracting study data\n\n\nNote: Using October 2023 data because Postman API couldn’t find Oct 2022 data, maybe too long ago :(\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\nRecheck to confirm that the 2 variables have indeed been updated:\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 20281, 20281, 1…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 20141, 20141, 1…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\nFor our study, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable allows for interactive tables:\n\n\nShow the code\ndatatable(\n  odbus6_9,\n  filter='top')\n\n\n\n\n\n\n\nWe will save the output in rds format for future use, and reimport the saved rds file into R environment:\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Importing geospatial dataGeospatial data wrangling\n\n\n\n\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kytjy\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\nShow the code\ndatatable(busstop_mpsz)\n\n\n\n\n\n\n\nSave the output in rds format for future use:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\n\n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\n\n\n\nCheck for duplicates to prevent double counting:\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate\n\n# A tibble: 1,186 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 11009     01341         1 QTSZ01   \n 2 11009     01341         1 QTSZ01   \n 3 11009     01411         4 QTSZ01   \n 4 11009     01411         4 QTSZ01   \n 5 11009     01421        17 QTSZ01   \n 6 11009     01421        17 QTSZ01   \n 7 11009     01511        19 QTSZ01   \n 8 11009     01511        19 QTSZ01   \n 9 11009     01521         2 QTSZ01   \n10 11009     01521         2 QTSZ01   \n# ℹ 1,176 more rows\n\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\n\n\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate\n\n# A tibble: 1,350 × 5\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ SUBZONE_C\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 01013     51071         2 RCSZ10    CCSZ01   \n 2 01013     51071         2 RCSZ10    CCSZ01   \n 3 01112     51071        66 RCSZ10    CCSZ01   \n 4 01112     51071        66 RCSZ10    CCSZ01   \n 5 01112     53041         4 RCSZ10    BSSZ01   \n 6 01112     53041         4 RCSZ10    BSSZ01   \n 7 01121     51071         8 RCSZ04    CCSZ01   \n 8 01121     51071         8 RCSZ04    CCSZ01   \n 9 01121     82221         1 RCSZ04    GLSZ05   \n10 01121     82221         1 RCSZ04    GLSZ05   \n# ℹ 1,340 more rows\n\n\nRetain unique records:\n\nod_data &lt;- unique(od_data)\n\n\n\n\n\nod_data &lt;- od_data %&gt;%\n  # Rename column for better clarity\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  # Remove NAs\n  drop_na() %&gt;% \n  # Group and summarise number of trips at each O/D level \n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nod_data\n\n# A tibble: 21,079 × 3\n# Groups:   ORIGIN_SZ [310]\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 AMSZ01    AMSZ01            2694\n 2 AMSZ01    AMSZ02           10591\n 3 AMSZ01    AMSZ03           14980\n 4 AMSZ01    AMSZ04            3106\n 5 AMSZ01    AMSZ05            7734\n 6 AMSZ01    AMSZ06            2306\n 7 AMSZ01    AMSZ07            1824\n 8 AMSZ01    AMSZ08            2734\n 9 AMSZ01    AMSZ09            2300\n10 AMSZ01    AMSZ10             164\n# ℹ 21,069 more rows\n\n\nSave the output in rds format for future use, and reimport into R environment:\n\nwrite_rds(od_data, \"data/rds/od_data.rds\")\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "title": "Hands-on Exercise 3: Processing and Visualising Flow Data",
    "section": "",
    "text": "Remove intra-zonal flowsCreate desired linesVisualise desired lines\n\n\nWe will not plot the intra-zonal flows, i.e. where the origin and destination are the same (eg origin = AMSZ01 and destination = AMSZ01)\nThe code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\n\n\n\n\nNote\n\n\n\nThe comma , after the condition is significant. In R’s data frame syntax, the format for subsetting is [rows, columns]. When you place a condition before the comma, it applies to rows. The comma itself then implies that you’re not applying any specific filter to the columns – meaning you want all columns.\n\n\n\n\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey of geospatial analytics. Join me in my adventure :)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains.\n\n\n\n\nAimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#background",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#background",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "AimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.1 The Data",
    "text": "3.1 The Data\nThe following data are used for this study:\n\nAspatial:\n\nPassenger Volume by Origin Destination Bus Stops for August, September and October 2023, downloaded from LTA DataMall using API.\n\nGeospatial\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\nhexagon, a hexagon layer of 250m is provided to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2 Import & Preparation",
    "text": "3.2 Import & Preparation"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#aspatial",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#aspatial",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2.1 Aspatial",
    "text": "3.2.1 Aspatial\n\nImport into RData ExplorationData Wrangling4.1 Data Classification4.2 Plots5.1 Global Spatial Autocorrelation5.2 Computing Global Spatial Autocorrelation Statistics5.3 Local Spatial Autocorrelation StatisticsOriginal Valueslogged Variables\n\n\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset from August to October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n#odbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\n#odbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\n\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n#glimpse(odbus09)\n#glimpse(odbus10)\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops.\n\n\n\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma())\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\nNotice that there are 5067 unique origin bus stops.\n\n\n(d) Variable Transformation\n\n\nShow the code\n# Extract column\ndistWDM &lt;- peakperiods_wide$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 80000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWDA &lt;- peakperiods_wide$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 110000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEM &lt;- peakperiods_wide$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 23000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEE &lt;- peakperiods_wide$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 29000, \n    y = 2000, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\npeakperiods_wider &lt;- peakperiods_wide %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Extract column\ndistlogWDM &lt;- peakperiods_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWDA &lt;- peakperiods_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Extract column\ndistlogWEM &lt;- peakperiods_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWEE &lt;- peakperiods_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"view\")\nhex &lt;- tm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\nhex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id, busstops) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 5\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id busstops\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;    &lt;int&gt;\n1 43709      B06        BLK 644                 1904        7\n2 43709      B06        BLK 644                 1904        7\n3 58031      UNK        OPP CANBERRA DR         2939        7\n4 58031      UNK        OPP CANBERRA DR         2939        7\n5 51071      B21        MACRITCHIE RESERVOIR    3081        6\n6 51071      B21        MACRITCHIE RESERVOIR    3081        6\n7 97079      B14        OPP ST. JOHN'S CRES     5037        5\n8 97079      B14        OPP ST. JOHN'S CRES     5037        5\n\n\nResults displayed 4 genuine duplicated records. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(c) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore.\n\norigin_grid &lt;- left_join(peakperiods_wider, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  group_by(grid_id) %&gt;% \n  # retains SG bus stops\n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219))\n\nglimpse(origin_grid)\n\nRows: 5,076\nColumns: 13\nGroups: grid_id [1,504]\n$ ORIGIN_BS  &lt;chr&gt; \"01012\", \"01013\", \"01019\", \"01029\", \"01039\", \"01059\", \"0110…\n$ WDA        &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233, 932…\n$ WDM        &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 4240, 5…\n$ WEE        &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6221,…\n$ WEM        &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 6198, …\n$ logWDM     &lt;dbl&gt; 7.587311, 6.858565, 7.489412, 7.848153, 7.985484, 7.409136,…\n$ logWDA     &lt;dbl&gt; 9.041685, 8.899458, 8.190909, 9.139596, 9.467847, 7.665285,…\n$ logWEM     &lt;dbl&gt; 7.728856, 7.436617, 7.320527, 8.093157, 8.598589, 6.967909,…\n$ logWEE     &lt;dbl&gt; 8.073403, 7.935945, 7.392032, 8.353261, 8.909641, 7.081709,…\n$ BUS_ROOF_N &lt;chr&gt; \"B03\", \"B05\", \"B04\", \"B07\", \"B09\", \"B08\", \"TMNL\", \"B07\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"HOTEL GRAND PACIFIC\", \"ST JOSEPH'S CH\", \"BRAS BASAH CPLX\",…\n$ grid_id    &lt;int&gt; 3292, 3292, 3292, 3323, 3354, 3324, 3324, 3292, 3324, 3292,…\n$ busstops   &lt;int&gt; 8, 8, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7,…\n\n\n\n\n(d) Retrieve Geometry\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid, \n                           by = \"grid_id\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop).\n\n\n\n\n\n\n\n\n4 Geovisualisation & Analysis\n\n\n\nDifferent classification schemes highlight areas with the highest and/or lowest values, while others create classes that result in a more uniform distribution of colors. When data is sharply skewed or has extreme outliers, it’s important to consider whether the goal is to emphasize those areas or to achieve a more even distribution of colors and sizes.\nThe main methods of data classification are:\n\nQuantile: each class contains an equal number of features. It assigns the same number of data values to each class. There are no empty classes or classes with too few or too many values\nJenks/Natural breaks: seeks clumps of values that are clustered together in order to form categories that may reflect meaningful groupings of areas\nEqual: divides the range of attribute values into equal-sized sub-ranges\n\nSince our variable is less skewed after log transformation, we can explore various classification methods for visualization. This approach may reveal interesting insights that were not immediately apparent before.\n\n\n\n4.2.1 Weekday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\n\nplotlogWDM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n\nplotlogWDM_q\n\n\n\n\n\n\n\nThe grids above are partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period:\n\nWest: BLK 821, BLK 252, Sunshine Place\nNorth: BLK 314\nNorth-East: BLK 477A, BLK 1, BLK 555, BLK 324\nEast: BLK 109, BLK 124, BLK 756\n\nThis is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nHigher passenger traffic were noted at the bus stops nearer to MRT stations such as Harbourfront Station, Farrer Road Station, Yio Chu Kang Station, and Admirality Station. A possible contributing factor could be the people who are transiting from taking the MRTs to buses to get to their destinations.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. This could potentially be due to the people commuting across the causeway from Malaysia into the Singapore borders.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_e\n\n\n\n\n\n\n\nThe map using equal intervals provided slightly different insights. We noted that the bus stop located near to MRT stations had higher levels of ridership. In particular, more trips originated from Tiong Bahru Station, Buona Vista Station, Tanah Merah Station, Admiralty Station, Harbourfront, and Woodleigh Station. Bus interchanges also appeared to be popular origins, i.e. Bukit Panjang Interchange and Joo Koon Interchange.\nIn general, more homogeneity is noted using the equal interval – the contrast between hexagon to hexagon is less obvious.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_j\n\n\n\n\n\n\n\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes. Higher bus ridership were spotted at bus stops within close proximity to MRT stations (Kranji Station, Buona Vista Station, Buangkok Station, Ranggung Station, Farrer Road Station, Stevens Station, Bedok Reservoir Station) and residential estates (Sunshine Place near Tengah, BLK 109 in Bedok, BLK 477A in Sengkang, Bef. BLK 629A in Woodlands, to name a few).\n\n\n\n\n\n4.2.2 Weekday Afternoon Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_q\n\n\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nBus stops in close proximity to MRT tations and popular bus stops in residential estatements remained high.\nMore trips originating from institutional areas: Opposite Ngee Ann Poly, Temasek Poly, NIE BLK 2, School of the Arts\nMore trips originating from industrial buildings/business parks: North Link Bldg, Aft Senoko Way, Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nMore trips originating from hospitals: Yishun Community Hospital, Changi General Hospital\nSeletar Camp also looked to have high passenger levels\nThe far West seemed to experience low ridership other than the bus stop opposite Tuas Link Station.\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_e\n\n\n\n\n\n\n\nNotably, there were higher concentration of passengers who boarded the bus at Serangoon Station, Harbourfront/VivoCity, Tiong Bahru Station, Admiralty Station, and Punggol Station during weekday afternoons according to the equal interval classification method.\nSimilar to the map for weekday morning peak period, the equal interval seemed to produce more homogeneous classifications.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_j\n\n\n\n\n\n\n\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas.\nIt also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method.\nAlternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\n\n4.2.3 Weekend/Holiday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_q\n\n\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nDuring the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. Buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends.\nBus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe bus stops with the highest boarding passengers are Sunshine Place, Opp BLK 271, BLK 252, Aft. Hasanah Mosque, Buona Vista Station, Harbourfront/Vivocity, Admiralty Station, BLK 555, Bedok Reservoir Station, BLK 22, BLK 109.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_e\n\n\n\n\n\n\n\nEqual interval classification highlighted the following bus stops to have the highest ridership during weekend/holiday morning peak period: Harbourfront/Vivocity, Tiong Bahru Station, Orchard Station/Lucky Plaza, Admirality Station, Aft. Punggol Road.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n4.2.4 Weekend/Holiday Evening\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_q\n\n\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods.\nSunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership.\nWoodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_e\n\n\n\n\n\n\n\nThe bus stops with higher traffic seem to be quite consistent across the different peak periods. This includes Woodlands Checkpoint, Kranji Station, Admiralty Station, Serangoon Station, Aft. Punggol Road, Bukit Panjang MRT, Yio Chu Kang Interchange.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n5 Spatial Association Analysis\nAccording to Tobler’s First Law of Geography, “everything is related to everything else, but near things are more related than distant things.”\nThis sub-section will cover the computation of local spatial autocorrelation statistics and spatial complete randomness test for local spatial autocorrelation. The goal of these analyses is to understand whether there are clusters or outliers of bus stop with high or low ridership across Singapore.\n\n\n\n\n5.1.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   22.89    0.00 1000.00 \n\n\nThe maximum nearest neighbour distance is 1000m, thus we will use threshold value of 1001m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 1001),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\n#kable(head(wm_fd,5))\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 266698 \nPercentage nonzero weights: 1.057466 \nAverage number of links: 53.10593 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  3   6   3   4   7   6  20  19  20  13  24  13  21  29  20  35  28  40  34  40 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n 24  52  45  33  39  48  26  44  31  30  31  52  48  39  35  55  48  49  83  55 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n 74  67  59  73  76  83  96  81  59  53 101 136  87 117 101  84 111  79 134 127 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n114 150  96 113 103 103 106  81  94 107  61  73  92  55  41  64  61  73  42  31 \n 81  82  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100 102 \n 40  32   9  30  30  26   9  19  14  21   6   9  12  15   8   4   4   6  13   5 \n3 least connected regions:\n2274 5021 5022 with 1 link\n5 most connected regions:\n3699 3700 3701 3702 3703 with 102 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 5 hexagons with 102 neighbours. We can also identify an average of 53 neighbours per hexagon using the distance-based weight matrix.\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1  2, 4, 5, 9, 10, 15, 32, 33\n2  1, 4, 5, 9, 10, 15, 32, 33\n3 5, 6, 7, 11, 12, 16, 17, 18\n                                                      wt grid_id busstops.x\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34          1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65          1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99          1\n  ORIGIN_BS WDA WDM WEE WEM   logWDM   logWDA   logWEM   logWEE BUS_ROOF_N\n1     25059 417  62  65   5 4.127134 6.033086 1.609438 4.174387        UNK\n2     25751 110  50  26  24 3.912023 4.700480 3.178054 3.258097       B02D\n3     26379 249  44  54  27 3.784190 5.517453 3.295837 3.988984        NIL\n             LOC_DESC busstops.y              area_hexagon_grid\n1   AFT TUAS STH BLVD          1 POLYGON ((3970.122 27925.48...\n2 BEF TUAS STH AVE 14          1 POLYGON ((4220.122 28358.49...\n3            YONG NAM          1 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_contiguity() of sfdep is used to identify the neighbours by using contiguity criteria. The output is a list of neighbours (i.e. nb).\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_contiguity(geo),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nsummary(wm_idw$nb)\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 107808 \nPercentage nonzero weights: 0.4274621 \nAverage number of links: 21.46714 \n6 regions with no links:\n1750 2274 3159 4675 4989 4994\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 \n  6  12  17  33  23  97  70  99  88  76 115 136 126 133 130 160 168 227 197 169 \n 20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39 \n159 174 251 240 213 195 222 210 183 187 124 115 104 110 111  39  54  56  11  17 \n 40  41  42  43  44  48 \n 55  62  13  17  10   8 \n12 least connected regions:\n1 32 62 736 3354 3355 4982 4990 5002 5003 5021 5022 with 1 link\n8 most connected regions:\n3048 3049 3050 3051 3052 3053 3054 3055 with 48 links\n\n\nUsing the inverse distance method resulted in 6 regions with no neighbours, this could be due to the spatial isolation of certain hexagons.\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method led to regions with no neighbours and is computationally intensive as each neighbour\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well.\n\n\ncentroid &lt;- st_centroid(origin_gridwgeom)\nplot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n\n\n\n#plot(wm_idw, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")\n\n\n\n\n\n5.2.1 Moran’s I\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing, using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed). H1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed using the original and logged values with a seed number 1234. set.seed() function allows us to create reproducible results.\nNote: nsim arugment of global_moran_perm() refers to the number of simulations is nsim + 1, i.e., for nsim = 99, 100 simulations will be performed.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.094609, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nlogged-transformed Data\n\n\nShow the code\ngmp_logWDM &lt;- global_moran_perm(wm_ad$logWDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.49564, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.063584, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nlogged-transformed Data\n\n\nShow the code\ngmp_logWDA &lt;- global_moran_perm(wm_ad$logWDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32588, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.095565, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nlogged-transformed Data\n\n\nShow the code\ngmp_logWEM &lt;- global_moran_perm(wm_ad$logWEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.46898, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nOriginal Data\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.083812, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nlogged-transformed Data\n\n\nShow the code\ngmp_logWEE &lt;- global_moran_perm(wm_ad$logWEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_logWEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.40498, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained). The higher Moran’s I values for logged-transformed variables suggests a higher level of clustering compared to the original ridership values.\n\n\n5.2.2 Geary’s C\n\n\n5.2.3 Spatial Correlogram\n\n\n\nGlobal spatial autocorrelation provides a broad overview of spatial clustering within a dataset, offering a single value that indicates whether similar values are generally clustered or dispersed across the entire study area. In contrast, local spatial autocorrelation delves into specific locations, identifying where clusters of similar values (hot spots or cold spots) or spatial outliers exist. While global metrics give an overall trend, local metrics provide detailed, location-specific insights, highlighting exact areas of significant spatial clustering or anomaly.\nThus, after we have established through statistical testing that spatial clustering of bus ridership occurs in Singapore, we now seek to detect clusters or outliers and discover if there are any hot or cold spots of high ridership using Local Spatial Autocorrelation Statistics.\n\n5.3.1 Local Moran’s I\nIn this section, we will perform Moran’s I statistics testing by using local_moran() of sfdep. The output of local_moran() is a sf data.frame, containing the columns below:\n\nii: local moran statistic\neii: expectation of local Moran’s I statistic\nvar_ii: variance of local Moran’s I statistic\nz_ii: standard deviation of local Moran’s I statistic\np_ii: p-value of local Moran’s I statistic using pnorm()\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value, based on crand.py of pysal\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nunnest() of tidyr package helps expand a list-column containing data frames into rows and columns.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\nOriginal Data\n\n\nShow the code\nlisa_WDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.190  0.0124  0.0151 1.44  0.149     0.02         0.01    -2.83    13.4 \n2 0.190 -0.00671 0.0165 1.53  0.125     0.02         0.01    -1.62     3.82\n3 0.186  0.0186  0.0116 1.56  0.120     0.02         0.01    -1.85     5.15\n4 0.181  0.0107  0.0132 1.48  0.138     0.02         0.01    -2.71    12.9 \n5 0.167 -0.0167  0.0416 0.899 0.369     0.02         0.01    -5.19    30.5 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nlogged-transformed Data\n\n\nShow the code\nlisa_logWDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWDM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii  var_ii  z_ii    p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 1.42   0.0283  0.271    2.67 0.00766     0.06         0.03   0.330    0.705 \n2 1.50   0.0346  0.247    2.94 0.00330     0.02         0.01   0.0477  -0.597 \n3 1.10  -0.00302 0.340    1.89 0.0581      0.12         0.06   0.600    0.228 \n4 0.998  0.0326  0.126    2.72 0.00658     0.02         0.01  -0.0108  -0.501 \n5 0.217  0.00475 0.00515  2.96 0.00304     0.02         0.01   0.471   -0.0787\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDA, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0752 -0.000546 0.00600 0.978 0.328     0.02         0.01    -2.58     8.00\n2 0.0795 -0.00164  0.00890 0.860 0.390     0.02         0.01    -2.75     8.58\n3 0.0734  0.00859  0.00434 0.984 0.325     0.06         0.03    -2.93    13.3 \n4 0.0567  0.00867  0.00181 1.13  0.260     0.02         0.01    -2.83    11.8 \n5 0.0415  0.00225  0.00131 1.09  0.277     0.02         0.01    -2.77     8.20\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nlogged-transformed Data\n\n\nShow the code\nlisa_logWDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWDA, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n       ii      eii  var_ii  z_ii    p_ii p_ii_sim p_folded_sim skewness kurtosis\n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  0.472  -0.00203 6.14e-2  1.91 0.0558      0.06         0.03    0.340  -0.439 \n2  0.805   0.0163  3.12e-1  1.41 0.158       0.22         0.11    0.101   0.0331\n3  0.413   0.00850 1.35e-1  1.10 0.270       0.28         0.14    0.381   0.180 \n4 -0.0616  0.00328 5.87e-4 -2.68 0.00736     0.02         0.01    0.253  -0.585 \n5 -0.298  -0.00176 1.27e-2 -2.63 0.00855     0.04         0.02   -0.592   0.625 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.143 -0.0295  0.0384  0.879 0.380     0.02         0.01    -2.94     9.01\n2 0.141 -0.00531 0.0131  1.28  0.201     0.02         0.01    -2.15     5.47\n3 0.130 -0.00521 0.0245  0.865 0.387     0.12         0.06    -3.61    18.0 \n4 0.124 -0.0266  0.0196  1.07  0.282     0.02         0.01    -3.06    12.3 \n5 0.115 -0.00727 0.00971 1.24  0.215     0.02         0.01    -3.14    14.3 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nlogged-transformed Data\n\n\nShow the code\nlisa_logWEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWEM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii      eii   var_ii  z_ii    p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2.08   -0.0664  0.753     2.48 0.0132      0.06         0.03   0.735     0.105\n2 1.52    0.0552  0.305     2.66 0.00787     0.04         0.02   0.690     0.597\n3 0.719  -0.0213  0.273     1.42 0.157       0.2          0.1    0.0768   -0.821\n4 0.620  -0.0130  0.0485    2.87 0.00406     0.02         0.01   0.233     0.278\n5 0.0788  0.00504 0.000556  3.13 0.00176     0.02         0.01   0.713     0.216\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\nOriginal Data\n\n\nShow the code\nlisa_WEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEE, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii      eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0904  0.00411 0.00639 1.08  0.281     0.02         0.01    -3.25    13.4 \n2 0.0924  0.0137  0.00537 1.08  0.282     0.04         0.02    -2.47     7.13\n3 0.0809  0.00401 0.00391 1.23  0.218     0.04         0.02    -2.26     7.45\n4 0.0756  0.00890 0.00461 0.982 0.326     0.04         0.02    -3.08    11.8 \n5 0.0637 -0.0134  0.0149  0.631 0.528     0.02         0.01    -4.91    26.4 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\nlogged-transformed Data\n\n\nShow the code\nlisa_logWEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$logWEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_logWEE, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n       ii       eii  var_ii   z_ii    p_ii p_ii_sim p_folded_sim skewness\n    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1  0.696  -0.00708  0.157    1.78  0.0756      0.18         0.09   0.516 \n2  0.927   0.0273   0.355    1.51  0.131       0.18         0.09  -0.106 \n3  0.451   0.0641   0.229    0.808 0.419       0.42         0.21   0.459 \n4  0.161   0.00863  0.00622  1.94  0.0526      0.1          0.05   0.582 \n5 -0.0878  0.000756 0.00112 -2.65  0.00816     0.04         0.02  -0.0919\n# ℹ 21 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;,\n#   WDA &lt;dbl&gt;, WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;,\n#   logWEM &lt;dbl&gt;, logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;,\n#   busstops.y &lt;int&gt;, area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\n\n5.3.2 Visualising Local Moran’s I & p-value\nTo better understand which areas are outliers/clusters, we will use choropleth mapping functions of tmap package to visualise the local Moran’s I values and the associated p-values by using the code chunks below.\nWeekday Morning :::panel-tabset\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisaWDM &lt;-\n  tm_shape(lisa_WDM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\nplotp_lisaWDM &lt;- \n  tm_shape(lisa_WDM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(-Inf, \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\ntmap_arrange(plot_lisaWDM, plotp_lisaWDM, asp=1, ncol=2) \n\n\n\n\n\nThe plot on the left shows regions of positive (blue) and negative (orange) Moran’s I statistics, indicating positive and negative clustering relationships. In particular, bus stops at Woodlands Checkpoint have the highest Local Moran’s I statistics.\nOn the right, we see that the p-values are significant at 5% significance level for the regions in the 3 darker shades of blue. We see that areas in the far West, North-West, and far East have statistically significant p-values for the cluster/outlier spatial relationship that they see.\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\nplot_lisalogWDM &lt;-\n  tm_shape(lisa_logWDM) +\n    tm_fill(\"ii\",\n            style=\"pretty\",\n            palette=\"RdBu\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\nplotp_lisalogWDM &lt;- \n  tm_shape(lisa_logWDM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            palette=\"-Blues\",\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"p-value of Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\ntmap_arrange(plot_lisalogWDM, plotp_lisalogWDM, asp=1, ncol=2) \n\n\n\n\n\nWe obtain different insights using the log-transformed variables to calculate Local Moran’s I. NorthWest region, particularly around Lim Chu Kang / Sungei Buloh. The plot on the right suggests that with p-value &lt;0.05, the high spatial clustering observed in the area is also statistically significant.\n\n\n\nWeekday Afternoon\n\n\n\n\n\n\nWeekend/Holiday Morning\n\n\n\n\n\n\nWeekend/Holiday Evening\n\n\n\n\n\n\n\n5.3.3 Visualising LISA Map\n\nOriginal Valueslogged Variables\n\n\n\nlisa_sig_WDM &lt;- lisa_WDM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_WDM) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_WDM) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\nlisa_sig_logWDM &lt;- lisa_logWDM  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_logWDM) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_logWDM) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-into-r",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#import-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Import into R",
    "text": "Import into R\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset from August to October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n#odbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\n#odbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-exploration",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-exploration",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n#glimpse(odbus09)\n#glimpse(odbus10)\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma())\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\nNotice that there are 5067 unique origin bus stops.\n\n\n(d) Variable Transformation\n\n\nShow the code\n# Extract column\ndistWDM &lt;- peakperiods_wide$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 80000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWDA &lt;- peakperiods_wide$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 110000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEM &lt;- peakperiods_wide$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 23000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEE &lt;- peakperiods_wide$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 29000, \n    y = 2000, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\npeakperiods_wider &lt;- peakperiods_wide %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Extract column\ndistlogWDM &lt;- peakperiods_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWDA &lt;- peakperiods_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Extract column\ndistlogWEM &lt;- peakperiods_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWEE &lt;- peakperiods_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"view\")\nhex &lt;- tm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\nhex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id, busstops) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 5\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id busstops\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;    &lt;int&gt;\n1 43709      B06        BLK 644                 1904        7\n2 43709      B06        BLK 644                 1904        7\n3 58031      UNK        OPP CANBERRA DR         2939        7\n4 58031      UNK        OPP CANBERRA DR         2939        7\n5 51071      B21        MACRITCHIE RESERVOIR    3081        6\n6 51071      B21        MACRITCHIE RESERVOIR    3081        6\n7 97079      B14        OPP ST. JOHN'S CRES     5037        5\n8 97079      B14        OPP ST. JOHN'S CRES     5037        5\n\n\nResults displayed 4 genuine duplicated records. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(c) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore.\n\norigin_grid &lt;- left_join(peakperiods_wider, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  group_by(grid_id) %&gt;% \n  # retains SG bus stops\n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219))\n\nglimpse(origin_grid)\n\nRows: 5,076\nColumns: 13\nGroups: grid_id [1,504]\n$ ORIGIN_BS  &lt;chr&gt; \"01012\", \"01013\", \"01019\", \"01029\", \"01039\", \"01059\", \"0110…\n$ WDA        &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233, 932…\n$ WDM        &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 4240, 5…\n$ WEE        &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6221,…\n$ WEM        &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 6198, …\n$ logWDM     &lt;dbl&gt; 7.587311, 6.858565, 7.489412, 7.848153, 7.985484, 7.409136,…\n$ logWDA     &lt;dbl&gt; 9.041685, 8.899458, 8.190909, 9.139596, 9.467847, 7.665285,…\n$ logWEM     &lt;dbl&gt; 7.728856, 7.436617, 7.320527, 8.093157, 8.598589, 6.967909,…\n$ logWEE     &lt;dbl&gt; 8.073403, 7.935945, 7.392032, 8.353261, 8.909641, 7.081709,…\n$ BUS_ROOF_N &lt;chr&gt; \"B03\", \"B05\", \"B04\", \"B07\", \"B09\", \"B08\", \"TMNL\", \"B07\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"HOTEL GRAND PACIFIC\", \"ST JOSEPH'S CH\", \"BRAS BASAH CPLX\",…\n$ grid_id    &lt;int&gt; 3292, 3292, 3292, 3323, 3354, 3324, 3324, 3292, 3324, 3292,…\n$ busstops   &lt;int&gt; 8, 8, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7,…\n\n\n\n\n(d) Retrieve Geometry\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid, \n                           by = \"grid_id\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-classification",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#data-classification",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.1 Data Classification",
    "text": "4.1 Data Classification\nDifferent classification schemes highlight areas with the highest and/or lowest values, while others create classes that result in a more uniform distribution of colors. When data is sharply skewed or has extreme outliers, it’s important to consider whether the goal is to emphasize those areas or to achieve a more even distribution of colors and sizes.\nThe main methods of data classification are:\n\nQuantile: each class contains an equal number of features. It assigns the same number of data values to each class. There are no empty classes or classes with too few or too many values\nJenks/Natural breaks: seeks clumps of values that are clustered together in order to form categories that may reflect meaningful groupings of areas\nEqual: divides the range of attribute values into equal-sized sub-ranges\n\nSince our variable is less skewed after log transformation, we can explore various classification methods for visualization. This approach may reveal interesting insights that were not immediately apparent before."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#plots",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#plots",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Plots",
    "text": "4.2 Plots\n\n4.2.1 Weekday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\n\nplotlogWDM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n\nplotlogWDM_q\n\n\n\n\n\n\n\nThe grids above are partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period:\n\nWest: BLK 821, BLK 252, Sunshine Place\nNorth: BLK 314\nNorth-East: BLK 477A, BLK 1, BLK 555, BLK 324\nEast: BLK 109, BLK 124, BLK 756\n\nThis is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nHigher passenger traffic were noted at the bus stops nearer to MRT stations such as Harbourfront Station, Farrer Road Station, Yio Chu Kang Station, and Admirality Station. A possible contributing factor could be the people who are transiting from taking the MRTs to buses to get to their destinations.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. This could potentially be due to the people commuting across the causeway from Malaysia into the Singapore borders.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_e\n\n\n\n\n\n\n\nThe map using equal intervals provided slightly different insights. We noted that the bus stop located near to MRT stations had higher levels of ridership. In particular, more trips originated from Tiong Bahru Station, Buona Vista Station, Tanah Merah Station, Admiralty Station, Harbourfront, and Woodleigh Station. Bus interchanges also appeared to be popular origins, i.e. Bukit Panjang Interchange and Joo Koon Interchange.\nIn general, more homogeneity is noted using the equal interval – the contrast between hexagon to hexagon is less obvious.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_j\n\n\n\n\n\n\n\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes. Higher bus ridership were spotted at bus stops within close proximity to MRT stations (Kranji Station, Buona Vista Station, Buangkok Station, Ranggung Station, Farrer Road Station, Stevens Station, Bedok Reservoir Station) and residential estates (Sunshine Place near Tengah, BLK 109 in Bedok, BLK 477A in Sengkang, Bef. BLK 629A in Woodlands, to name a few).\n\n\n\n\n\n4.2.2 Weekday Afternoon Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_q\n\n\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nBus stops in close proximity to MRT tations and popular bus stops in residential estatements remained high.\nMore trips originating from institutional areas: Opposite Ngee Ann Poly, Temasek Poly, NIE BLK 2, School of the Arts\nMore trips originating from industrial buildings/business parks: North Link Bldg, Aft Senoko Way, Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nMore trips originating from hospitals: Yishun Community Hospital, Changi General Hospital\nSeletar Camp also looked to have high passenger levels\nThe far West seemed to experience low ridership other than the bus stop opposite Tuas Link Station.\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_e\n\n\n\n\n\n\n\nNotably, there were higher concentration of passengers who boarded the bus at Serangoon Station, Harbourfront/VivoCity, Tiong Bahru Station, Admiralty Station, and Punggol Station during weekday afternoons according to the equal interval classification method.\nSimilar to the map for weekday morning peak period, the equal interval seemed to produce more homogeneous classifications.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_j\n\n\n\n\n\n\n\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas.\nIt also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method.\nAlternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\n\n4.2.3 Weekend/Holiday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_q\n\n\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nDuring the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. Buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends.\nBus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe bus stops with the highest boarding passengers are Sunshine Place, Opp BLK 271, BLK 252, Aft. Hasanah Mosque, Buona Vista Station, Harbourfront/Vivocity, Admiralty Station, BLK 555, Bedok Reservoir Station, BLK 22, BLK 109.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_e\n\n\n\n\n\n\n\nEqual interval classification highlighted the following bus stops to have the highest ridership during weekend/holiday morning peak period: Harbourfront/Vivocity, Tiong Bahru Station, Orchard Station/Lucky Plaza, Admirality Station, Aft. Punggol Road.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n4.2.4 Weekend/Holiday Evening\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_q\n\n\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods.\nSunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership.\nWoodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_e\n\n\n\n\n\n\n\nThe bus stops with higher traffic seem to be quite consistent across the different peak periods. This includes Woodlands Checkpoint, Kranji Station, Admiralty Station, Serangoon Station, Aft. Punggol Road, Bukit Panjang MRT, Yio Chu Kang Interchange.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Global Spatial Autocorrelation",
    "text": "5.1 Global Spatial Autocorrelation\n\n5.1.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   22.89    0.00 1000.00 \n\n\nThe maximum nearest neighbour distance is 1000m, thus we will use threshold value of 1001m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 1001),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\n#kable(head(wm_fd,5))\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 266698 \nPercentage nonzero weights: 1.057466 \nAverage number of links: 53.10593 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  3   6   3   4   7   6  20  19  20  13  24  13  21  29  20  35  28  40  34  40 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n 24  52  45  33  39  48  26  44  31  30  31  52  48  39  35  55  48  49  83  55 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n 74  67  59  73  76  83  96  81  59  53 101 136  87 117 101  84 111  79 134 127 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n114 150  96 113 103 103 106  81  94 107  61  73  92  55  41  64  61  73  42  31 \n 81  82  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100 102 \n 40  32   9  30  30  26   9  19  14  21   6   9  12  15   8   4   4   6  13   5 \n3 least connected regions:\n2274 5021 5022 with 1 link\n5 most connected regions:\n3699 3700 3701 3702 3703 with 102 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 5 hexagons with 102 neighbours. We can also identify an average of 53 neighbours per hexagon using the distance-based weight matrix.\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1  2, 4, 5, 9, 10, 15, 32, 33\n2  1, 4, 5, 9, 10, 15, 32, 33\n3 5, 6, 7, 11, 12, 16, 17, 18\n                                                      wt grid_id busstops.x\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34          1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65          1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99          1\n  ORIGIN_BS WDA WDM WEE WEM   logWDM   logWDA   logWEM   logWEE BUS_ROOF_N\n1     25059 417  62  65   5 4.127134 6.033086 1.609438 4.174387        UNK\n2     25751 110  50  26  24 3.912023 4.700480 3.178054 3.258097       B02D\n3     26379 249  44  54  27 3.784190 5.517453 3.295837 3.988984        NIL\n             LOC_DESC busstops.y              area_hexagon_grid\n1   AFT TUAS STH BLVD          1 POLYGON ((3970.122 27925.48...\n2 BEF TUAS STH AVE 14          1 POLYGON ((4220.122 28358.49...\n3            YONG NAM          1 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_contiguity() of sfdep is used to identify the neighbours by using contiguity criteria. The output is a list of neighbours (i.e. nb).\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_contiguity(geo),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nsummary(wm_idw$nb)\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 107808 \nPercentage nonzero weights: 0.4274621 \nAverage number of links: 21.46714 \n6 regions with no links:\n1750 2274 3159 4675 4989 4994\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 \n  6  12  17  33  23  97  70  99  88  76 115 136 126 133 130 160 168 227 197 169 \n 20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39 \n159 174 251 240 213 195 222 210 183 187 124 115 104 110 111  39  54  56  11  17 \n 40  41  42  43  44  48 \n 55  62  13  17  10   8 \n12 least connected regions:\n1 32 62 736 3354 3355 4982 4990 5002 5003 5021 5022 with 1 link\n8 most connected regions:\n3048 3049 3050 3051 3052 3053 3054 3055 with 48 links\n\n\nUsing the inverse distance method resulted in 6 regions with no neighbours, this could be due to the spatial isolation of certain hexagons.\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method led to regions with no neighbours and is computationally intensive as each neighbour\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well.\n\n\ncentroid &lt;- st_centroid(origin_gridwgeom)\nplot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n\n\n\n#plot(wm_idw, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#computing-global-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#computing-global-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Computing Global Spatial Autocorrelation Statistics",
    "text": "5.2 Computing Global Spatial Autocorrelation Statistics\n\n5.2.1 Moran’s I\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing, using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed). H1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed with a seed number 1234. set.seed() function allows us to create reproducible results.\nNote: nsim arugment of global_moran_perm() refers to the number of simulations is nsim + 1, i.e., for nsim = 99, 100 simulations will be performed.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.094609, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.063584, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.095565, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.083812, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained).\n\n\n5.2.2 Geary’s C\n\n\n5.2.3 Spatial Correlogram"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#local-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#local-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.3 Local Spatial Autocorrelation Statistics",
    "text": "5.3 Local Spatial Autocorrelation Statistics\nGlobal spatial autocorrelation provides a broad overview of spatial clustering within a dataset, offering a single value that indicates whether similar values are generally clustered or dispersed across the entire study area. In contrast, local spatial autocorrelation delves into specific locations, identifying where clusters of similar values (hot spots or cold spots) or spatial outliers exist. While global metrics give an overall trend, local metrics provide detailed, location-specific insights, highlighting exact areas of significant spatial clustering or anomaly.\nThus, after we have established through statistical testing that spatial clustering of bus ridership occurs in Singapore, we now seek to detect clusters or outliers and discover if there are any hot or cold spots of high ridership using Local Spatial Autocorrelation Statistics.\n\n5.3.1 Local Moran’s I\nIn this section, we will perform Moran’s I statistics testing by using local_moran() of sfdep. The output of local_moran() is a sf data.frame, containing the columns below:\n\nii: local moran statistic\neii: expectation of local Moran’s I statistic\nvar_ii: variance of local Moran’s I statistic\nz_ii: standard deviation of local Moran’s I statistic\np_ii: p-value of local Moran’s I statistic using pnorm()\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value, based on crand.py of pysal\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nunnest() of tidyr package helps expand a list-column containing data frames into rows and columns.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\nlisa_WDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.190  0.00735 0.0204 1.28  0.201     0.02         0.01    -2.55     8.37\n2 0.190 -0.0100  0.0433 0.962 0.336     0.02         0.01    -5.72    42.9 \n3 0.186  0.00312 0.0459 0.853 0.394     0.02         0.01    -6.21    49.1 \n4 0.181  0.0166  0.0142 1.38  0.167     0.02         0.01    -2.06     5.79\n5 0.167  0.00919 0.0118 1.45  0.147     0.02         0.01    -2.18     7.71\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\nShow the code\nlisa_WDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDA, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii     eii   var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0752 0.00345 0.00381  1.16  0.245     0.02         0.01    -1.92     4.44\n2 0.0795 0.00807 0.00673  0.870 0.384     0.04         0.02    -3.02    10.4 \n3 0.0734 0.00141 0.00811  0.799 0.424     0.08         0.04    -2.87     9.31\n4 0.0567 0.0145  0.00114  1.25  0.212     0.02         0.01    -3.00    12.6 \n5 0.0415 0.00794 0.000767 1.21  0.225     0.02         0.01    -2.80    11.0 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\nShow the code\nlisa_WEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.143  0.000449 0.0154  1.15  0.252     0.04         0.02   -2.77     8.66 \n2 0.141  0.0126   0.00812 1.43  0.154     0.06         0.03   -0.884    0.201\n3 0.130 -0.0145   0.0446  0.684 0.494     0.02         0.01   -3.95    18.0  \n4 0.124  0.00189  0.0111  1.16  0.247     0.04         0.02   -2.96    11.3  \n5 0.115 -0.00534  0.0161  0.948 0.343     0.02         0.01   -5.03    33.2  \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\nShow the code\nlisa_WEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEE, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0904 -0.0160   0.0277  0.639 0.523     0.04         0.02    -4.96    27.3 \n2 0.0924 -0.00619  0.0143  0.824 0.410     0.02         0.01    -2.83     8.51\n3 0.0809  0.00535  0.00947 0.777 0.437     0.14         0.07    -2.66     7.65\n4 0.0756  0.000552 0.00974 0.760 0.447     0.02         0.01    -4.97    30.6 \n5 0.0637  0.000789 0.00272 1.20  0.228     0.04         0.02    -2.01     4.58\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\n\n\n5.3.2 Visualising Local Moran’s I & p-value\n:::panel-tabset ## Weekday Morning\n\n\nShow the code\n#tmap_mode(\"view\")\n#tm_basemap(\"CartoDB.Positron\") +\n#  tm_shape(lisa_WDM) +\n#  tm_fill(\"ii\",\n#          palette = \"Greens\",\n#          alpha = 0.6,\n#          id=\"LOC_DESC\") + \n#  tm_borders(alpha = 0.5)\n\ntmap_mode(\"plot\")\n\nplot_lisaWDM &lt;-\n  tm_shape(lisa_WDM) +\n    tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\nplotp_lisaWDM &lt;- \n  tm_shape(lisa_WDM) +\n    tm_fill(\"p_ii_sim\",\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_layout(main.title = \"p-value of Local Moran's I of Bus Ridership for Weekday Mornings\",\n            main.title.size = 0.7)\n\ntmap_arrange(plot_lisaWDM, plotp_lisaWDM, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex1.html",
    "href": "Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nThis is the getting started paragraph"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html",
    "href": "In-class_Ex/In-class_Ex2/test.html",
    "title": "In-class Ex 2",
    "section": "",
    "text": "Geospatial Analysis using sfdep"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html#joining-the-dataframes",
    "href": "In-class_Ex/In-class_Ex2/test.html#joining-the-dataframes",
    "title": "In-class Ex 2",
    "section": "2.1 Joining the dataframes",
    "text": "2.1 Joining the dataframes\nSpatial features are added to the attribute dataframe as geometry column:\n\nhunan_GDPPC&lt;- left_join(hunan, \n                         GDPPC, \n                         by = \"County\")\n\nglimpse(hunan_GDPPC)\n\nRows: 1,496\nColumns: 10\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21098, 21098, 21098, 21098, 21098, 21098, 21098, 210…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anx…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County\", \"County\", \"County\", \"County\",…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 1.869074, 1.869074, 1.869074, 1.869074, 1.869074,…\n$ Shape_Area &lt;dbl&gt; 0.1005619, 0.1005619, 0.1005619, 0.1005619, 0.1005619, 0.10…\n$ County     &lt;chr&gt; \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anxiang\", \"Anx…\n$ Year       &lt;dbl&gt; 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,…\n$ GDPPC      &lt;dbl&gt; 8184.00, 10995.00, 12670.00, 14128.00, 16763.00, 19817.00, …\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.0625 …"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/test.html#confirm-if-the-new-dataframe-is-a-spacetime-cube-object",
    "href": "In-class_Ex/In-class_Ex2/test.html#confirm-if-the-new-dataframe-is-a-spacetime-cube-object",
    "title": "In-class Ex 2",
    "section": "6.1 Confirm if the new dataframe is a spacetime cube object",
    "text": "6.1 Confirm if the new dataframe is a spacetime cube object\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Data Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains.\n\n\n\n\nAimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "As urban infrastructures, including public transportation systems like buses, taxis, mass rapid transit, public utilities, and roads, become increasingly digitised, the data generated becomes a valuable resource for tracking the movements of people and vehicles over space and time. This transformation has been facilitated by pervasive computing technologies such as Global Positioning System (GPS) and Radio Frequency Identification (RFID) tags on vehicles. An example of this is the collection of data on bus routes and ridership, amassed from the use of smart cards and GPS devices available on public buses.\nThe data collected from these sources is likely to contain valuable patterns that offer insights into various aspects of human movement and behavior within a city. Analyzing and comparing these patterns can provide a deeper understanding of urban mobility. Such insights can be instrumental in improving urban management and can also serve as valuable information for both public and private sector stakeholders involved in urban transportation services. This information can aid them in making informed decisions and gaining a competitive edge in their respective domains."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "AimTasks\n\n\nThe objective of this study is to utilize appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) techniques to uncover spatial and spatio-temporal mobility patterns among public bus passengers in Singapore.\n\n\nThis will include the following tasks:\n\nGeovisualisation and Analysis:\n\nCompute the passenger trips generated by origin at the hexagon level\nDisplay the geographical distribution of the passenger trips\nExplore spatial patterns revealed by the geovisualisation\n\n\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis - Compute LISA of the passenger trips generate by origin - Display and draw statistical conclusions of LISA maps\nEmerging Hot Spot Analysis (EHSA)\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values\nDisplay EHSA maps of the Gi* values, describe the spatial patterns revealed"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.1 The Data",
    "text": "3.1 The Data\nThe following data are used for this study:\n\nAspatial:\n\nPassenger Volume by Origin Destination Bus Stops for August, September and October 2023, downloaded from LTA DataMall using API.\n\nGeospatial\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\nhexagon, a hexagon layer of 250m is provided to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2 Import & Preparation",
    "text": "3.2 Import & Preparation"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#aspatial",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#aspatial",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2.1 Aspatial",
    "text": "3.2.1 Aspatial\n::: panel-tabset"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-into-r",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#import-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Import into R",
    "text": "Import into R\nWe will be importing the Passenger Volume by Origin Destination Bus Stops dataset from August to October 2023, downloaded from LTA DataMall by using read_csv() or readr package.\n\nodbus08 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n#odbus09 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202309.csv\")\n#odbus10 &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-exploration",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-exploration",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n(a) Attributes\nglimpse() of the dplyr package allows us to see all columns and their data type in the data frame.\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n#glimpse(odbus09)\n#glimpse(odbus10)\n\nInsights:\n\nThere are 7 variables in the odbus08 tibble data, they are:\n\nYEAR_MONTH: Month in which data is collected\nDAY_TYPE: Weekdays or weekends/holidays\nTIME_PER_HOUR: Hour which the passenger trip is based on, in intervals from 0 to 23 hours\nPT_TYPE: Type of public transport, i.e. bus\nORIGIN_PT_CODE: Origin bus stop ID\nDESTINATION_PT_CODE: Destination bus stop ID\nTOTAL_TRIPS: Number of trips\n\nWe also note that values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type.\n\n\n\n(b) Unique Bus Stops\nn_distinct() of the dplyr package allows us to count the unique bus stops in the data set.\n\nn_distinct(odbus08$ORIGIN_PT_CODE)\n\n[1] 5067\n\n\nThe results reveal that there are 5067 distinct origin bus stops."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n(a) Convert Data Type\nas.factor() can be used to convert the variables ORIGIN_PT_CODE and DESTINATON_PT_CODE from numeric to categorical data type. We use glimpse() again to check the results.\n\nodbus08$ORIGIN_PT_CODE &lt;- as.factor(odbus08$ORIGIN_PT_CODE)\nodbus08$DESTINATION_PT_CODE &lt;- as.factor(odbus08$DESTINATION_PT_CODE)\n\nglimpse(odbus08)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nNote that both of them are in factor data type now.\n\n\n(b) Duplicates Check\nBefore moving on to the next step, it is a good practice for us to check for duplicated records to prevent double counting of passenger trips.\n\nduplicate &lt;- odbus08 %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 7\n# ℹ 7 variables: YEAR_MONTH &lt;chr&gt;, DAY_TYPE &lt;chr&gt;, TIME_PER_HOUR &lt;dbl&gt;,\n#   PT_TYPE &lt;chr&gt;, ORIGIN_PT_CODE &lt;fct&gt;, DESTINATION_PT_CODE &lt;fct&gt;,\n#   TOTAL_TRIPS &lt;dbl&gt;\n\n\nResults confirm that there are no duplicated records found.\n\n\n(c) Extracting the Study Data\nIn our study, we would like to know patterns for 4 peak hour periods. Therefore, we can create a new variable period using the ifelse() that states whether an observation occurred during peak period using the code chunk below.\n\npeak &lt;- odbus08 %&gt;%\n  # Weekday morning peak\n  mutate(period= ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9), \"WDM\", \n                        # Weekday afternoon peak\n                        ifelse(DAY_TYPE==\"WEEKDAY\" & (TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20), \"WDA\", \n                               # Weekend/holiday morning peak\n                               ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14), \"WEM\",\n                                      # Weekend/holiday evening peak\n                                      ifelse(DAY_TYPE==\"WEEKENDS/HOLIDAY\" & (TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19), \"WEE\",\n                                             # Return off-peak if neither of the peak hour periods\n                                             \"Off-peak\")))))\n\nWe can then filter for peak-period data using the newly created period column and aggregate the total trips for each origin bus stop during peak period.\n\npeakperiods &lt;- peak %&gt;% \n  # filter helps to keep records that occurred during period periods\n  filter(period !=\"Off-peak\") %&gt;% \n  # aggregate the total passenger trips for each origin bus stop\n  group_by(period, ORIGIN_PT_CODE) %&gt;% \n  summarise(TRIPS=sum(TOTAL_TRIPS))\n\nLet’s visualise the proportions of passenger volumes for each peak period.\n\n\nShow the code\nfreq&lt;- ggplot(data=peakperiods, \n       aes(x=period,y=TRIPS))+\n  geom_bar(stat=\"identity\") +\n  theme(legend.position=\"none\")+\n  labs(title = \"Frequency of Trip for each Peak Period\",\n      x = \"Peak Period\",\n      y = \"Frequency\")\n\nfreq + scale_y_continuous(labels=label_comma())\n\n\n\n\n\nWe can see that passenger volume on weekdays are much higher than over the weekends/holidays.\nTranspose each peak period period as a columns using pivot_wider() of tidyr package will allow us to create further variables at a bus stop level. We replace NA values with 0 to reflect when there are no traffic for certain periods.\n\npeakperiods_wide &lt;- pivot_wider(peakperiods, \n                                names_from = \"period\", \n                                values_from = \"TRIPS\")\n\npeakperiods_wide[\"WDA\"][is.na(peakperiods_wide[\"WDA\"])] &lt;- 0\npeakperiods_wide[\"WDM\"][is.na(peakperiods_wide[\"WDM\"])] &lt;- 0\npeakperiods_wide[\"WEE\"][is.na(peakperiods_wide[\"WEE\"])] &lt;- 0\npeakperiods_wide[\"WEM\"][is.na(peakperiods_wide[\"WEM\"])] &lt;- 0\n\nglimpse(peakperiods_wide)\n\nRows: 5,067\nColumns: 5\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ WDA            &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n$ WDM            &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 424…\n$ WEE            &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6…\n$ WEM            &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 61…\n\n\nNotice that there are 5067 unique origin bus stops.\n\n\n(d) Variable Transformation\n\n\nShow the code\n# Extract column\ndistWDM &lt;- peakperiods_wide$WDM\n# Calculate mean \ndistWDM_mean &lt;- mean(distWDM)\n\nplot_distWDM &lt;- ggplot(\n    data = data.frame(distWDM),\n    aes(x = distWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 80000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWDA &lt;- peakperiods_wide$WDA\n# Calculate mean \ndistWDA_mean &lt;- mean(distWDA)\n\nplot_distWDA &lt;- ggplot(\n    data = data.frame(distWDA),\n    aes(x = distWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 110000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEM &lt;- peakperiods_wide$WEM\n# Calculate mean \ndistWEM_mean &lt;- mean(distWEM)\n\nplot_distWEM &lt;- ggplot(\n    data = data.frame(distWEM),\n    aes(x = distWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 23000, \n    y = 2000,\n    label = paste(\"Mean =\", round(distWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n# Extract column\ndistWEE &lt;- peakperiods_wide$WEE\n# Calculate mean \ndistWEE_mean &lt;- mean(distWEE)\n\nplot_distWEE &lt;- ggplot(\n    data = data.frame(distWEE),\n    aes(x = distWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"black\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 29000, \n    y = 2000, \n    label = paste(\"Mean =\", round(distWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) +\n  scale_x_continuous(labels = label_number(), n.breaks=8)\n\n(plot_distWDM | plot_distWDA)/\n(plot_distWEM | plot_distWEE)\n\n\n\n\n\nThe distribution of passenger trips for the 4 peak periods appear to be highly skewed to the right. Rescaling our data using log transformation can greatly reduce the skewness.\n\npeakperiods_wider &lt;- peakperiods_wide %&gt;% \n  mutate(logWDM = ifelse(WDM == 0, 0, log(WDM)),\n         logWDA = ifelse(WDA == 0, 0, log(WDA)),\n         logWEM = ifelse(WEM == 0, 0, log(WEM)),\n         logWEE = ifelse(WEE == 0, 0, log(WEE)))\n\nLet’s visualise the distribution of the 4 peak periods again.\n\n\nShow the code\n# Extract column\ndistlogWDM &lt;- peakperiods_wider$logWDM\n# Calculate mean \ndistlogWDM_mean &lt;- mean(distlogWDM)\n\nplot_distlogWDM &lt;- ggplot(\n    data = data.frame(distlogWDM),\n    aes(x = distlogWDM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWDA &lt;- peakperiods_wider$logWDA\n# Calculate mean \ndistlogWDA_mean &lt;- mean(distlogWDA)\n\nplot_distlogWDA &lt;- ggplot(\n    data = data.frame(distlogWDA),\n    aes(x = distlogWDA)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWDA_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWDA_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekday Afternoon Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  )\n\n# Extract column\ndistlogWEM &lt;- peakperiods_wider$logWEM\n# Calculate mean \ndistlogWEM_mean &lt;- mean(distlogWEM)\n\nplot_distlogWEM &lt;- ggplot(\n    data = data.frame(distlogWEM),\n    aes(x = distlogWEM)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEM_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000,\n    label = paste(\"Mean =\", round(distlogWEM_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekdend/Holiday Morning Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n# Extract column\ndistlogWEE &lt;- peakperiods_wider$logWEE\n# Calculate mean \ndistlogWEE_mean &lt;- mean(distlogWEE)\n\nplot_distlogWEE &lt;- ggplot(\n    data = data.frame(distlogWEE),\n    aes(x = distlogWEE)\n  ) +\n  geom_histogram(\n    bins = 20, \n    color = \"#FFFCF9\", \n    fill = \"#34414E\",\n    alpha = .3\n  ) +\n  # Add line for mean\n  geom_vline(\n    xintercept = distlogWEE_mean, \n    color = \"#595DE5\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  # Add line annotations\n  annotate(\n    \"text\", \n    x = 10, \n    y = 1000, \n    label = paste(\"Mean =\", round(distlogWEE_mean, 3)),\n    color = \"#595DE5\",\n    size = 3\n  ) +\n  labs(\n    title = \"Weekend/Holiday Evening Peak\",\n    x = \"Bus Trips\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust=1)\n  ) \n\n(plot_distlogWDM | plot_distlogWDA)/\n(plot_distlogWEM | plot_distlogWEE)\n\n\n\n\n\n\n\n3.2.2 Geospatial\n\nImport into RGeospatial Data Wrangling\n\n\n\n(a) Bus Stop Shapefile\nIn this section, we import BusStop shapefile into RStudio using st_read() function of sf package. This data provides the locations of all bus stops as at Q2 of 2023. crs = 3414 ensures coordinate reference system (CRS) is 3414, which is the EPSG code for the SVY21 projection used in Singapore.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kytjy\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe imported shape file is simple features object of sf. From the output, we can see that there are 5161 points with 3 fields, and confirm that the datum SVY21 is correct.\nRecall that there are 5067 origin bus stops from the peakperiods_wider table, compared to the 5161 bus stops from LTA’s BusStop shape file. This could be due to timing difference – LTA’s BusStop shapefile is as of July 2023, while peakperiod is based on Aug 2023.\n\nmapview::mapview(busstop)\n\n\n\n\n\n\nNote that there are 5 bus stops located outside Singapore, they are bus stops 46239, 46609, 47701, 46211, and 46219.\n\n\n(b) Hexagon Layer\nA hexagonal grid is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA. Hexagons have a number of advantages over these other shapes:\n\n\n\n\n\n\nWhy hexagons?\n\n\n\n\n\n\nThe distance between the centroid of a hexagon to all neighboring centroids is the same in all directions.\nThe lack of acute angles in a regular hexagon means that no areas of the shape are outliers in any direction.\nAll neighboring hexagons have the same spatial relationship with the central hexagon, making spatial querying and joining a more straightforward process.\nUnlike square-based grids, the geometry of hexagons are well-structured to represent curves of geographic features which are rarely perpendicular in shape, such as rivers and roads.\nThe “softer” shape of a hexagon compared to a square means it performs better at representing gradual spatial changes.\n\n\n\n\n\nStep 1: Create Hexagonal GridsStep 2: Convert to sf and count gridsStep 3: Remove grids with no bus stopsStep 4: Check & Visualise\n\n\nWe first create a hexagonal grid layer of 250m (refers to the perpendicular distance between the centre of the hexagon and its edges) with st_make_grid, and st_sf to convert the grid into an sf object with the codes below.\n\n\n\n\n\n\nst_make_grid Arguments\n\n\n\n\n\nst_make_grid function is used to create a grid over a spatial object. It takes 4 arguments, they are:\n\nx: sf object; the input spatial data\ncellsize: for hexagonal cells the distance between opposite edges in the unit of the crs the spatial data is using. In this case, we take cellsize to be 250m * 2 = 500m\n\n\n\nwhat: character; one of: \"polygons\", \"corners\", or \"centers\"\nsquare: indicates whether you are a square grid (TRUE) or hexagon grid (FALSE)\n\n\n\n\n\narea_hexagon_grid = st_make_grid(busstop, 500, what = \"polygons\", square = FALSE)\n\n\n\nNext, st_sf converts the grid created to sf object while lengths() of Base R is used to calculate the number of grids created.\n\n# Converts grid to sf\nhexagon_grid_sf = st_sf(area_hexagon_grid) %&gt;%\n  # Assign unique ID to each grid\n  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))\n\n\n\nWe count the number of bus stops in each grid and keep grids with bus stops using the code chunks below.\n\n# Create a column containing the count of bus stops in each grid\nhexagon_grid_sf$busstops = lengths(st_intersects(hexagon_grid_sf, busstop))\n\n# Remove if no bus stop in side that grid, ie only keep hexagons with bus stops\nhexagon_w_busstops = filter(hexagon_grid_sf, busstops &gt; 0)\n\n\n\nLet’s confirm that all bus stops have been accounted for in our hexagon layer.\n\nsum(hexagon_w_busstops$busstops)\n\n[1] 5161\n\n\nThis is in line with the 5161 points of the busstop shapefile.\nLastly, using tm_shape of tmap, we can quickly visualise the results of the hexagon grids we have created.\n\n\nShow the code\ntmap_mode (\"view\")\nhex &lt;- tm_shape(hexagon_w_busstops)+\n  tm_fill(\n    col = \"busstops\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of Bus Stops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.format = list(\n      grid_id = list(format = \"f\", digits = 0)\n    )\n  )+\n  tm_borders(col = \"grey40\", lwd = 0.7)\nhex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Combining Busstop and hexagon layer\nCode chunk below populates the grid ID (i.e. grid_id) of hexagon_w_busstops sf data frame into busstop sf data frame.\n\nbs_wgrids &lt;- st_intersection(busstop, hexagon_w_busstops) %&gt;% \n  select(BUS_STOP_N,BUS_ROOF_N,LOC_DESC, grid_id, busstops) %&gt;% \n  st_drop_geometry\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_stop_geometry() removes the geometry data to manipulate it like a regular dataframe using tidyr and dplyr functions\n\n\n\nBefore we proceed, let’s perform a duplicates check on bs_wgrids.\n\nduplicate2 &lt;- bs_wgrids %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nduplicate2\n\n# A tibble: 8 × 5\n  BUS_STOP_N BUS_ROOF_N LOC_DESC             grid_id busstops\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;int&gt;    &lt;int&gt;\n1 43709      B06        BLK 644                 1904        7\n2 43709      B06        BLK 644                 1904        7\n3 58031      UNK        OPP CANBERRA DR         2939        7\n4 58031      UNK        OPP CANBERRA DR         2939        7\n5 51071      B21        MACRITCHIE RESERVOIR    3081        6\n6 51071      B21        MACRITCHIE RESERVOIR    3081        6\n7 97079      B14        OPP ST. JOHN'S CRES     5037        5\n8 97079      B14        OPP ST. JOHN'S CRES     5037        5\n\n\nResults displayed 4 genuine duplicated records. We remove these to prevent double-counting.\nThe code chunk below helps retain unique records.\n\nbs_wgrids &lt;- unique(bs_wgrids)\n\n\n\n(c) Populate PeakPeriods with Grid Details\nWe can now append the grid ID from bs_wgrids data frame onto peakperiods_wide data frame. Recall we previously identified 5 bus stops outside Singapore, filter() allows us to exclude the 5 outside Singapore.\n\norigin_grid &lt;- left_join(peakperiods_wider, bs_wgrids,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;% \n  rename(ORIGIN_BS = ORIGIN_PT_CODE) %&gt;% \n  group_by(grid_id) %&gt;% \n  # retains SG bus stops\n  filter(!ORIGIN_BS %in% c(46239, 46609, 47701, 46211, 46219))\n\nglimpse(origin_grid)\n\nRows: 5,076\nColumns: 13\nGroups: grid_id [1,504]\n$ ORIGIN_BS  &lt;chr&gt; \"01012\", \"01013\", \"01019\", \"01029\", \"01039\", \"01059\", \"0110…\n$ WDA        &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233, 932…\n$ WDM        &lt;dbl&gt; 1973, 952, 1789, 2561, 2938, 1651, 161, 8492, 9015, 4240, 5…\n$ WEE        &lt;dbl&gt; 3208, 2796, 1623, 4244, 7403, 1190, 88, 21706, 11927, 6221,…\n$ WEM        &lt;dbl&gt; 2273, 1697, 1511, 3272, 5424, 1062, 89, 14964, 8278, 6198, …\n$ logWDM     &lt;dbl&gt; 7.587311, 6.858565, 7.489412, 7.848153, 7.985484, 7.409136,…\n$ logWDA     &lt;dbl&gt; 9.041685, 8.899458, 8.190909, 9.139596, 9.467847, 7.665285,…\n$ logWEM     &lt;dbl&gt; 7.728856, 7.436617, 7.320527, 8.093157, 8.598589, 6.967909,…\n$ logWEE     &lt;dbl&gt; 8.073403, 7.935945, 7.392032, 8.353261, 8.909641, 7.081709,…\n$ BUS_ROOF_N &lt;chr&gt; \"B03\", \"B05\", \"B04\", \"B07\", \"B09\", \"B08\", \"TMNL\", \"B07\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"HOTEL GRAND PACIFIC\", \"ST JOSEPH'S CH\", \"BRAS BASAH CPLX\",…\n$ grid_id    &lt;int&gt; 3292, 3292, 3292, 3323, 3354, 3324, 3324, 3292, 3324, 3292,…\n$ busstops   &lt;int&gt; 8, 8, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7,…\n\n\n\n\n(d) Retrieve Geometry\n\norigin_gridwgeom &lt;- inner_join(hexagon_w_busstops,\n                               origin_grid, \n                           by = \"grid_id\")\n#origin_gridwgeom &lt;- st_as_sf(origin_gridwgeom)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hexagon_w_busstop)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-classification",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-classification",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.1 Data Classification",
    "text": "4.1 Data Classification\nDifferent classification schemes highlight areas with the highest and/or lowest values, while others create classes that result in a more uniform distribution of colors. When data is sharply skewed or has extreme outliers, it’s important to consider whether the goal is to emphasize those areas or to achieve a more even distribution of colors and sizes.\nThe main methods of data classification are: - Quantile: each class contains an equal number of features. It assigns the same number of data values to each class. There are no empty classes or classes with too few or too many values - Jenks/Natural breaks: seeks clumps of values that are clustered together in order to form categories that may reflect meaningful groupings of areas - Equal: divides the range of attribute values into equal-sized sub-ranges\nSince our variable is less skewed after log transformation, we can explore various classification methods for visualization. This approach may reveal interesting insights that were not immediately apparent before."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#plots",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#plots",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Plots",
    "text": "4.2 Plots\n\n4.2.1 Weekday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\n\nplotlogWDM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n\nplotlogWDM_q\n\n\n\n\n\n\n\nThe grids above are partitioned using the quantile intervals. We can observe that the bus trips are unevenly distributed across Singapore. There are lighter shares of blue (indicating lower levels of ridership) originating from the edges of the country, particularly in the West, while higher levels of ridership in the North region are indicated by the darker shades of blue.\nBus stops nearer to the residential estates appeared to be popular during the weekday morning peak period:\n\nWest: BLK 821, BLK 252, Sunshine Place\nNorth: BLK 314\nNorth-East: BLK 477A, BLK 1, BLK 555, BLK 324\nEast: BLK 109, BLK 124, BLK 756\n\nThis is likely due to a large number of people commuting from home to their workplaces/schools on weekday mornings.\nHigher passenger traffic were noted at the bus stops nearer to MRT stations such as Harbourfront Station, Farrer Road Station, Yio Chu Kang Station, and Admirality Station. A possible contributing factor could be the people who are transiting from taking the MRTs to buses to get to their destinations.\nLastly, Woodlands Checkpoint also demonstrated higher ridership. This could potentially be due to the people commuting across the causeway from Malaysia into the Singapore borders.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_e\n\n\n\n\n\n\n\nThe map using equal intervals provided slightly different insights. We noted that the bus stop located near to MRT stations had higher levels of ridership. In particular, more trips originated from Tiong Bahru Station, Buona Vista Station, Tanah Merah Station, Admiralty Station, Harbourfront, and Woodleigh Station. Bus interchanges also appeared to be popular origins, i.e. Bukit Panjang Interchange and Joo Koon Interchange.\nIn general, more homogeneity is noted using the equal interval – the contrast between hexagon to hexagon is less obvious.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDM_j\n\n\n\n\n\n\n\nUsing Jenk’s partitioning method, the results were largely similar to the other two types of interval classes. Higher bus ridership were spotted at bus stops within close proximity to MRT stations (Kranji Station, Buona Vista Station, Buangkok Station, Ranggung Station, Farrer Road Station, Stevens Station, Bedok Reservoir Station) and residential estates (Sunshine Place near Tengah, BLK 109 in Bedok, BLK 477A in Sengkang, Bef. BLK 629A in Woodlands, to name a few).\n\n\n\n\n\n4.2.2 Weekday Afternoon Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_q\n\n\n\n\n\n\n\nA look at the weekday afternoon ridership using the quantile classification yielded the following insights.\n\nRidership from Woodlands Checkpoint remained high.\nBus stops in close proximity to MRT tations and popular bus stops in residential estatements remained high.\nMore trips originating from institutional areas: Opposite Ngee Ann Poly, Temasek Poly, NIE BLK 2, School of the Arts\nMore trips originating from industrial buildings/business parks: North Link Bldg, Aft Senoko Way, Mapletree Business City, Woodlands Auto Hub, Opp Airline Hse, etc.\nMore trips originating from hospitals: Yishun Community Hospital, Changi General Hospital\nSeletar Camp also looked to have high passenger levels\nThe far West seemed to experience low ridership other than the bus stop opposite Tuas Link Station.\nSouthern part of Singapore, consisting of more commercial areas, appeared to be more clustered as illustrated by the density of the darker red hexagons, compared to the weekday morning peak period.\n\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_e\n\n\n\n\n\n\n\nNotably, there were higher concentration of passengers who boarded the bus at Serangoon Station, Harbourfront/VivoCity, Tiong Bahru Station, Admiralty Station, and Punggol Station during weekday afternoons according to the equal interval classification method.\nSimilar to the map for weekday morning peak period, the equal interval seemed to produce more homogeneous classifications.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWDA_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWDA\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWDA_j\n\n\n\n\n\n\n\nJenk’s classification delivered similar insights to the quantile classification, where the higher concentration of ridership can be observed in the Southern downtown areas.\nIt also highlighted Opp Airline Hse in the far East as a bus stop with high ridership, something not as visible using the equal interval method.\nAlternative methods of commute might be more popular in the West and North-West regions illustrated by the lighter shades of red hexagons.\n\n\n\n\n\n4.2.3 Weekend/Holiday Morning Peak Period\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_q\n\n\n\n\n\n\n\nGenerally, the distribution of bus ridership looks varied across the island.\nDuring the weekend/holiday peak period, the ridership for far West region remained relatively low. Interestingly, the bus trips recorded from Seletar area appeared to have dipped compared to the weekday peak periods. Buses in these industrial areas could be oriented towards work-related travel, thus less common on weekends.\nBus stops nearer to housing estates, shopping malls, and Woodlands Checkpoint demonstrated higher levels of weekend morning ridership.\nThe bus stops with the highest boarding passengers are Sunshine Place, Opp BLK 271, BLK 252, Aft. Hasanah Mosque, Buona Vista Station, Harbourfront/Vivocity, Admiralty Station, BLK 555, Bedok Reservoir Station, BLK 22, BLK 109.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_e\n\n\n\n\n\n\n\nEqual interval classification highlighted the following bus stops to have the highest ridership during weekend/holiday morning peak period: Harbourfront/Vivocity, Tiong Bahru Station, Orchard Station/Lucky Plaza, Admirality Station, Aft. Punggol Road.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEM_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEM\", \n          style = \"jenks\", \n          palette = \"Blues\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEM_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification.\n\n\n\n\n\n4.2.4 Weekend/Holiday Evening\n\nQuantileEqual IntervalsJenk’s\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_q &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_q\n\n\n\n\n\n\n\nOn weekend/holiday evenings, there seemed to be increased ridership at the bus stops near Changi Airport compared to the other peak periods.\nSunshine Plaza remains one of the most frequented bus stops, exhibiting high ridership across all four peak periods. While the exact reason for this is difficult to pinpoint, it’s possible that the buses stopping here connect to a wide variety of regions, which could explain the high ridership.\nWoodlands Checkpoint also demonstrated high levels of ridership across the different peak periods.\nVisually, it looks like there are more bus stops with high ridership across Singapore during the weekend/holiday evening peak period. For example, there seem to be an increase in passenger volume at the Tanah Merah Ferry compared to the other peak periods.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_e &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"equal\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_e\n\n\n\n\n\n\n\nThe bus stops with higher traffic seem to be quite consistent across the different peak periods. This includes Woodlands Checkpoint, Kranji Station, Admiralty Station, Serangoon Station, Aft. Punggol Road, Bukit Panjang MRT, Yio Chu Kang Interchange.\n\n\n\n\nShow the code\ntmap_mode (\"view\")\nplotlogWEE_j &lt;- tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(origin_gridwgeom) +\n  tm_fill(\"logWEE\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total passenger trips\",\n          alpha=0.6,\n          id=\"LOC_DESC\")\n  \nplotlogWEE_j\n\n\n\n\n\n\n\nThe findings noted with Jenk’s method are similar to the quantile classification."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#global-spatial-autocorrelation",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Global Spatial Autocorrelation",
    "text": "5.1 Global Spatial Autocorrelation\n\n5.1.1 Spatial Weights Matrix\nTo compute the local spatial autocorrelation statistics, we first need to construct a spatial weights of Singapore. Spatial relationships are multi-directional and multi-lateral. We can use spatial weights to define who the neighbours of the spatial units.\nThere are two common methods of spatial weights: contiguity-based and distance-based.\nContiguity-based: Neighbours share a common boundary, which can be further distinguished between a Rook and a Queen criterion of contiguity. Rook contiguity defines neighbours by the existence of a common edge between two spatial units. In Queen contiguity defines neighbours as spatial units sharing a common edge or a common vertex.\nDistance-based: Assign higher weights to pairs of locations that are closer to each other and lower weights to pairs that are further. This can be further distinguished by fixed weighting, adaptive weighting and inverse-distance weighting schemes. Fixed weighting scheme considers two regions are neighbours if they are within a specified distance from one another. For adaptive weighting scheme, each region will have the same number of neighbours. The number of neighbour is specified beforehand, where k = number of neighbours. Inverse distance method considers that the closer two features are in space, the more likely they are to interact/influence each other.\nFor this study, we will be using distance-based weight matrix as there are areas where bus stops are sparse (such as Lim Chu Kang and Mandai) and isolated (for example, Tanah Merah Ferry, Changi Naval Base, Resort World Sentosa, Marina Bay Cruise Centre). Consequently, contiguity-based matrix may yield many regions with no neighbours, making it not suitable for our analysis.\n\nFixed Distance Weight MatrixAdaptive Distance-Based Weight MatrixInverse Distance Weights (IDW)\n\n\n\nStep 1: Determine Cut-Off Distance Limit\nFirst step is to determine the upper distance limit to ensure that each hexagon has at least 1 neighbour.\nThe following functions can be used:\n\nst_knn() of sfdep is used to identify neighbors based on k (e.g. k = 8 indicates the nearest eight neighbours). The output is a neighbours list of class nb. If polygon geometry is provided, the centroids of the polygon will be used for calculation.\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\n\ngeo &lt;- sf::st_geometry(origin_gridwgeom)\nnb &lt;- st_knn(geo, \n             longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\n\nStep 2: Derive Summary Stats\nWe can derive summary statistics of the nearest neighbour distances vector (i.e. dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   22.89    0.00 1000.00 \n\n\nThe maximum nearest neighbour distance is 1000m, thus we will use threshold value of 1001m to ensure each spatial unit has a minimum of 1 neighbour.\n\n\nStep 3: Compute fixed distance weight\nNow we will go ahead to compute the fixed distance weights by using following functions:\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 1000m). The output is a list of neighbours (i.e. nb). st_weights() is then used to calculate polygon spatial weights of the nb list. Note that the default style argument is set to “W” for row standardized weights, and the default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors.\n\nwm_fd &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_dist_band(geo,\n                           upper = 1001),\n               wt = st_weights(nb),\n               .before = 1)\n\n\n\nStep 4: Observations\n\n\nShow the code\n#kable(head(wm_fd,5))\nsummary(wm_fd$nb)\n\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 266698 \nPercentage nonzero weights: 1.057466 \nAverage number of links: 53.10593 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  3   6   3   4   7   6  20  19  20  13  24  13  21  29  20  35  28  40  34  40 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n 24  52  45  33  39  48  26  44  31  30  31  52  48  39  35  55  48  49  83  55 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n 74  67  59  73  76  83  96  81  59  53 101 136  87 117 101  84 111  79 134 127 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n114 150  96 113 103 103 106  81  94 107  61  73  92  55  41  64  61  73  42  31 \n 81  82  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100 102 \n 40  32   9  30  30  26   9  19  14  21   6   9  12  15   8   4   4   6  13   5 \n3 least connected regions:\n2274 5021 5022 with 1 link\n5 most connected regions:\n3699 3700 3701 3702 3703 with 102 links\n\n\nFrom the result above, we can confirm that all hexagons have at least one neighbour and there are 5 hexagons with 102 neighbours. We can also identify an average of 53 neighbours per hexagon using the distance-based weight matrix.\n\n\n\nA characteristic of fixed distance weights matrix is that more densely settled areas (town, residential neighbourhoods) tend to have more neigbours while less densely settle areas (military camps, industrial estates) tend to have less neighbours. To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can directly control the number of neighbours using k-nearest neighbours by setting the value of k in the code chunk below.\nAs a rule-of-thumb, we will set k = 8 i.e., all hexagons will have 8 neighbours.\n\nwm_ad &lt;- origin_gridwgeom %&gt;% \n  mutate(nb = st_knn(geo,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\nhead(wm_ad, n=3)\n\nSimple feature collection with 3 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4720.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n                           nb\n1  2, 4, 5, 9, 10, 15, 32, 33\n2  1, 4, 5, 9, 10, 15, 32, 33\n3 5, 6, 7, 11, 12, 16, 17, 18\n                                                      wt grid_id busstops.x\n1 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      34          1\n2 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      65          1\n3 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125      99          1\n  ORIGIN_BS WDA WDM WEE WEM   logWDM   logWDA   logWEM   logWEE BUS_ROOF_N\n1     25059 417  62  65   5 4.127134 6.033086 1.609438 4.174387        UNK\n2     25751 110  50  26  24 3.912023 4.700480 3.178054 3.258097       B02D\n3     26379 249  44  54  27 3.784190 5.517453 3.295837 3.988984        NIL\n             LOC_DESC busstops.y              area_hexagon_grid\n1   AFT TUAS STH BLVD          1 POLYGON ((3970.122 27925.48...\n2 BEF TUAS STH AVE 14          1 POLYGON ((4220.122 28358.49...\n3            YONG NAM          1 POLYGON ((4470.122 30523.55...\n\n\nThe results show that the weights of the neighbours have been assigned to 1/8 (0.125) of the total weight, representing each of the 8 neighbours.\n\n\nInverse distance weights takes into account the decay functions of distance.\nWe can derive spatial weight matrix based on inverse distance method using the following functions:\n\nst_contiguity() of sfdep is used to identify the neighbours by using contiguity criteria. The output is a list of neighbours (i.e. nb).\nst_inverse_distance() is then used to calculate inverse distance weights of neighbours on the nb list.\n\n\nwm_idw &lt;- origin_gridwgeom %&gt;%\n  mutate(nb = st_contiguity(geo),\n         wts = st_inverse_distance(nb, geo,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nsummary(wm_idw$nb)\n\nNeighbour list object:\nNumber of regions: 5022 \nNumber of nonzero links: 107808 \nPercentage nonzero weights: 0.4274621 \nAverage number of links: 21.46714 \n6 regions with no links:\n1750 2274 3159 4675 4989 4994\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 \n  6  12  17  33  23  97  70  99  88  76 115 136 126 133 130 160 168 227 197 169 \n 20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39 \n159 174 251 240 213 195 222 210 183 187 124 115 104 110 111  39  54  56  11  17 \n 40  41  42  43  44  48 \n 55  62  13  17  10   8 \n12 least connected regions:\n1 32 62 736 3354 3355 4982 4990 5002 5003 5021 5022 with 1 link\n8 most connected regions:\n3048 3049 3050 3051 3052 3053 3054 3055 with 48 links\n\n\nUsing the inverse distance method resulted in 6 regions with no neighbours, this could be due to the spatial isolation of certain hexagons.\n\n\n\nIn summary:\n\nThe number of neighbours using fixed distance method vary widely from 1 to 102. Consequently, the uneven distribution could affect the spatial autocorrelation analysis.\nInverse distance method led to regions with no neighbours and is computationally intensive as each neighbour\nSince each hexagon is equally sized, the adaptive distance-based spatial weight matrix would be best suited for our analysis since each centroid can represent each region well.\n\n\ncentroid &lt;- st_centroid(origin_gridwgeom)\nplot(origin_gridwgeom$area_hexagon_grid, border = \"lightgrey\")\n\n\n\n#plot(wm_idw, centroid, pch = 19, cex = 0.1, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#computing-global-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#computing-global-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Computing Global Spatial Autocorrelation Statistics",
    "text": "5.2 Computing Global Spatial Autocorrelation Statistics\n\n5.2.1 Moran’s I\nWe will perform Moran’s I statistical testing by using global_moran_perm() of spdep. The Global Moran’s I Permutation Test is a statistical method used in spatial analysis to assess the significance of spatial autocorrelation in a dataset. Spatial autocorrelation refers to the degree to which a variable is correlated with itself across space, indicating patterns such as clustering or dispersion.\n\n\n\n\n\n\nInterpretation of Moran’s I\n\n\n\n\n\nThe Moran I statistic ranges from -1 to 1. If the Moran I is:\n\npositive (I&gt;0): Clustered, observations tend to be similar\nnegative (I&lt;0): Disperse, observations tend to be dissimilar\napproximately zero: observations arranged randomly over space\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing, using the null and alternative hypotheses as follows:\nH0: The observed spatial patterns of proportion of bus ridership in Singapore are not clustered (i.e. either random or dispersed). H1: The observed spatial patterns of proportion of bus ridership in Singapore are clustered.\nA total of 100 simulations will be performed with a seed number 1234. set.seed() function allows us to create reproducible results.\nNote: nsim arugment of global_moran_perm() refers to the number of simulations is nsim + 1, i.e., for nsim = 99, 100 simulations will be performed.\n\nset.seed(1234)\n\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\ngmp_WDM &lt;- global_moran_perm(wm_ad$WDM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.094609, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WDA &lt;- global_moran_perm(wm_ad$WDA,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WDA\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.063584, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEM &lt;- global_moran_perm(wm_ad$WEM,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEM\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.095565, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nShow the code\ngmp_WEE &lt;- global_moran_perm(wm_ad$WEE,\n                  wm_ad$nb,\n                  wm_ad$wt,\n                  nsim = 99)\ngmp_WEE\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.083812, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\nAcross the 4 peak periods, the permutation test generated low p-values of &lt;0.05. This indicates that we can reject the null hypothesis at the 95% level of confidence, and conclude that for each of the 4 peak periods, the overall bus ridership across Singapore is spatially clustered (since positive Moran’s I value is obtained).\n\n\n5.2.2 Geary’s C\n\n\n5.2.3 Spatial Correlogram"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-spatial-autocorrelation-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-spatial-autocorrelation-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.3 Local Spatial Autocorrelation Statistics",
    "text": "5.3 Local Spatial Autocorrelation Statistics\nGlobal spatial autocorrelation provides a broad overview of spatial clustering within a dataset, offering a single value that indicates whether similar values are generally clustered or dispersed across the entire study area. In contrast, local spatial autocorrelation delves into specific locations, identifying where clusters of similar values (hot spots or cold spots) or spatial outliers exist. While global metrics give an overall trend, local metrics provide detailed, location-specific insights, highlighting exact areas of significant spatial clustering or anomaly.\nThus, after we have established through statistical testing that spatial clustering of bus ridership occurs in Singapore, we now seek to detect clusters or outliers and discover if there are any hot or cold spots of high ridership using Local Spatial Autocorrelation Statistics.\n\n5.2.1 Local Moran’s I\nIn this section, we will perform Moran’s I statistics testing by using local_moran() of sfdep. The output of local_moran() is a sf data.frame, containing the columns below:\n\nii: local moran statistic\neii: expectation of local Moran’s I statistic\nvar_ii: variance of local Moran’s I statistic\nz_ii: standard deviation of local Moran’s I statistic\np_ii: p-value of local Moran’s I statistic using pnorm()\np_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: the simulation folded [0, 0.5] range ranked p-value, based on crand.py of pysal\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nunnest() of tidyr package helps expand a list-column containing data frames into rows and columns.\n\nWeekday MorningWeekday AfternoonWeekend/Holiday MorningWeekend/Holiday Evening\n\n\n\n\nShow the code\nlisa_WDM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDM, n=5)\n\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.190  0.00735 0.0204 1.28  0.201     0.02         0.01    -2.55     8.37\n2 0.190 -0.0100  0.0433 0.962 0.336     0.02         0.01    -5.72    42.9 \n3 0.186  0.00312 0.0459 0.853 0.394     0.02         0.01    -6.21    49.1 \n4 0.181  0.0166  0.0142 1.38  0.167     0.02         0.01    -2.06     5.79\n5 0.167  0.00919 0.0118 1.45  0.147     0.02         0.01    -2.18     7.71\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WDA &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WDA, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WDA, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii     eii   var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0752 0.00345 0.00381  1.16  0.245     0.02         0.01    -1.92     4.44\n2 0.0795 0.00807 0.00673  0.870 0.384     0.04         0.02    -3.02    10.4 \n3 0.0734 0.00141 0.00811  0.799 0.424     0.08         0.04    -2.87     9.31\n4 0.0567 0.0145  0.00114  1.25  0.212     0.02         0.01    -3.00    12.6 \n5 0.0415 0.00794 0.000767 1.21  0.225     0.02         0.01    -2.80    11.0 \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WEM &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEM, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEM, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n     ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.143  0.000449 0.0154  1.15  0.252     0.04         0.02   -2.77     8.66 \n2 0.141  0.0126   0.00812 1.43  0.154     0.06         0.03   -0.884    0.201\n3 0.130 -0.0145   0.0446  0.684 0.494     0.02         0.01   -3.95    18.0  \n4 0.124  0.00189  0.0111  1.16  0.247     0.04         0.02   -2.96    11.3  \n5 0.115 -0.00534  0.0161  0.948 0.343     0.02         0.01   -5.03    33.2  \n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;\n\n\n\n\n\nlisa_WEE &lt;- wm_ad %&gt;% \n  mutate(local_moran = local_moran(\n    origin_gridwgeom$WEE, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nhead(lisa_WEE, n=5)\n\nSimple feature collection with 5 features and 28 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31100.9\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5 × 29\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0904 -0.0160   0.0277  0.639 0.523     0.04         0.02    -4.96    27.3 \n2 0.0924 -0.00619  0.0143  0.824 0.410     0.02         0.01    -2.83     8.51\n3 0.0809  0.00535  0.00947 0.777 0.437     0.14         0.07    -2.66     7.65\n4 0.0756  0.000552 0.00974 0.760 0.447     0.02         0.01    -4.97    30.6 \n5 0.0637  0.000789 0.00272 1.20  0.228     0.04         0.02    -2.01     4.58\n# ℹ 20 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, grid_id &lt;int&gt;, busstops.x &lt;int&gt;, ORIGIN_BS &lt;chr&gt;, WDA &lt;dbl&gt;,\n#   WDM &lt;dbl&gt;, WEE &lt;dbl&gt;, WEM &lt;dbl&gt;, logWDM &lt;dbl&gt;, logWDA &lt;dbl&gt;, logWEM &lt;dbl&gt;,\n#   logWEE &lt;dbl&gt;, BUS_ROOF_N &lt;chr&gt;, LOC_DESC &lt;chr&gt;, busstops.y &lt;int&gt;,\n#   area_hexagon_grid &lt;POLYGON [m]&gt;"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekday-afternoon-2",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekday-afternoon-2",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekday Afternoon",
    "text": "Weekday Afternoon"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-morning-2",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-morning-2",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekend/Holiday Morning",
    "text": "Weekend/Holiday Morning"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-evening-3",
    "href": "Take-Home_Ex/Take-Home_Ex1/THE1.html#weekendholiday-evening-3",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Weekend/Holiday Evening",
    "text": "Weekend/Holiday Evening"
  }
]